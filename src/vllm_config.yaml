parameters:
  
  max_num_batched_tokens:
    name: "max-num-batched-tokens"
    enabled: true
    options: [8192, 16384]

  compilation_config:
    name: "compilation-config"
    enabled: true
    level: [0, 3]
    
  block_size:
    name: "block-size"
    enabled: true
    options: [8, 16, 32, 64, 128]

  kv_cache_dtype:
    name: "kv-cache-dtype"
    enabled: true
    options: ["auto", "fp8", "fp8_e5m2", "fp8_e4m3"]

  gpu_memory_utilization:
    name: "gpu-memory-utilization"
    enabled: true
    range:
      start: 0.90
      end: 0.95
      step: 0.01

  preemption-mode:
    name: "preemption-mode"
    enabled: true
    options: ["recompute", "swap"]

  # Guidellm concurrency parameter
  guidellm_concurrency:
    name: "guidellm-concurrency"
    enabled: true
    range:
      start: 10
      end: 240
      step: 10

  cuda_graph_sizes:
    name: "cuda-graph-sizes"
    enabled: true
    range:
      start: 8
      end: 16384
      step: 8

  long_prefill_token_threshold:
    name: "long-prefill-token-threshold"
    enabled: true
    range:
      start: 512
      end: 4096
      step: 512

  max_parallel_loading_workers:
    name: "max-parallel-loading-workers"
    enabled: true
    range:
      start: 1
      end: 8
      step: 1

optimization:
  # Available approaches:
  # - "single_objective": Maximize throughput only
  # - "multi_objective": Find Pareto-optimal throughput vs latency trade-offs
  approach: "multi_objective"
  
  n_trials: 200

  # choose between ["botorch", "nsga2", "tpe", "random", "grid"]
  sampler: "botorch"

settings:
  trial_interval: 30