parameters:
  
  max_num_batched_tokens:
    name: "max-num-batched-tokens"
    enabled: true
    options: [8192, 16384]

  compilation_config:
    name: "compilation-config"
    enabled: true
    level: [0, 3]
    
  block_size:
    name: "block-size"
    enabled: true
    options: [16, 32]

  max_num_seqs:
    name: "max-num-seqs"
    enabled: true
    options: [64, 128, 192, 256, 384, 512]

  kv_cache_dtype:
    name: "kv-cache-dtype"
    enabled: true
    options: ["fp8"] # fp8_e5m2 kv-cache is not supported with fp8 checkpoint  
    # "auto" 

  gpu_memory_utilization:
    name: "gpu-memory-utilization"
    enabled: true
    range:
      start: 0.90
      end: 0.95
      step: 0.01

  preemption-mode:
    name: "preemption-mode"
    enabled: false
    options: ["recompute", "swap"]

  # Guidellm concurrency parameter
  guidellm_concurrency:
    name: "guidellm-concurrency"
    enabled: false
    range:
      start: 10
      end: 240
      step: 10

  cuda_graph_sizes:
    name: "cuda-graph-sizes"
    enabled: true
    range:
      start: 8
      end: 16328
      step: 64

  long_prefill_token_threshold:
    name: "long-prefill-token-threshold"
    enabled: true
    options: [0, 256, 512, 1024, 2048]

  max_seq_len_to_capture:
    name: "max-seq-len-to-capture"
    enabled: false
    options: [4096, 8192, 16384]

  max_num_partial_prefills:
    name: "max-num-partial-prefills"
    enabled: true
    options: [1, 2, 4, 8]

optimization:
  # Available approaches:
  # - "single_objective": Maximize throughput only
  # - "multi_objective": Find Pareto-optimal throughput vs latency trade-offs
  approach: "multi_objective"
  
  n_trials: 200

  # Choose between ["botorch", "nsga2", "tpe", "random", "grid"]
  # BoTorch is particularly effective for parallel optimization across multiple GPUs
  # as it can suggest multiple candidates simultaneously and learn from parallel trials
  sampler: "botorch"

settings:
  trial_interval: 30