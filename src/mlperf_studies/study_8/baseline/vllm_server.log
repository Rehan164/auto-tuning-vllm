INFO 07-22 15:08:14 [__init__.py:243] Automatically detected platform cuda.
INFO 07-22 15:08:20 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 07-22 15:08:20 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 07-22 15:08:20 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 07-22 15:08:21 [api_server.py:1289] vLLM API server version 0.9.0.1
INFO 07-22 15:08:21 [cli_args.py:300] non-default args: {'disable_log_requests': True}
INFO 07-22 15:08:37 [config.py:793] This model supports multiple tasks: {'embed', 'generate', 'classify', 'reward', 'score'}. Defaulting to 'generate'.
INFO 07-22 15:08:37 [config.py:2118] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 07-22 15:08:42 [__init__.py:243] Automatically detected platform cuda.
INFO 07-22 15:08:45 [core.py:438] Waiting for init message from front-end.
INFO 07-22 15:08:45 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 07-22 15:08:45 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 07-22 15:08:45 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 07-22 15:08:45 [core.py:65] Initializing a V1 LLM engine (v0.9.0.1) with config: model='meta-llama/Llama-3.1-8B', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.1-8B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level": 3, "custom_ops": ["none"], "splitting_ops": ["vllm.unified_attention", "vllm.unified_attention_with_output"], "compile_sizes": [], "inductor_compile_config": {"enable_auto_functionalized_v2": false}, "use_cudagraph": true, "cudagraph_num_of_warmups": 1, "cudagraph_capture_sizes": [512, 504, 496, 488, 480, 472, 464, 456, 448, 440, 432, 424, 416, 408, 400, 392, 384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], "max_capture_size": 512}
WARNING 07-22 15:08:45 [utils.py:2671] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd4a04514c0>
INFO 07-22 15:08:50 [parallel_state.py:1064] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
WARNING 07-22 15:08:50 [topk_topp_sampler.py:58] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 07-22 15:08:50 [gpu_model_runner.py:1531] Starting to load model meta-llama/Llama-3.1-8B...
INFO 07-22 15:08:51 [cuda.py:217] Using Flash Attention backend on V1 engine.
INFO 07-22 15:08:51 [backends.py:35] Using InductorAdaptor
INFO 07-22 15:08:52 [weight_utils.py:291] Using model weights format ['*.safetensors']
INFO 07-22 15:08:53 [weight_utils.py:307] Time spent downloading weights for meta-llama/Llama-3.1-8B: 0.561068 seconds
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:00,  6.56it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.12it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.69it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.54it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.73it/s]

INFO 07-22 15:08:56 [default_loader.py:280] Loading weights took 2.37 seconds
INFO 07-22 15:08:56 [gpu_model_runner.py:1549] Model loading took 14.9889 GiB and 5.312570 seconds
INFO 07-22 15:09:02 [backends.py:459] Using cache directory: /root/.cache/vllm/torch_compile_cache/842d7db6ee/rank_0_0 for vLLM's torch.compile
INFO 07-22 15:09:02 [backends.py:469] Dynamo bytecode transform time: 6.07 s
INFO 07-22 15:09:04 [backends.py:158] Cache the graph of shape None for later use
INFO 07-22 15:09:26 [backends.py:170] Compiling a graph for general shape takes 23.65 s
INFO 07-22 15:09:37 [monitor.py:33] torch.compile takes 29.72 s in total
INFO 07-22 15:09:38 [kv_cache_utils.py:637] GPU KV cache size: 191,312 tokens
INFO 07-22 15:09:38 [kv_cache_utils.py:640] Maximum concurrency for 131,072 tokens per request: 1.46x
INFO 07-22 15:10:00 [gpu_model_runner.py:1933] Graph capturing finished in 22 secs, took 0.52 GiB
INFO 07-22 15:10:00 [core.py:167] init engine (profile, create kv cache, warmup model) took 64.16 seconds
INFO 07-22 15:10:01 [loggers.py:134] vllm cache_config_info with initialization after num_gpu_blocks is: 11957
WARNING 07-22 15:10:02 [config.py:1339] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 07-22 15:10:02 [serving_chat.py:117] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 07-22 15:10:03 [serving_completion.py:65] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 07-22 15:10:03 [api_server.py:1336] Starting vLLM API server on http://0.0.0.0:8000
INFO 07-22 15:10:03 [launcher.py:28] Available routes are:
INFO 07-22 15:10:03 [launcher.py:36] Route: /openapi.json, Methods: GET, HEAD
INFO 07-22 15:10:03 [launcher.py:36] Route: /docs, Methods: GET, HEAD
INFO 07-22 15:10:03 [launcher.py:36] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 07-22 15:10:03 [launcher.py:36] Route: /redoc, Methods: GET, HEAD
INFO 07-22 15:10:03 [launcher.py:36] Route: /health, Methods: GET
INFO 07-22 15:10:03 [launcher.py:36] Route: /load, Methods: GET
INFO 07-22 15:10:03 [launcher.py:36] Route: /ping, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /ping, Methods: GET
INFO 07-22 15:10:03 [launcher.py:36] Route: /tokenize, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /detokenize, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /v1/models, Methods: GET
INFO 07-22 15:10:03 [launcher.py:36] Route: /version, Methods: GET
INFO 07-22 15:10:03 [launcher.py:36] Route: /v1/chat/completions, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /v1/completions, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /v1/embeddings, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /pooling, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /classify, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /score, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /v1/score, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /v1/audio/transcriptions, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /rerank, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /v1/rerank, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /v2/rerank, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /invocations, Methods: POST
INFO 07-22 15:10:03 [launcher.py:36] Route: /metrics, Methods: GET
INFO:     Started server process [206029]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:53218 - "GET /health HTTP/1.1" 200 OK
INFO 07-22 15:13:03 [loggers.py:116] Engine 000: Avg prompt throughput: 8602.6 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 20 reqs, Waiting: 13273 reqs, GPU KV cache usage: 7.4%, Prefix cache hit rate: 1.7%
INFO 07-22 15:13:13 [loggers.py:116] Engine 000: Avg prompt throughput: 12720.0 tokens/s, Avg generation throughput: 231.2 tokens/s, Running: 49 reqs, Waiting: 13117 reqs, GPU KV cache usage: 19.5%, Prefix cache hit rate: 1.9%
INFO 07-22 15:13:23 [loggers.py:116] Engine 000: Avg prompt throughput: 12142.0 tokens/s, Avg generation throughput: 361.8 tokens/s, Running: 62 reqs, Waiting: 12977 reqs, GPU KV cache usage: 26.4%, Prefix cache hit rate: 1.9%
INFO 07-22 15:13:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11894.1 tokens/s, Avg generation throughput: 353.5 tokens/s, Running: 59 reqs, Waiting: 12838 reqs, GPU KV cache usage: 25.3%, Prefix cache hit rate: 1.9%
INFO 07-22 15:13:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11911.5 tokens/s, Avg generation throughput: 353.3 tokens/s, Running: 60 reqs, Waiting: 12700 reqs, GPU KV cache usage: 26.2%, Prefix cache hit rate: 1.9%
INFO 07-22 15:13:53 [loggers.py:116] Engine 000: Avg prompt throughput: 12058.4 tokens/s, Avg generation throughput: 372.3 tokens/s, Running: 70 reqs, Waiting: 12551 reqs, GPU KV cache usage: 28.6%, Prefix cache hit rate: 1.9%
INFO 07-22 15:14:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11434.3 tokens/s, Avg generation throughput: 419.7 tokens/s, Running: 69 reqs, Waiting: 12419 reqs, GPU KV cache usage: 30.5%, Prefix cache hit rate: 1.9%
INFO 07-22 15:14:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11704.5 tokens/s, Avg generation throughput: 404.3 tokens/s, Running: 58 reqs, Waiting: 12283 reqs, GPU KV cache usage: 23.8%, Prefix cache hit rate: 1.9%
INFO 07-22 15:14:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11974.8 tokens/s, Avg generation throughput: 349.3 tokens/s, Running: 67 reqs, Waiting: 12142 reqs, GPU KV cache usage: 25.4%, Prefix cache hit rate: 1.9%
INFO 07-22 15:14:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11717.7 tokens/s, Avg generation throughput: 407.3 tokens/s, Running: 71 reqs, Waiting: 12004 reqs, GPU KV cache usage: 28.5%, Prefix cache hit rate: 1.9%
INFO 07-22 15:14:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11652.0 tokens/s, Avg generation throughput: 422.6 tokens/s, Running: 68 reqs, Waiting: 11868 reqs, GPU KV cache usage: 29.4%, Prefix cache hit rate: 1.9%
INFO 07-22 15:14:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11554.2 tokens/s, Avg generation throughput: 380.7 tokens/s, Running: 61 reqs, Waiting: 11738 reqs, GPU KV cache usage: 29.8%, Prefix cache hit rate: 1.9%
INFO 07-22 15:15:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11494.1 tokens/s, Avg generation throughput: 338.7 tokens/s, Running: 53 reqs, Waiting: 11615 reqs, GPU KV cache usage: 27.0%, Prefix cache hit rate: 1.8%
INFO 07-22 15:15:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11880.4 tokens/s, Avg generation throughput: 310.8 tokens/s, Running: 59 reqs, Waiting: 11480 reqs, GPU KV cache usage: 28.3%, Prefix cache hit rate: 1.8%
INFO 07-22 15:15:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11460.4 tokens/s, Avg generation throughput: 379.6 tokens/s, Running: 72 reqs, Waiting: 11353 reqs, GPU KV cache usage: 32.3%, Prefix cache hit rate: 1.8%
INFO 07-22 15:15:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11172.9 tokens/s, Avg generation throughput: 435.2 tokens/s, Running: 71 reqs, Waiting: 11227 reqs, GPU KV cache usage: 28.5%, Prefix cache hit rate: 1.8%
INFO 07-22 15:15:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11576.9 tokens/s, Avg generation throughput: 403.5 tokens/s, Running: 63 reqs, Waiting: 11098 reqs, GPU KV cache usage: 27.0%, Prefix cache hit rate: 1.8%
INFO 07-22 15:15:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11855.7 tokens/s, Avg generation throughput: 374.7 tokens/s, Running: 66 reqs, Waiting: 10951 reqs, GPU KV cache usage: 26.3%, Prefix cache hit rate: 1.8%
INFO 07-22 15:16:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11985.0 tokens/s, Avg generation throughput: 399.2 tokens/s, Running: 69 reqs, Waiting: 10804 reqs, GPU KV cache usage: 24.4%, Prefix cache hit rate: 1.8%
INFO 07-22 15:16:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11449.6 tokens/s, Avg generation throughput: 398.0 tokens/s, Running: 63 reqs, Waiting: 10683 reqs, GPU KV cache usage: 25.4%, Prefix cache hit rate: 1.8%
INFO 07-22 15:16:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11701.8 tokens/s, Avg generation throughput: 375.6 tokens/s, Running: 60 reqs, Waiting: 10543 reqs, GPU KV cache usage: 26.6%, Prefix cache hit rate: 1.8%
INFO 07-22 15:16:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11701.2 tokens/s, Avg generation throughput: 367.3 tokens/s, Running: 68 reqs, Waiting: 10409 reqs, GPU KV cache usage: 29.2%, Prefix cache hit rate: 1.8%
INFO 07-22 15:16:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11647.9 tokens/s, Avg generation throughput: 397.0 tokens/s, Running: 73 reqs, Waiting: 10263 reqs, GPU KV cache usage: 28.0%, Prefix cache hit rate: 1.9%
INFO 07-22 15:16:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11745.6 tokens/s, Avg generation throughput: 415.4 tokens/s, Running: 66 reqs, Waiting: 10132 reqs, GPU KV cache usage: 26.9%, Prefix cache hit rate: 1.9%
INFO 07-22 15:17:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11683.8 tokens/s, Avg generation throughput: 358.1 tokens/s, Running: 55 reqs, Waiting: 9994 reqs, GPU KV cache usage: 24.4%, Prefix cache hit rate: 1.9%
INFO 07-22 15:17:13 [loggers.py:116] Engine 000: Avg prompt throughput: 12023.6 tokens/s, Avg generation throughput: 329.0 tokens/s, Running: 57 reqs, Waiting: 9855 reqs, GPU KV cache usage: 24.2%, Prefix cache hit rate: 1.9%
INFO 07-22 15:17:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11634.9 tokens/s, Avg generation throughput: 387.5 tokens/s, Running: 73 reqs, Waiting: 9710 reqs, GPU KV cache usage: 29.0%, Prefix cache hit rate: 1.9%
INFO 07-22 15:17:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11505.4 tokens/s, Avg generation throughput: 414.9 tokens/s, Running: 65 reqs, Waiting: 9586 reqs, GPU KV cache usage: 28.1%, Prefix cache hit rate: 1.9%
INFO 07-22 15:17:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11999.0 tokens/s, Avg generation throughput: 344.9 tokens/s, Running: 48 reqs, Waiting: 9448 reqs, GPU KV cache usage: 22.2%, Prefix cache hit rate: 1.9%
INFO 07-22 15:17:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11898.3 tokens/s, Avg generation throughput: 284.7 tokens/s, Running: 56 reqs, Waiting: 9314 reqs, GPU KV cache usage: 24.4%, Prefix cache hit rate: 1.8%
INFO 07-22 15:18:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11765.8 tokens/s, Avg generation throughput: 351.7 tokens/s, Running: 60 reqs, Waiting: 9185 reqs, GPU KV cache usage: 25.9%, Prefix cache hit rate: 1.8%
INFO 07-22 15:18:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11681.2 tokens/s, Avg generation throughput: 374.1 tokens/s, Running: 61 reqs, Waiting: 9047 reqs, GPU KV cache usage: 26.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:18:23 [loggers.py:116] Engine 000: Avg prompt throughput: 12118.1 tokens/s, Avg generation throughput: 339.0 tokens/s, Running: 52 reqs, Waiting: 8910 reqs, GPU KV cache usage: 23.0%, Prefix cache hit rate: 1.8%
INFO 07-22 15:18:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11733.8 tokens/s, Avg generation throughput: 330.6 tokens/s, Running: 60 reqs, Waiting: 8781 reqs, GPU KV cache usage: 27.0%, Prefix cache hit rate: 1.8%
INFO 07-22 15:18:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11754.0 tokens/s, Avg generation throughput: 343.1 tokens/s, Running: 65 reqs, Waiting: 8648 reqs, GPU KV cache usage: 29.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:18:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11698.7 tokens/s, Avg generation throughput: 368.5 tokens/s, Running: 63 reqs, Waiting: 8518 reqs, GPU KV cache usage: 26.7%, Prefix cache hit rate: 1.8%
INFO 07-22 15:19:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11614.8 tokens/s, Avg generation throughput: 389.3 tokens/s, Running: 67 reqs, Waiting: 8386 reqs, GPU KV cache usage: 31.0%, Prefix cache hit rate: 1.8%
INFO 07-22 15:19:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11676.8 tokens/s, Avg generation throughput: 382.9 tokens/s, Running: 63 reqs, Waiting: 8252 reqs, GPU KV cache usage: 29.3%, Prefix cache hit rate: 1.8%
INFO 07-22 15:19:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11553.0 tokens/s, Avg generation throughput: 355.5 tokens/s, Running: 62 reqs, Waiting: 8123 reqs, GPU KV cache usage: 29.4%, Prefix cache hit rate: 1.8%
INFO 07-22 15:19:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11975.6 tokens/s, Avg generation throughput: 354.3 tokens/s, Running: 62 reqs, Waiting: 7992 reqs, GPU KV cache usage: 26.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:19:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11777.0 tokens/s, Avg generation throughput: 378.4 tokens/s, Running: 63 reqs, Waiting: 7853 reqs, GPU KV cache usage: 24.3%, Prefix cache hit rate: 1.8%
INFO 07-22 15:19:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11648.6 tokens/s, Avg generation throughput: 395.3 tokens/s, Running: 64 reqs, Waiting: 7722 reqs, GPU KV cache usage: 25.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:20:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11690.5 tokens/s, Avg generation throughput: 368.0 tokens/s, Running: 61 reqs, Waiting: 7586 reqs, GPU KV cache usage: 27.9%, Prefix cache hit rate: 1.8%
INFO 07-22 15:20:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11850.1 tokens/s, Avg generation throughput: 335.0 tokens/s, Running: 62 reqs, Waiting: 7459 reqs, GPU KV cache usage: 30.0%, Prefix cache hit rate: 1.8%
INFO 07-22 15:20:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11505.6 tokens/s, Avg generation throughput: 380.1 tokens/s, Running: 67 reqs, Waiting: 7331 reqs, GPU KV cache usage: 30.5%, Prefix cache hit rate: 1.8%
INFO 07-22 15:20:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11452.6 tokens/s, Avg generation throughput: 385.4 tokens/s, Running: 66 reqs, Waiting: 7201 reqs, GPU KV cache usage: 29.3%, Prefix cache hit rate: 1.8%
INFO 07-22 15:20:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11683.4 tokens/s, Avg generation throughput: 434.4 tokens/s, Running: 77 reqs, Waiting: 7057 reqs, GPU KV cache usage: 31.6%, Prefix cache hit rate: 1.8%
INFO 07-22 15:20:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11466.2 tokens/s, Avg generation throughput: 448.0 tokens/s, Running: 73 reqs, Waiting: 6923 reqs, GPU KV cache usage: 29.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:21:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11725.5 tokens/s, Avg generation throughput: 392.6 tokens/s, Running: 64 reqs, Waiting: 6790 reqs, GPU KV cache usage: 24.4%, Prefix cache hit rate: 1.8%
INFO 07-22 15:21:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11698.9 tokens/s, Avg generation throughput: 377.3 tokens/s, Running: 71 reqs, Waiting: 6664 reqs, GPU KV cache usage: 30.8%, Prefix cache hit rate: 1.8%
INFO 07-22 15:21:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11525.5 tokens/s, Avg generation throughput: 406.1 tokens/s, Running: 70 reqs, Waiting: 6533 reqs, GPU KV cache usage: 31.7%, Prefix cache hit rate: 1.8%
INFO 07-22 15:21:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11482.5 tokens/s, Avg generation throughput: 425.7 tokens/s, Running: 73 reqs, Waiting: 6396 reqs, GPU KV cache usage: 29.7%, Prefix cache hit rate: 1.8%
INFO 07-22 15:21:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11678.2 tokens/s, Avg generation throughput: 404.3 tokens/s, Running: 63 reqs, Waiting: 6263 reqs, GPU KV cache usage: 24.6%, Prefix cache hit rate: 1.9%
INFO 07-22 15:21:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11973.5 tokens/s, Avg generation throughput: 348.3 tokens/s, Running: 50 reqs, Waiting: 6124 reqs, GPU KV cache usage: 19.5%, Prefix cache hit rate: 1.8%
INFO 07-22 15:22:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11797.2 tokens/s, Avg generation throughput: 339.2 tokens/s, Running: 63 reqs, Waiting: 5986 reqs, GPU KV cache usage: 26.5%, Prefix cache hit rate: 1.8%
INFO 07-22 15:22:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11658.8 tokens/s, Avg generation throughput: 372.2 tokens/s, Running: 68 reqs, Waiting: 5851 reqs, GPU KV cache usage: 29.0%, Prefix cache hit rate: 1.8%
INFO 07-22 15:22:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11794.8 tokens/s, Avg generation throughput: 388.4 tokens/s, Running: 57 reqs, Waiting: 5716 reqs, GPU KV cache usage: 21.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:22:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11899.9 tokens/s, Avg generation throughput: 359.7 tokens/s, Running: 59 reqs, Waiting: 5580 reqs, GPU KV cache usage: 23.9%, Prefix cache hit rate: 1.9%
INFO 07-22 15:22:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11712.5 tokens/s, Avg generation throughput: 330.9 tokens/s, Running: 56 reqs, Waiting: 5449 reqs, GPU KV cache usage: 23.5%, Prefix cache hit rate: 1.8%
INFO 07-22 15:22:53 [loggers.py:116] Engine 000: Avg prompt throughput: 12027.1 tokens/s, Avg generation throughput: 316.6 tokens/s, Running: 54 reqs, Waiting: 5314 reqs, GPU KV cache usage: 22.7%, Prefix cache hit rate: 1.8%
INFO 07-22 15:23:03 [loggers.py:116] Engine 000: Avg prompt throughput: 12012.5 tokens/s, Avg generation throughput: 339.8 tokens/s, Running: 61 reqs, Waiting: 5179 reqs, GPU KV cache usage: 24.7%, Prefix cache hit rate: 1.8%
INFO 07-22 15:23:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11536.4 tokens/s, Avg generation throughput: 404.0 tokens/s, Running: 75 reqs, Waiting: 5043 reqs, GPU KV cache usage: 29.6%, Prefix cache hit rate: 1.8%
INFO 07-22 15:23:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11625.5 tokens/s, Avg generation throughput: 434.6 tokens/s, Running: 74 reqs, Waiting: 4910 reqs, GPU KV cache usage: 31.7%, Prefix cache hit rate: 1.8%
INFO 07-22 15:23:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11531.9 tokens/s, Avg generation throughput: 418.8 tokens/s, Running: 72 reqs, Waiting: 4777 reqs, GPU KV cache usage: 31.8%, Prefix cache hit rate: 1.8%
INFO 07-22 15:23:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11376.8 tokens/s, Avg generation throughput: 402.6 tokens/s, Running: 71 reqs, Waiting: 4649 reqs, GPU KV cache usage: 30.3%, Prefix cache hit rate: 1.8%
INFO 07-22 15:23:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11557.8 tokens/s, Avg generation throughput: 429.3 tokens/s, Running: 75 reqs, Waiting: 4515 reqs, GPU KV cache usage: 32.2%, Prefix cache hit rate: 1.8%
INFO 07-22 15:24:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11446.9 tokens/s, Avg generation throughput: 422.2 tokens/s, Running: 73 reqs, Waiting: 4378 reqs, GPU KV cache usage: 28.8%, Prefix cache hit rate: 1.9%
INFO 07-22 15:24:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11746.3 tokens/s, Avg generation throughput: 399.2 tokens/s, Running: 60 reqs, Waiting: 4244 reqs, GPU KV cache usage: 22.5%, Prefix cache hit rate: 1.8%
INFO 07-22 15:24:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11920.1 tokens/s, Avg generation throughput: 386.6 tokens/s, Running: 61 reqs, Waiting: 4104 reqs, GPU KV cache usage: 23.5%, Prefix cache hit rate: 1.9%
INFO 07-22 15:24:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11746.0 tokens/s, Avg generation throughput: 353.9 tokens/s, Running: 63 reqs, Waiting: 3972 reqs, GPU KV cache usage: 27.4%, Prefix cache hit rate: 1.8%
INFO 07-22 15:24:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11519.8 tokens/s, Avg generation throughput: 366.0 tokens/s, Running: 64 reqs, Waiting: 3847 reqs, GPU KV cache usage: 30.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:24:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11733.6 tokens/s, Avg generation throughput: 386.2 tokens/s, Running: 66 reqs, Waiting: 3718 reqs, GPU KV cache usage: 29.3%, Prefix cache hit rate: 1.8%
INFO 07-22 15:25:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11713.0 tokens/s, Avg generation throughput: 392.8 tokens/s, Running: 69 reqs, Waiting: 3578 reqs, GPU KV cache usage: 29.6%, Prefix cache hit rate: 1.8%
INFO 07-22 15:25:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11525.4 tokens/s, Avg generation throughput: 386.0 tokens/s, Running: 59 reqs, Waiting: 3450 reqs, GPU KV cache usage: 25.2%, Prefix cache hit rate: 1.8%
INFO 07-22 15:25:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11654.1 tokens/s, Avg generation throughput: 354.1 tokens/s, Running: 57 reqs, Waiting: 3311 reqs, GPU KV cache usage: 25.3%, Prefix cache hit rate: 1.8%
INFO 07-22 15:25:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11940.4 tokens/s, Avg generation throughput: 335.4 tokens/s, Running: 58 reqs, Waiting: 3174 reqs, GPU KV cache usage: 26.8%, Prefix cache hit rate: 1.8%
INFO 07-22 15:25:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11784.2 tokens/s, Avg generation throughput: 340.6 tokens/s, Running: 61 reqs, Waiting: 3043 reqs, GPU KV cache usage: 27.9%, Prefix cache hit rate: 1.8%
INFO 07-22 15:25:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11783.4 tokens/s, Avg generation throughput: 378.8 tokens/s, Running: 70 reqs, Waiting: 2899 reqs, GPU KV cache usage: 27.7%, Prefix cache hit rate: 1.8%
INFO 07-22 15:26:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11725.8 tokens/s, Avg generation throughput: 428.0 tokens/s, Running: 71 reqs, Waiting: 2753 reqs, GPU KV cache usage: 27.6%, Prefix cache hit rate: 1.9%
INFO 07-22 15:26:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11592.0 tokens/s, Avg generation throughput: 413.4 tokens/s, Running: 65 reqs, Waiting: 2620 reqs, GPU KV cache usage: 26.3%, Prefix cache hit rate: 1.9%
INFO 07-22 15:26:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11770.9 tokens/s, Avg generation throughput: 369.5 tokens/s, Running: 62 reqs, Waiting: 2487 reqs, GPU KV cache usage: 25.2%, Prefix cache hit rate: 1.9%
INFO 07-22 15:26:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11789.4 tokens/s, Avg generation throughput: 389.0 tokens/s, Running: 68 reqs, Waiting: 2344 reqs, GPU KV cache usage: 27.1%, Prefix cache hit rate: 1.9%
INFO 07-22 15:26:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11638.7 tokens/s, Avg generation throughput: 407.4 tokens/s, Running: 67 reqs, Waiting: 2213 reqs, GPU KV cache usage: 29.1%, Prefix cache hit rate: 1.9%
INFO 07-22 15:26:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11558.7 tokens/s, Avg generation throughput: 372.1 tokens/s, Running: 63 reqs, Waiting: 2080 reqs, GPU KV cache usage: 27.6%, Prefix cache hit rate: 1.9%
INFO 07-22 15:27:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11726.1 tokens/s, Avg generation throughput: 362.3 tokens/s, Running: 61 reqs, Waiting: 1954 reqs, GPU KV cache usage: 27.9%, Prefix cache hit rate: 1.9%
INFO 07-22 15:27:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11730.7 tokens/s, Avg generation throughput: 382.7 tokens/s, Running: 67 reqs, Waiting: 1820 reqs, GPU KV cache usage: 30.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:27:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11522.4 tokens/s, Avg generation throughput: 395.9 tokens/s, Running: 72 reqs, Waiting: 1686 reqs, GPU KV cache usage: 30.5%, Prefix cache hit rate: 1.8%
INFO 07-22 15:27:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11470.3 tokens/s, Avg generation throughput: 412.3 tokens/s, Running: 75 reqs, Waiting: 1551 reqs, GPU KV cache usage: 31.5%, Prefix cache hit rate: 1.8%
INFO 07-22 15:27:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11454.5 tokens/s, Avg generation throughput: 447.6 tokens/s, Running: 76 reqs, Waiting: 1417 reqs, GPU KV cache usage: 30.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:27:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11697.4 tokens/s, Avg generation throughput: 435.1 tokens/s, Running: 68 reqs, Waiting: 1282 reqs, GPU KV cache usage: 27.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:28:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11400.4 tokens/s, Avg generation throughput: 399.3 tokens/s, Running: 74 reqs, Waiting: 1154 reqs, GPU KV cache usage: 33.1%, Prefix cache hit rate: 1.8%
INFO 07-22 15:28:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11530.6 tokens/s, Avg generation throughput: 444.4 tokens/s, Running: 74 reqs, Waiting: 1021 reqs, GPU KV cache usage: 32.2%, Prefix cache hit rate: 1.8%
INFO 07-22 15:28:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11370.5 tokens/s, Avg generation throughput: 420.9 tokens/s, Running: 67 reqs, Waiting: 899 reqs, GPU KV cache usage: 26.8%, Prefix cache hit rate: 1.8%
INFO 07-22 15:28:33 [loggers.py:116] Engine 000: Avg prompt throughput: 11810.3 tokens/s, Avg generation throughput: 384.7 tokens/s, Running: 61 reqs, Waiting: 757 reqs, GPU KV cache usage: 21.9%, Prefix cache hit rate: 1.8%
INFO 07-22 15:28:43 [loggers.py:116] Engine 000: Avg prompt throughput: 11882.5 tokens/s, Avg generation throughput: 397.3 tokens/s, Running: 66 reqs, Waiting: 610 reqs, GPU KV cache usage: 26.0%, Prefix cache hit rate: 1.9%
INFO 07-22 15:28:53 [loggers.py:116] Engine 000: Avg prompt throughput: 11717.8 tokens/s, Avg generation throughput: 375.0 tokens/s, Running: 64 reqs, Waiting: 470 reqs, GPU KV cache usage: 25.7%, Prefix cache hit rate: 1.9%
INFO 07-22 15:29:03 [loggers.py:116] Engine 000: Avg prompt throughput: 11754.4 tokens/s, Avg generation throughput: 382.9 tokens/s, Running: 68 reqs, Waiting: 338 reqs, GPU KV cache usage: 30.4%, Prefix cache hit rate: 1.9%
INFO 07-22 15:29:13 [loggers.py:116] Engine 000: Avg prompt throughput: 11536.0 tokens/s, Avg generation throughput: 395.8 tokens/s, Running: 66 reqs, Waiting: 222 reqs, GPU KV cache usage: 34.0%, Prefix cache hit rate: 1.8%
INFO 07-22 15:29:23 [loggers.py:116] Engine 000: Avg prompt throughput: 11466.0 tokens/s, Avg generation throughput: 364.2 tokens/s, Running: 59 reqs, Waiting: 87 reqs, GPU KV cache usage: 26.2%, Prefix cache hit rate: 1.8%
INFO 07-22 15:29:33 [loggers.py:116] Engine 000: Avg prompt throughput: 7431.7 tokens/s, Avg generation throughput: 582.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 1.8%
INFO:     127.0.0.1:51760 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 07-22 15:29:43 [loggers.py:116] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 1.8%
INFO 07-22 15:31:42 [launcher.py:79] Shutting down FastAPI HTTP server.
[rank0]:[W722 15:31:43.887357632 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
