INFO 07-22 21:04:17 [__init__.py:243] Automatically detected platform cuda.
INFO 07-22 21:04:23 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 07-22 21:04:23 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 07-22 21:04:23 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 07-22 21:04:24 [api_server.py:1289] vLLM API server version 0.9.0.1
INFO 07-22 21:04:24 [cli_args.py:300] non-default args: {'block_size': 16, 'kv_cache_dtype': 'fp8', 'max_num_batched_tokens': 8192, 'max_num_seqs': 384, 'max_num_partial_prefills': 8, 'cuda_graph_sizes': [7176], 'long_prefill_token_threshold': 256, 'enable_chunked_prefill': True}
INFO 07-22 21:04:34 [config.py:793] This model supports multiple tasks: {'classify', 'embed', 'generate', 'score', 'reward'}. Defaulting to 'generate'.
WARNING 07-22 21:04:35 [arg_utils.py:1583] --kv-cache-dtype is not supported by the V1 Engine. Falling back to V0. 
INFO 07-22 21:04:35 [config.py:1503] Using fp8 data type to store kv cache. It reduces the GPU memory footprint and boosts the performance. Meanwhile, it may cause accuracy drop without a proper scaling factor
INFO 07-22 21:04:35 [config.py:2118] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 07-22 21:04:35 [config.py:2128] Concurrent partial prefills enabled with max_num_partial_prefills=8, max_long_partial_prefills=1, long_prefill_token_threshold=256
INFO 07-22 21:04:35 [api_server.py:257] Started engine process with PID 235864
INFO 07-22 21:04:38 [__init__.py:243] Automatically detected platform cuda.
INFO 07-22 21:04:41 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 07-22 21:04:41 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 07-22 21:04:41 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 07-22 21:04:41 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.0.1) with config: model='meta-llama/Llama-3.1-8B', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=fp8,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.1-8B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"compile_sizes": [], "inductor_compile_config": {"enable_auto_functionalized_v2": false}, "cudagraph_capture_sizes": [384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], "max_capture_size": 384}, use_cached_outputs=True, 
INFO 07-22 21:04:43 [cuda.py:273] Cannot use FlashAttention backend for FP8 KV cache.
WARNING 07-22 21:04:43 [cuda.py:275] Please use FlashInfer backend with FP8 KV Cache for better performance by setting environment variable VLLM_ATTENTION_BACKEND=FLASHINFER
INFO 07-22 21:04:43 [cuda.py:289] Using XFormers backend.
INFO 07-22 21:04:49 [parallel_state.py:1064] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
INFO 07-22 21:04:49 [model_runner.py:1170] Starting to load model meta-llama/Llama-3.1-8B...
INFO 07-22 21:04:50 [weight_utils.py:291] Using model weights format ['*.safetensors']
INFO 07-22 21:04:51 [weight_utils.py:307] Time spent downloading weights for meta-llama/Llama-3.1-8B: 0.593013 seconds
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:00,  6.60it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.11it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.70it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.54it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.73it/s]

INFO 07-22 21:04:54 [default_loader.py:280] Loading weights took 2.37 seconds
INFO 07-22 21:04:54 [model_runner.py:1202] Model loading took 14.9889 GiB and 4.709025 seconds
INFO 07-22 21:04:55 [worker.py:291] Memory profiling takes 1.01 seconds
INFO 07-22 21:04:55 [worker.py:291] the current vLLM instance can use total_gpu_memory (44.52GiB) x gpu_memory_utilization (0.90) = 40.07GiB
INFO 07-22 21:04:55 [worker.py:291] model weights take 14.99GiB; non_torch_memory takes 0.08GiB; PyTorch activation peak memory takes 1.81GiB; the rest of the memory reserved for KV Cache is 23.18GiB.
INFO 07-22 21:04:55 [executor_base.py:112] # cuda blocks: 23739, # CPU blocks: 4096
INFO 07-22 21:04:55 [executor_base.py:117] Maximum concurrency for 131072 tokens per request: 2.90x
INFO 07-22 21:04:56 [model_runner.py:1512] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graph shapes:   2%|▏         | 1/51 [00:00<00:24,  2.01it/s]Capturing CUDA graph shapes:   4%|▍         | 2/51 [00:00<00:23,  2.11it/s]Capturing CUDA graph shapes:   6%|▌         | 3/51 [00:01<00:21,  2.19it/s]Capturing CUDA graph shapes:   8%|▊         | 4/51 [00:01<00:20,  2.28it/s]Capturing CUDA graph shapes:  10%|▉         | 5/51 [00:02<00:20,  2.23it/s]Capturing CUDA graph shapes:  12%|█▏        | 6/51 [00:02<00:19,  2.27it/s]Capturing CUDA graph shapes:  14%|█▎        | 7/51 [00:03<00:19,  2.29it/s]Capturing CUDA graph shapes:  16%|█▌        | 8/51 [00:03<00:18,  2.27it/s]Capturing CUDA graph shapes:  18%|█▊        | 9/51 [00:03<00:18,  2.33it/s]Capturing CUDA graph shapes:  20%|█▉        | 10/51 [00:04<00:17,  2.35it/s]Capturing CUDA graph shapes:  22%|██▏       | 11/51 [00:04<00:17,  2.32it/s]Capturing CUDA graph shapes:  24%|██▎       | 12/51 [00:05<00:17,  2.29it/s]Capturing CUDA graph shapes:  25%|██▌       | 13/51 [00:05<00:16,  2.27it/s]Capturing CUDA graph shapes:  27%|██▋       | 14/51 [00:06<00:16,  2.29it/s]Capturing CUDA graph shapes:  29%|██▉       | 15/51 [00:06<00:15,  2.29it/s]Capturing CUDA graph shapes:  31%|███▏      | 16/51 [00:07<00:15,  2.25it/s]Capturing CUDA graph shapes:  33%|███▎      | 17/51 [00:07<00:14,  2.28it/s]Capturing CUDA graph shapes:  35%|███▌      | 18/51 [00:07<00:14,  2.35it/s]Capturing CUDA graph shapes:  37%|███▋      | 19/51 [00:08<00:14,  2.28it/s]Capturing CUDA graph shapes:  39%|███▉      | 20/51 [00:08<00:13,  2.32it/s]Capturing CUDA graph shapes:  41%|████      | 21/51 [00:09<00:12,  2.33it/s]Capturing CUDA graph shapes:  43%|████▎     | 22/51 [00:09<00:12,  2.32it/s]Capturing CUDA graph shapes:  45%|████▌     | 23/51 [00:10<00:11,  2.33it/s]Capturing CUDA graph shapes:  47%|████▋     | 24/51 [00:10<00:11,  2.36it/s]Capturing CUDA graph shapes:  49%|████▉     | 25/51 [00:10<00:11,  2.35it/s]Capturing CUDA graph shapes:  51%|█████     | 26/51 [00:11<00:10,  2.37it/s]Capturing CUDA graph shapes:  53%|█████▎    | 27/51 [00:11<00:10,  2.37it/s]Capturing CUDA graph shapes:  55%|█████▍    | 28/51 [00:12<00:09,  2.34it/s]Capturing CUDA graph shapes:  57%|█████▋    | 29/51 [00:12<00:09,  2.40it/s]Capturing CUDA graph shapes:  59%|█████▉    | 30/51 [00:12<00:08,  2.37it/s]Capturing CUDA graph shapes:  61%|██████    | 31/51 [00:13<00:08,  2.40it/s]Capturing CUDA graph shapes:  63%|██████▎   | 32/51 [00:13<00:07,  2.45it/s]Capturing CUDA graph shapes:  65%|██████▍   | 33/51 [00:14<00:07,  2.42it/s]Capturing CUDA graph shapes:  67%|██████▋   | 34/51 [00:14<00:06,  2.46it/s]Capturing CUDA graph shapes:  69%|██████▊   | 35/51 [00:15<00:06,  2.41it/s]Capturing CUDA graph shapes:  71%|███████   | 36/51 [00:15<00:06,  2.44it/s]Capturing CUDA graph shapes:  73%|███████▎  | 37/51 [00:15<00:05,  2.46it/s]Capturing CUDA graph shapes:  75%|███████▍  | 38/51 [00:16<00:05,  2.45it/s]Capturing CUDA graph shapes:  76%|███████▋  | 39/51 [00:16<00:04,  2.42it/s]Capturing CUDA graph shapes:  78%|███████▊  | 40/51 [00:17<00:04,  2.37it/s]Capturing CUDA graph shapes:  80%|████████  | 41/51 [00:17<00:04,  2.37it/s]Capturing CUDA graph shapes:  82%|████████▏ | 42/51 [00:17<00:03,  2.43it/s]Capturing CUDA graph shapes:  84%|████████▍ | 43/51 [00:18<00:03,  2.42it/s]Capturing CUDA graph shapes:  86%|████████▋ | 44/51 [00:18<00:02,  2.44it/s]Capturing CUDA graph shapes:  88%|████████▊ | 45/51 [00:19<00:02,  2.47it/s]Capturing CUDA graph shapes:  90%|█████████ | 46/51 [00:19<00:02,  2.48it/s]Capturing CUDA graph shapes:  92%|█████████▏| 47/51 [00:19<00:01,  2.47it/s]Capturing CUDA graph shapes:  94%|█████████▍| 48/51 [00:20<00:01,  2.47it/s]Capturing CUDA graph shapes:  96%|█████████▌| 49/51 [00:20<00:00,  2.51it/s]Capturing CUDA graph shapes:  98%|█████████▊| 50/51 [00:21<00:00,  2.53it/s]Capturing CUDA graph shapes: 100%|██████████| 51/51 [00:21<00:00,  2.43it/s]Capturing CUDA graph shapes: 100%|██████████| 51/51 [00:21<00:00,  2.36it/s]
INFO 07-22 21:05:18 [model_runner.py:1670] Graph capturing finished in 22 secs, took 0.34 GiB
INFO 07-22 21:05:18 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 24.14 seconds
WARNING 07-22 21:05:19 [config.py:1339] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 07-22 21:05:19 [serving_chat.py:117] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 07-22 21:05:19 [serving_completion.py:65] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 07-22 21:05:19 [api_server.py:1336] Starting vLLM API server on http://0.0.0.0:8000
INFO 07-22 21:05:19 [launcher.py:28] Available routes are:
INFO 07-22 21:05:19 [launcher.py:36] Route: /openapi.json, Methods: HEAD, GET
INFO 07-22 21:05:19 [launcher.py:36] Route: /docs, Methods: HEAD, GET
INFO 07-22 21:05:19 [launcher.py:36] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 07-22 21:05:19 [launcher.py:36] Route: /redoc, Methods: HEAD, GET
INFO 07-22 21:05:19 [launcher.py:36] Route: /health, Methods: GET
INFO 07-22 21:05:19 [launcher.py:36] Route: /load, Methods: GET
INFO 07-22 21:05:19 [launcher.py:36] Route: /ping, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /ping, Methods: GET
INFO 07-22 21:05:19 [launcher.py:36] Route: /tokenize, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /detokenize, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /v1/models, Methods: GET
INFO 07-22 21:05:19 [launcher.py:36] Route: /version, Methods: GET
INFO 07-22 21:05:19 [launcher.py:36] Route: /v1/chat/completions, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /v1/completions, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /v1/embeddings, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /pooling, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /classify, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /score, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /v1/score, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /v1/audio/transcriptions, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /rerank, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /v1/rerank, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /v2/rerank, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /invocations, Methods: POST
INFO 07-22 21:05:19 [launcher.py:36] Route: /metrics, Methods: GET
INFO:     Started server process [235563]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
ERROR 07-22 21:05:29 [client.py:306] RuntimeError('Engine process (pid 235864) died.')
ERROR 07-22 21:05:29 [client.py:306] NoneType: None
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [235563]
/root/.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/multiprocessing/resource_tracker.py:279: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
