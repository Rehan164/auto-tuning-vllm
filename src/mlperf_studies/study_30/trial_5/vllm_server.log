INFO 07-23 06:05:13 [__init__.py:243] Automatically detected platform cuda.
INFO 07-23 06:05:20 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 07-23 06:05:20 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 07-23 06:05:20 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 07-23 06:05:21 [api_server.py:1289] vLLM API server version 0.9.0.1
INFO 07-23 06:05:21 [cli_args.py:300] non-default args: {'max_model_len': 8192, 'block_size': 16, 'gpu_memory_utilization': 0.91, 'kv_cache_dtype': 'fp8', 'max_num_batched_tokens': 16384, 'max_num_seqs': 512, 'cuda_graph_sizes': [1032], 'long_prefill_token_threshold': 1024, 'disable_log_requests': True}
INFO 07-23 06:05:31 [config.py:793] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate', 'score'}. Defaulting to 'generate'.
WARNING 07-23 06:05:31 [arg_utils.py:1583] --kv-cache-dtype is not supported by the V1 Engine. Falling back to V0. 
INFO 07-23 06:05:31 [config.py:1503] Using fp8 data type to store kv cache. It reduces the GPU memory footprint and boosts the performance. Meanwhile, it may cause accuracy drop without a proper scaling factor
INFO 07-23 06:05:31 [api_server.py:257] Started engine process with PID 273486
INFO 07-23 06:05:35 [__init__.py:243] Automatically detected platform cuda.
INFO 07-23 06:05:38 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 07-23 06:05:38 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 07-23 06:05:38 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 07-23 06:05:38 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.0.1) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=fp8,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, pooler_config=None, compilation_config={"compile_sizes": [], "inductor_compile_config": {"enable_auto_functionalized_v2": false}, "cudagraph_capture_sizes": [512, 504, 496, 488, 480, 472, 464, 456, 448, 440, 432, 424, 416, 408, 400, 392, 384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], "max_capture_size": 512}, use_cached_outputs=True, 
INFO 07-23 06:05:40 [cuda.py:273] Cannot use FlashAttention backend for FP8 KV cache.
WARNING 07-23 06:05:40 [cuda.py:275] Please use FlashInfer backend with FP8 KV Cache for better performance by setting environment variable VLLM_ATTENTION_BACKEND=FLASHINFER
INFO 07-23 06:05:40 [cuda.py:289] Using XFormers backend.
INFO 07-23 06:05:46 [parallel_state.py:1064] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
INFO 07-23 06:05:46 [model_runner.py:1170] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 07-23 06:05:47 [weight_utils.py:291] Using model weights format ['*.safetensors']
INFO 07-23 06:05:48 [weight_utils.py:307] Time spent downloading weights for meta-llama/Llama-3.1-8B-Instruct: 0.610373 seconds
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.59it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.52it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.49it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  2.07it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.83it/s]

INFO 07-23 06:05:50 [default_loader.py:280] Loading weights took 2.20 seconds
INFO 07-23 06:05:51 [model_runner.py:1202] Model loading took 14.9889 GiB and 4.633704 seconds
INFO 07-23 06:05:52 [worker.py:291] Memory profiling takes 1.63 seconds
INFO 07-23 06:05:52 [worker.py:291] the current vLLM instance can use total_gpu_memory (44.52GiB) x gpu_memory_utilization (0.91) = 40.51GiB
INFO 07-23 06:05:52 [worker.py:291] model weights take 14.99GiB; non_torch_memory takes 0.08GiB; PyTorch activation peak memory takes 2.46GiB; the rest of the memory reserved for KV Cache is 22.98GiB.
INFO 07-23 06:05:53 [executor_base.py:112] # cuda blocks: 23535, # CPU blocks: 4096
INFO 07-23 06:05:53 [executor_base.py:117] Maximum concurrency for 8192 tokens per request: 45.97x
INFO 07-23 06:05:54 [model_runner.py:1512] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|▏         | 1/67 [00:00<00:33,  1.97it/s]Capturing CUDA graph shapes:   3%|▎         | 2/67 [00:00<00:29,  2.19it/s]Capturing CUDA graph shapes:   4%|▍         | 3/67 [00:01<00:28,  2.23it/s]Capturing CUDA graph shapes:   6%|▌         | 4/67 [00:01<00:27,  2.25it/s]Capturing CUDA graph shapes:   7%|▋         | 5/67 [00:02<00:27,  2.24it/s]Capturing CUDA graph shapes:   9%|▉         | 6/67 [00:02<00:27,  2.22it/s]Capturing CUDA graph shapes:  10%|█         | 7/67 [00:03<00:27,  2.20it/s]Capturing CUDA graph shapes:  12%|█▏        | 8/67 [00:03<00:27,  2.18it/s]Capturing CUDA graph shapes:  13%|█▎        | 9/67 [00:04<00:25,  2.24it/s]Capturing CUDA graph shapes:  15%|█▍        | 10/67 [00:04<00:25,  2.22it/s]Capturing CUDA graph shapes:  16%|█▋        | 11/67 [00:04<00:24,  2.28it/s]Capturing CUDA graph shapes:  18%|█▊        | 12/67 [00:05<00:23,  2.32it/s]Capturing CUDA graph shapes:  19%|█▉        | 13/67 [00:05<00:23,  2.34it/s]Capturing CUDA graph shapes:  21%|██        | 14/67 [00:06<00:22,  2.38it/s]Capturing CUDA graph shapes:  22%|██▏       | 15/67 [00:06<00:22,  2.35it/s]Capturing CUDA graph shapes:  24%|██▍       | 16/67 [00:07<00:22,  2.28it/s]Capturing CUDA graph shapes:  25%|██▌       | 17/67 [00:07<00:22,  2.25it/s]Capturing CUDA graph shapes:  27%|██▋       | 18/67 [00:07<00:21,  2.32it/s]Capturing CUDA graph shapes:  28%|██▊       | 19/67 [00:08<00:20,  2.30it/s]Capturing CUDA graph shapes:  30%|██▉       | 20/67 [00:08<00:20,  2.28it/s]Capturing CUDA graph shapes:  31%|███▏      | 21/67 [00:09<00:20,  2.25it/s]Capturing CUDA graph shapes:  33%|███▎      | 22/67 [00:09<00:19,  2.32it/s]Capturing CUDA graph shapes:  34%|███▍      | 23/67 [00:10<00:18,  2.38it/s]Capturing CUDA graph shapes:  36%|███▌      | 24/67 [00:10<00:18,  2.33it/s]Capturing CUDA graph shapes:  37%|███▋      | 25/67 [00:10<00:17,  2.36it/s]Capturing CUDA graph shapes:  39%|███▉      | 26/67 [00:11<00:17,  2.34it/s]Capturing CUDA graph shapes:  40%|████      | 27/67 [00:11<00:16,  2.36it/s]Capturing CUDA graph shapes:  42%|████▏     | 28/67 [00:12<00:16,  2.41it/s]Capturing CUDA graph shapes:  43%|████▎     | 29/67 [00:12<00:15,  2.38it/s]Capturing CUDA graph shapes:  45%|████▍     | 30/67 [00:13<00:15,  2.35it/s]Capturing CUDA graph shapes:  46%|████▋     | 31/67 [00:13<00:15,  2.37it/s]Capturing CUDA graph shapes:  48%|████▊     | 32/67 [00:13<00:14,  2.36it/s]Capturing CUDA graph shapes:  49%|████▉     | 33/67 [00:14<00:14,  2.37it/s]Capturing CUDA graph shapes:  51%|█████     | 34/67 [00:14<00:13,  2.42it/s]Capturing CUDA graph shapes:  52%|█████▏    | 35/67 [00:15<00:13,  2.45it/s]Capturing CUDA graph shapes:  54%|█████▎    | 36/67 [00:15<00:12,  2.45it/s]Capturing CUDA graph shapes:  55%|█████▌    | 37/67 [00:15<00:12,  2.42it/s]Capturing CUDA graph shapes:  57%|█████▋    | 38/67 [00:16<00:11,  2.43it/s]Capturing CUDA graph shapes:  58%|█████▊    | 39/67 [00:16<00:11,  2.43it/s]Capturing CUDA graph shapes:  60%|█████▉    | 40/67 [00:17<00:10,  2.46it/s]Capturing CUDA graph shapes:  61%|██████    | 41/67 [00:17<00:10,  2.44it/s]Capturing CUDA graph shapes:  63%|██████▎   | 42/67 [00:17<00:10,  2.46it/s]Capturing CUDA graph shapes:  64%|██████▍   | 43/67 [00:18<00:09,  2.49it/s]Capturing CUDA graph shapes:  66%|██████▌   | 44/67 [00:18<00:09,  2.46it/s]Capturing CUDA graph shapes:  67%|██████▋   | 45/67 [00:19<00:09,  2.42it/s]Capturing CUDA graph shapes:  69%|██████▊   | 46/67 [00:19<00:08,  2.45it/s]Capturing CUDA graph shapes:  70%|███████   | 47/67 [00:20<00:08,  2.46it/s]Capturing CUDA graph shapes:  72%|███████▏  | 48/67 [00:20<00:07,  2.43it/s]Capturing CUDA graph shapes:  73%|███████▎  | 49/67 [00:20<00:07,  2.48it/s]Capturing CUDA graph shapes:  75%|███████▍  | 50/67 [00:21<00:06,  2.49it/s]Capturing CUDA graph shapes:  76%|███████▌  | 51/67 [00:21<00:06,  2.50it/s]Capturing CUDA graph shapes:  78%|███████▊  | 52/67 [00:22<00:05,  2.50it/s]Capturing CUDA graph shapes:  79%|███████▉  | 53/67 [00:22<00:05,  2.51it/s]Capturing CUDA graph shapes:  81%|████████  | 54/67 [00:22<00:05,  2.48it/s]Capturing CUDA graph shapes:  82%|████████▏ | 55/67 [00:23<00:04,  2.42it/s]Capturing CUDA graph shapes:  84%|████████▎ | 56/67 [00:23<00:04,  2.45it/s]Capturing CUDA graph shapes:  85%|████████▌ | 57/67 [00:24<00:04,  2.50it/s]Capturing CUDA graph shapes:  87%|████████▋ | 58/67 [00:24<00:03,  2.54it/s]Capturing CUDA graph shapes:  88%|████████▊ | 59/67 [00:24<00:03,  2.52it/s]Capturing CUDA graph shapes:  90%|████████▉ | 60/67 [00:25<00:02,  2.53it/s]Capturing CUDA graph shapes:  91%|█████████ | 61/67 [00:25<00:02,  2.57it/s]Capturing CUDA graph shapes:  93%|█████████▎| 62/67 [00:25<00:01,  2.60it/s]Capturing CUDA graph shapes:  94%|█████████▍| 63/67 [00:26<00:01,  2.53it/s]Capturing CUDA graph shapes:  96%|█████████▌| 64/67 [00:26<00:01,  2.54it/s]Capturing CUDA graph shapes:  97%|█████████▋| 65/67 [00:27<00:00,  2.58it/s]Capturing CUDA graph shapes:  99%|█████████▊| 66/67 [00:27<00:00,  2.59it/s]Capturing CUDA graph shapes: 100%|██████████| 67/67 [00:27<00:00,  2.57it/s]Capturing CUDA graph shapes: 100%|██████████| 67/67 [00:27<00:00,  2.40it/s]
INFO 07-23 06:06:22 [model_runner.py:1670] Graph capturing finished in 28 secs, took 0.43 GiB
INFO 07-23 06:06:22 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 31.55 seconds
WARNING 07-23 06:06:23 [config.py:1339] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 07-23 06:06:23 [serving_chat.py:117] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 07-23 06:06:24 [serving_completion.py:65] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 07-23 06:06:24 [api_server.py:1336] Starting vLLM API server on http://0.0.0.0:8000
INFO 07-23 06:06:24 [launcher.py:28] Available routes are:
INFO 07-23 06:06:24 [launcher.py:36] Route: /openapi.json, Methods: GET, HEAD
INFO 07-23 06:06:24 [launcher.py:36] Route: /docs, Methods: GET, HEAD
INFO 07-23 06:06:24 [launcher.py:36] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 07-23 06:06:24 [launcher.py:36] Route: /redoc, Methods: GET, HEAD
INFO 07-23 06:06:24 [launcher.py:36] Route: /health, Methods: GET
INFO 07-23 06:06:24 [launcher.py:36] Route: /load, Methods: GET
INFO 07-23 06:06:24 [launcher.py:36] Route: /ping, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /ping, Methods: GET
INFO 07-23 06:06:24 [launcher.py:36] Route: /tokenize, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /detokenize, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /v1/models, Methods: GET
INFO 07-23 06:06:24 [launcher.py:36] Route: /version, Methods: GET
INFO 07-23 06:06:24 [launcher.py:36] Route: /v1/chat/completions, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /v1/completions, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /v1/embeddings, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /pooling, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /classify, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /score, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /v1/score, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /v1/audio/transcriptions, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /rerank, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /v1/rerank, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /v2/rerank, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /invocations, Methods: POST
INFO 07-23 06:06:24 [launcher.py:36] Route: /metrics, Methods: GET
INFO:     Started server process [273194]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:59688 - "GET /health HTTP/1.1" 200 OK
INFO 07-23 06:09:26 [metrics.py:486] Avg prompt throughput: 1171.1 tokens/s, Avg generation throughput: 1.2 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 13336 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:09:31 [metrics.py:486] Avg prompt throughput: 12647.9 tokens/s, Avg generation throughput: 13.4 tokens/s, Running: 106 reqs, Swapped: 0 reqs, Pending: 13262 reqs, GPU KV cache usage: 25.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:09:36 [metrics.py:486] Avg prompt throughput: 12519.0 tokens/s, Avg generation throughput: 16.4 tokens/s, Running: 183 reqs, Swapped: 0 reqs, Pending: 13185 reqs, GPU KV cache usage: 42.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:09:41 [metrics.py:486] Avg prompt throughput: 12535.4 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 261 reqs, Swapped: 0 reqs, Pending: 13107 reqs, GPU KV cache usage: 59.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:09:47 [metrics.py:486] Avg prompt throughput: 12442.9 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 334 reqs, Swapped: 0 reqs, Pending: 13034 reqs, GPU KV cache usage: 76.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:09:52 [metrics.py:486] Avg prompt throughput: 12483.7 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 406 reqs, Swapped: 0 reqs, Pending: 12962 reqs, GPU KV cache usage: 93.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:09:56 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-425 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
INFO 07-23 06:09:57 [metrics.py:486] Avg prompt throughput: 6833.7 tokens/s, Avg generation throughput: 1768.3 tokens/s, Running: 421 reqs, Swapped: 0 reqs, Pending: 12947 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:02 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3196.8 tokens/s, Running: 404 reqs, Swapped: 0 reqs, Pending: 12964 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:07 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3681.2 tokens/s, Running: 386 reqs, Swapped: 0 reqs, Pending: 12982 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:13 [metrics.py:486] Avg prompt throughput: 7933.1 tokens/s, Avg generation throughput: 1271.6 tokens/s, Running: 64 reqs, Swapped: 0 reqs, Pending: 12924 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:18 [metrics.py:486] Avg prompt throughput: 12387.0 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 144 reqs, Swapped: 0 reqs, Pending: 12844 reqs, GPU KV cache usage: 34.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:23 [metrics.py:486] Avg prompt throughput: 12303.9 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 219 reqs, Swapped: 0 reqs, Pending: 12769 reqs, GPU KV cache usage: 51.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:28 [metrics.py:486] Avg prompt throughput: 12258.4 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 290 reqs, Swapped: 0 reqs, Pending: 12698 reqs, GPU KV cache usage: 68.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:34 [metrics.py:486] Avg prompt throughput: 12196.3 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 366 reqs, Swapped: 0 reqs, Pending: 12622 reqs, GPU KV cache usage: 85.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:39 [metrics.py:486] Avg prompt throughput: 12272.7 tokens/s, Avg generation throughput: 16.2 tokens/s, Running: 432 reqs, Swapped: 0 reqs, Pending: 12556 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:44 [metrics.py:486] Avg prompt throughput: 778.5 tokens/s, Avg generation throughput: 3028.7 tokens/s, Running: 419 reqs, Swapped: 0 reqs, Pending: 12556 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:49 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3766.7 tokens/s, Running: 401 reqs, Swapped: 0 reqs, Pending: 12556 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:54 [metrics.py:486] Avg prompt throughput: 392.3 tokens/s, Avg generation throughput: 3432.2 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 12529 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:10:59 [metrics.py:486] Avg prompt throughput: 12220.3 tokens/s, Avg generation throughput: 15.0 tokens/s, Running: 100 reqs, Swapped: 0 reqs, Pending: 12456 reqs, GPU KV cache usage: 22.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:11:04 [metrics.py:486] Avg prompt throughput: 12153.5 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 174 reqs, Swapped: 0 reqs, Pending: 12382 reqs, GPU KV cache usage: 38.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:11:10 [metrics.py:486] Avg prompt throughput: 12103.3 tokens/s, Avg generation throughput: 14.1 tokens/s, Running: 243 reqs, Swapped: 0 reqs, Pending: 12313 reqs, GPU KV cache usage: 55.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:11:15 [metrics.py:486] Avg prompt throughput: 12190.6 tokens/s, Avg generation throughput: 13.1 tokens/s, Running: 310 reqs, Swapped: 0 reqs, Pending: 12246 reqs, GPU KV cache usage: 72.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:11:20 [metrics.py:486] Avg prompt throughput: 12124.6 tokens/s, Avg generation throughput: 14.9 tokens/s, Running: 390 reqs, Swapped: 0 reqs, Pending: 12166 reqs, GPU KV cache usage: 90.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:11:25 [metrics.py:486] Avg prompt throughput: 9708.8 tokens/s, Avg generation throughput: 774.2 tokens/s, Running: 431 reqs, Swapped: 0 reqs, Pending: 12125 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:11:27 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-1239 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
INFO 07-23 06:11:30 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3240.9 tokens/s, Running: 411 reqs, Swapped: 0 reqs, Pending: 12145 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:11:35 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3675.7 tokens/s, Running: 390 reqs, Swapped: 0 reqs, Pending: 12166 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:11:41 [metrics.py:486] Avg prompt throughput: 2944.0 tokens/s, Avg generation throughput: 2296.0 tokens/s, Running: 37 reqs, Swapped: 0 reqs, Pending: 12139 reqs, GPU KV cache usage: 8.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:11:46 [metrics.py:486] Avg prompt throughput: 12106.2 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 108 reqs, Swapped: 0 reqs, Pending: 12068 reqs, GPU KV cache usage: 25.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:11:51 [metrics.py:486] Avg prompt throughput: 12214.2 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 185 reqs, Swapped: 0 reqs, Pending: 11991 reqs, GPU KV cache usage: 42.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:11:57 [metrics.py:486] Avg prompt throughput: 12076.0 tokens/s, Avg generation throughput: 14.1 tokens/s, Running: 257 reqs, Swapped: 0 reqs, Pending: 11919 reqs, GPU KV cache usage: 59.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:02 [metrics.py:486] Avg prompt throughput: 12023.0 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 330 reqs, Swapped: 0 reqs, Pending: 11846 reqs, GPU KV cache usage: 76.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:07 [metrics.py:486] Avg prompt throughput: 12086.3 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 404 reqs, Swapped: 0 reqs, Pending: 11772 reqs, GPU KV cache usage: 93.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:12 [metrics.py:486] Avg prompt throughput: 7192.0 tokens/s, Avg generation throughput: 1514.9 tokens/s, Running: 420 reqs, Swapped: 0 reqs, Pending: 11749 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:12:16 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-1616 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
INFO 07-23 06:12:17 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3739.9 tokens/s, Running: 399 reqs, Swapped: 0 reqs, Pending: 11753 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:22 [metrics.py:486] Avg prompt throughput: 439.8 tokens/s, Avg generation throughput: 3447.6 tokens/s, Running: 377 reqs, Swapped: 0 reqs, Pending: 11750 reqs, GPU KV cache usage: 98.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:28 [metrics.py:486] Avg prompt throughput: 6159.8 tokens/s, Avg generation throughput: 1244.7 tokens/s, Running: 53 reqs, Swapped: 0 reqs, Pending: 11700 reqs, GPU KV cache usage: 13.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:33 [metrics.py:486] Avg prompt throughput: 11952.6 tokens/s, Avg generation throughput: 13.0 tokens/s, Running: 123 reqs, Swapped: 0 reqs, Pending: 11630 reqs, GPU KV cache usage: 30.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:38 [metrics.py:486] Avg prompt throughput: 11965.2 tokens/s, Avg generation throughput: 13.1 tokens/s, Running: 191 reqs, Swapped: 0 reqs, Pending: 11562 reqs, GPU KV cache usage: 47.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:43 [metrics.py:486] Avg prompt throughput: 11959.8 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 263 reqs, Swapped: 0 reqs, Pending: 11490 reqs, GPU KV cache usage: 64.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:49 [metrics.py:486] Avg prompt throughput: 11938.9 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 335 reqs, Swapped: 0 reqs, Pending: 11418 reqs, GPU KV cache usage: 81.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:54 [metrics.py:486] Avg prompt throughput: 11887.8 tokens/s, Avg generation throughput: 14.0 tokens/s, Running: 405 reqs, Swapped: 0 reqs, Pending: 11348 reqs, GPU KV cache usage: 98.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:12:59 [metrics.py:486] Avg prompt throughput: 3819.3 tokens/s, Avg generation throughput: 2481.5 tokens/s, Running: 399 reqs, Swapped: 0 reqs, Pending: 11353 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:04 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3593.8 tokens/s, Running: 382 reqs, Swapped: 0 reqs, Pending: 11367 reqs, GPU KV cache usage: 99.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:09 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3096.7 tokens/s, Running: 366 reqs, Swapped: 0 reqs, Pending: 11382 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:15 [metrics.py:486] Avg prompt throughput: 10347.0 tokens/s, Avg generation throughput: 439.4 tokens/s, Running: 81 reqs, Swapped: 0 reqs, Pending: 11302 reqs, GPU KV cache usage: 20.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:21 [metrics.py:486] Avg prompt throughput: 12001.3 tokens/s, Avg generation throughput: 12.7 tokens/s, Running: 150 reqs, Swapped: 0 reqs, Pending: 11233 reqs, GPU KV cache usage: 37.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:26 [metrics.py:486] Avg prompt throughput: 12001.0 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 221 reqs, Swapped: 0 reqs, Pending: 11162 reqs, GPU KV cache usage: 54.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:31 [metrics.py:486] Avg prompt throughput: 11973.9 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 292 reqs, Swapped: 0 reqs, Pending: 11091 reqs, GPU KV cache usage: 71.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:36 [metrics.py:486] Avg prompt throughput: 11966.7 tokens/s, Avg generation throughput: 14.6 tokens/s, Running: 365 reqs, Swapped: 0 reqs, Pending: 11018 reqs, GPU KV cache usage: 88.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:41 [metrics.py:486] Avg prompt throughput: 11034.3 tokens/s, Avg generation throughput: 264.4 tokens/s, Running: 419 reqs, Swapped: 0 reqs, Pending: 10964 reqs, GPU KV cache usage: 99.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:46 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3725.4 tokens/s, Running: 400 reqs, Swapped: 0 reqs, Pending: 10966 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:51 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3596.3 tokens/s, Running: 385 reqs, Swapped: 0 reqs, Pending: 10968 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:13:57 [metrics.py:486] Avg prompt throughput: 5202.6 tokens/s, Avg generation throughput: 2037.3 tokens/s, Running: 59 reqs, Swapped: 0 reqs, Pending: 10909 reqs, GPU KV cache usage: 12.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:14:03 [metrics.py:486] Avg prompt throughput: 12032.4 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 133 reqs, Swapped: 0 reqs, Pending: 10835 reqs, GPU KV cache usage: 29.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:14:08 [metrics.py:486] Avg prompt throughput: 12061.5 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 200 reqs, Swapped: 0 reqs, Pending: 10768 reqs, GPU KV cache usage: 46.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:14:13 [metrics.py:486] Avg prompt throughput: 11966.5 tokens/s, Avg generation throughput: 12.9 tokens/s, Running: 272 reqs, Swapped: 0 reqs, Pending: 10696 reqs, GPU KV cache usage: 63.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:14:19 [metrics.py:486] Avg prompt throughput: 11952.5 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 10617 reqs, GPU KV cache usage: 80.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:14:24 [metrics.py:486] Avg prompt throughput: 11970.5 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 422 reqs, Swapped: 0 reqs, Pending: 10546 reqs, GPU KV cache usage: 97.2%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:14:28 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-2824 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
INFO 07-23 06:14:29 [metrics.py:486] Avg prompt throughput: 4443.5 tokens/s, Avg generation throughput: 1770.4 tokens/s, Running: 424 reqs, Swapped: 0 reqs, Pending: 10544 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:14:34 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3710.4 tokens/s, Running: 401 reqs, Swapped: 0 reqs, Pending: 10567 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:14:39 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3583.6 tokens/s, Running: 385 reqs, Swapped: 0 reqs, Pending: 10579 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:14:45 [metrics.py:486] Avg prompt throughput: 7750.3 tokens/s, Avg generation throughput: 883.9 tokens/s, Running: 70 reqs, Swapped: 0 reqs, Pending: 10514 reqs, GPU KV cache usage: 16.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:14:50 [metrics.py:486] Avg prompt throughput: 11985.9 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 141 reqs, Swapped: 0 reqs, Pending: 10443 reqs, GPU KV cache usage: 34.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:14:56 [metrics.py:486] Avg prompt throughput: 11989.3 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 215 reqs, Swapped: 0 reqs, Pending: 10369 reqs, GPU KV cache usage: 50.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:01 [metrics.py:486] Avg prompt throughput: 11948.1 tokens/s, Avg generation throughput: 15.5 tokens/s, Running: 297 reqs, Swapped: 0 reqs, Pending: 10287 reqs, GPU KV cache usage: 67.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:06 [metrics.py:486] Avg prompt throughput: 11978.6 tokens/s, Avg generation throughput: 14.6 tokens/s, Running: 376 reqs, Swapped: 0 reqs, Pending: 10208 reqs, GPU KV cache usage: 84.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:12 [metrics.py:486] Avg prompt throughput: 11905.8 tokens/s, Avg generation throughput: 12.8 tokens/s, Running: 428 reqs, Swapped: 0 reqs, Pending: 10156 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:17 [metrics.py:486] Avg prompt throughput: 816.4 tokens/s, Avg generation throughput: 3483.8 tokens/s, Running: 413 reqs, Swapped: 0 reqs, Pending: 10156 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:22 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3660.5 tokens/s, Running: 393 reqs, Swapped: 0 reqs, Pending: 10160 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:27 [metrics.py:486] Avg prompt throughput: 452.2 tokens/s, Avg generation throughput: 2885.3 tokens/s, Running: 381 reqs, Swapped: 0 reqs, Pending: 10158 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:32 [metrics.py:486] Avg prompt throughput: 11644.0 tokens/s, Avg generation throughput: 83.5 tokens/s, Running: 98 reqs, Swapped: 0 reqs, Pending: 10062 reqs, GPU KV cache usage: 22.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:38 [metrics.py:486] Avg prompt throughput: 12024.8 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 172 reqs, Swapped: 0 reqs, Pending: 9988 reqs, GPU KV cache usage: 39.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:43 [metrics.py:486] Avg prompt throughput: 11978.0 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 246 reqs, Swapped: 0 reqs, Pending: 9914 reqs, GPU KV cache usage: 56.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:48 [metrics.py:486] Avg prompt throughput: 11999.6 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 317 reqs, Swapped: 0 reqs, Pending: 9843 reqs, GPU KV cache usage: 73.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:54 [metrics.py:486] Avg prompt throughput: 11997.3 tokens/s, Avg generation throughput: 15.7 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 9758 reqs, GPU KV cache usage: 90.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:15:59 [metrics.py:486] Avg prompt throughput: 9521.6 tokens/s, Avg generation throughput: 791.8 tokens/s, Running: 438 reqs, Swapped: 0 reqs, Pending: 9722 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:16:00 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-3641 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
INFO 07-23 06:16:04 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3833.1 tokens/s, Running: 418 reqs, Swapped: 0 reqs, Pending: 9741 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:16:09 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3150.8 tokens/s, Running: 400 reqs, Swapped: 0 reqs, Pending: 9756 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:16:14 [metrics.py:486] Avg prompt throughput: 3124.3 tokens/s, Avg generation throughput: 2596.0 tokens/s, Running: 32 reqs, Swapped: 0 reqs, Pending: 9735 reqs, GPU KV cache usage: 8.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:16:19 [metrics.py:486] Avg prompt throughput: 12027.9 tokens/s, Avg generation throughput: 12.2 tokens/s, Running: 98 reqs, Swapped: 0 reqs, Pending: 9669 reqs, GPU KV cache usage: 25.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:16:24 [metrics.py:486] Avg prompt throughput: 12028.2 tokens/s, Avg generation throughput: 12.9 tokens/s, Running: 163 reqs, Swapped: 0 reqs, Pending: 9604 reqs, GPU KV cache usage: 41.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:16:30 [metrics.py:486] Avg prompt throughput: 12044.9 tokens/s, Avg generation throughput: 15.6 tokens/s, Running: 247 reqs, Swapped: 0 reqs, Pending: 9520 reqs, GPU KV cache usage: 59.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:16:35 [metrics.py:486] Avg prompt throughput: 11981.0 tokens/s, Avg generation throughput: 12.7 tokens/s, Running: 314 reqs, Swapped: 0 reqs, Pending: 9453 reqs, GPU KV cache usage: 76.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:16:40 [metrics.py:486] Avg prompt throughput: 11945.9 tokens/s, Avg generation throughput: 13.0 tokens/s, Running: 377 reqs, Swapped: 0 reqs, Pending: 9390 reqs, GPU KV cache usage: 92.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:16:45 [metrics.py:486] Avg prompt throughput: 7679.2 tokens/s, Avg generation throughput: 1262.1 tokens/s, Running: 398 reqs, Swapped: 0 reqs, Pending: 9363 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:16:50 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3615.9 tokens/s, Running: 379 reqs, Swapped: 0 reqs, Pending: 9363 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:16:55 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3119.2 tokens/s, Running: 364 reqs, Swapped: 0 reqs, Pending: 9363 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:00 [metrics.py:486] Avg prompt throughput: 6455.5 tokens/s, Avg generation throughput: 1593.7 tokens/s, Running: 58 reqs, Swapped: 0 reqs, Pending: 9305 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:06 [metrics.py:486] Avg prompt throughput: 11950.3 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 128 reqs, Swapped: 0 reqs, Pending: 9235 reqs, GPU KV cache usage: 30.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:11 [metrics.py:486] Avg prompt throughput: 11910.2 tokens/s, Avg generation throughput: 12.9 tokens/s, Running: 200 reqs, Swapped: 0 reqs, Pending: 9163 reqs, GPU KV cache usage: 47.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:16 [metrics.py:486] Avg prompt throughput: 11995.0 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 276 reqs, Swapped: 0 reqs, Pending: 9087 reqs, GPU KV cache usage: 64.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:22 [metrics.py:486] Avg prompt throughput: 11919.4 tokens/s, Avg generation throughput: 14.1 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 9012 reqs, GPU KV cache usage: 80.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:27 [metrics.py:486] Avg prompt throughput: 11844.7 tokens/s, Avg generation throughput: 14.3 tokens/s, Running: 420 reqs, Swapped: 0 reqs, Pending: 8943 reqs, GPU KV cache usage: 97.2%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:17:32 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-4423 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
INFO 07-23 06:17:32 [metrics.py:486] Avg prompt throughput: 4239.2 tokens/s, Avg generation throughput: 2435.4 tokens/s, Running: 416 reqs, Swapped: 0 reqs, Pending: 8947 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:37 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3134.7 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 8961 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:42 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3623.9 tokens/s, Running: 379 reqs, Swapped: 0 reqs, Pending: 8981 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:47 [metrics.py:486] Avg prompt throughput: 8989.1 tokens/s, Avg generation throughput: 860.0 tokens/s, Running: 68 reqs, Swapped: 0 reqs, Pending: 8918 reqs, GPU KV cache usage: 16.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:53 [metrics.py:486] Avg prompt throughput: 11931.1 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 142 reqs, Swapped: 0 reqs, Pending: 8844 reqs, GPU KV cache usage: 33.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:17:58 [metrics.py:486] Avg prompt throughput: 11943.5 tokens/s, Avg generation throughput: 12.0 tokens/s, Running: 206 reqs, Swapped: 0 reqs, Pending: 8780 reqs, GPU KV cache usage: 50.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:03 [metrics.py:486] Avg prompt throughput: 11896.6 tokens/s, Avg generation throughput: 13.0 tokens/s, Running: 278 reqs, Swapped: 0 reqs, Pending: 8708 reqs, GPU KV cache usage: 67.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:09 [metrics.py:486] Avg prompt throughput: 12022.1 tokens/s, Avg generation throughput: 14.2 tokens/s, Running: 350 reqs, Swapped: 0 reqs, Pending: 8636 reqs, GPU KV cache usage: 84.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:14 [metrics.py:486] Avg prompt throughput: 11996.2 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 411 reqs, Swapped: 0 reqs, Pending: 8575 reqs, GPU KV cache usage: 98.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:19 [metrics.py:486] Avg prompt throughput: 698.7 tokens/s, Avg generation throughput: 2872.6 tokens/s, Running: 398 reqs, Swapped: 0 reqs, Pending: 8575 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:24 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3635.4 tokens/s, Running: 376 reqs, Swapped: 0 reqs, Pending: 8575 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:30 [metrics.py:486] Avg prompt throughput: 3079.8 tokens/s, Avg generation throughput: 2625.5 tokens/s, Running: 33 reqs, Swapped: 0 reqs, Pending: 8542 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:35 [metrics.py:486] Avg prompt throughput: 11954.1 tokens/s, Avg generation throughput: 13.7 tokens/s, Running: 107 reqs, Swapped: 0 reqs, Pending: 8468 reqs, GPU KV cache usage: 25.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:41 [metrics.py:486] Avg prompt throughput: 11964.2 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 178 reqs, Swapped: 0 reqs, Pending: 8397 reqs, GPU KV cache usage: 42.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:46 [metrics.py:486] Avg prompt throughput: 11871.4 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 249 reqs, Swapped: 0 reqs, Pending: 8326 reqs, GPU KV cache usage: 59.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:51 [metrics.py:486] Avg prompt throughput: 11963.0 tokens/s, Avg generation throughput: 13.1 tokens/s, Running: 320 reqs, Swapped: 0 reqs, Pending: 8255 reqs, GPU KV cache usage: 76.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:18:56 [metrics.py:486] Avg prompt throughput: 11812.7 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 390 reqs, Swapped: 0 reqs, Pending: 8185 reqs, GPU KV cache usage: 93.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:01 [metrics.py:486] Avg prompt throughput: 7423.0 tokens/s, Avg generation throughput: 1398.5 tokens/s, Running: 408 reqs, Swapped: 0 reqs, Pending: 8167 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:19:02 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-5197 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
INFO 07-23 06:19:06 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3099.0 tokens/s, Running: 394 reqs, Swapped: 0 reqs, Pending: 8181 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:11 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3614.0 tokens/s, Running: 375 reqs, Swapped: 0 reqs, Pending: 8198 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:17 [metrics.py:486] Avg prompt throughput: 6147.9 tokens/s, Avg generation throughput: 1697.4 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 8154 reqs, GPU KV cache usage: 13.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:22 [metrics.py:486] Avg prompt throughput: 11987.0 tokens/s, Avg generation throughput: 13.4 tokens/s, Running: 121 reqs, Swapped: 0 reqs, Pending: 8084 reqs, GPU KV cache usage: 30.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:27 [metrics.py:486] Avg prompt throughput: 11951.2 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 188 reqs, Swapped: 0 reqs, Pending: 8017 reqs, GPU KV cache usage: 46.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:33 [metrics.py:486] Avg prompt throughput: 11986.7 tokens/s, Avg generation throughput: 13.2 tokens/s, Running: 264 reqs, Swapped: 0 reqs, Pending: 7941 reqs, GPU KV cache usage: 64.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:38 [metrics.py:486] Avg prompt throughput: 12008.4 tokens/s, Avg generation throughput: 14.1 tokens/s, Running: 340 reqs, Swapped: 0 reqs, Pending: 7865 reqs, GPU KV cache usage: 81.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:43 [metrics.py:486] Avg prompt throughput: 11991.7 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 417 reqs, Swapped: 0 reqs, Pending: 7788 reqs, GPU KV cache usage: 98.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:49 [metrics.py:486] Avg prompt throughput: 3521.5 tokens/s, Avg generation throughput: 2058.8 tokens/s, Running: 411 reqs, Swapped: 0 reqs, Pending: 7786 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:54 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3657.9 tokens/s, Running: 393 reqs, Swapped: 0 reqs, Pending: 7788 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:19:59 [metrics.py:486] Avg prompt throughput: 261.0 tokens/s, Avg generation throughput: 3541.4 tokens/s, Running: 375 reqs, Swapped: 0 reqs, Pending: 7787 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:20:04 [metrics.py:486] Avg prompt throughput: 8721.3 tokens/s, Avg generation throughput: 618.7 tokens/s, Running: 66 reqs, Swapped: 0 reqs, Pending: 7722 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:20:10 [metrics.py:486] Avg prompt throughput: 11960.8 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 144 reqs, Swapped: 0 reqs, Pending: 7644 reqs, GPU KV cache usage: 34.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:20:15 [metrics.py:486] Avg prompt throughput: 11954.6 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 213 reqs, Swapped: 0 reqs, Pending: 7575 reqs, GPU KV cache usage: 51.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:20:20 [metrics.py:486] Avg prompt throughput: 11957.7 tokens/s, Avg generation throughput: 12.8 tokens/s, Running: 284 reqs, Swapped: 0 reqs, Pending: 7504 reqs, GPU KV cache usage: 68.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:20:25 [metrics.py:486] Avg prompt throughput: 11948.3 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 7441 reqs, GPU KV cache usage: 84.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:20:31 [metrics.py:486] Avg prompt throughput: 11923.9 tokens/s, Avg generation throughput: 12.0 tokens/s, Running: 403 reqs, Swapped: 0 reqs, Pending: 7385 reqs, GPU KV cache usage: 98.7%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:20:35 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-5971 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
INFO 07-23 06:20:36 [metrics.py:486] Avg prompt throughput: 827.2 tokens/s, Avg generation throughput: 3353.8 tokens/s, Running: 388 reqs, Swapped: 0 reqs, Pending: 7400 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:20:41 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3649.2 tokens/s, Running: 369 reqs, Swapped: 0 reqs, Pending: 7418 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:20:47 [metrics.py:486] Avg prompt throughput: 2810.4 tokens/s, Avg generation throughput: 2225.7 tokens/s, Running: 30 reqs, Swapped: 0 reqs, Pending: 7397 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:20:52 [metrics.py:486] Avg prompt throughput: 12045.0 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 104 reqs, Swapped: 0 reqs, Pending: 7323 reqs, GPU KV cache usage: 25.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:20:57 [metrics.py:486] Avg prompt throughput: 11949.8 tokens/s, Avg generation throughput: 12.5 tokens/s, Running: 174 reqs, Swapped: 0 reqs, Pending: 7253 reqs, GPU KV cache usage: 42.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:02 [metrics.py:486] Avg prompt throughput: 11972.5 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 253 reqs, Swapped: 0 reqs, Pending: 7174 reqs, GPU KV cache usage: 59.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:08 [metrics.py:486] Avg prompt throughput: 11985.9 tokens/s, Avg generation throughput: 16.0 tokens/s, Running: 332 reqs, Swapped: 0 reqs, Pending: 7095 reqs, GPU KV cache usage: 76.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:13 [metrics.py:486] Avg prompt throughput: 11972.8 tokens/s, Avg generation throughput: 13.1 tokens/s, Running: 405 reqs, Swapped: 0 reqs, Pending: 7022 reqs, GPU KV cache usage: 94.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:18 [metrics.py:486] Avg prompt throughput: 6920.7 tokens/s, Avg generation throughput: 1538.0 tokens/s, Running: 423 reqs, Swapped: 0 reqs, Pending: 6999 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:23 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3744.1 tokens/s, Running: 406 reqs, Swapped: 0 reqs, Pending: 7002 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:28 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3145.4 tokens/s, Running: 390 reqs, Swapped: 0 reqs, Pending: 7002 reqs, GPU KV cache usage: 99.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:34 [metrics.py:486] Avg prompt throughput: 6205.0 tokens/s, Avg generation throughput: 1707.2 tokens/s, Running: 54 reqs, Swapped: 0 reqs, Pending: 6949 reqs, GPU KV cache usage: 12.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:39 [metrics.py:486] Avg prompt throughput: 12004.7 tokens/s, Avg generation throughput: 14.1 tokens/s, Running: 125 reqs, Swapped: 0 reqs, Pending: 6878 reqs, GPU KV cache usage: 29.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:44 [metrics.py:486] Avg prompt throughput: 11987.0 tokens/s, Avg generation throughput: 13.7 tokens/s, Running: 201 reqs, Swapped: 0 reqs, Pending: 6802 reqs, GPU KV cache usage: 46.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:49 [metrics.py:486] Avg prompt throughput: 11983.5 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 271 reqs, Swapped: 0 reqs, Pending: 6732 reqs, GPU KV cache usage: 63.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:21:55 [metrics.py:486] Avg prompt throughput: 12003.2 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 339 reqs, Swapped: 0 reqs, Pending: 6664 reqs, GPU KV cache usage: 80.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:00 [metrics.py:486] Avg prompt throughput: 11867.1 tokens/s, Avg generation throughput: 12.4 tokens/s, Running: 408 reqs, Swapped: 0 reqs, Pending: 6595 reqs, GPU KV cache usage: 97.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:05 [metrics.py:486] Avg prompt throughput: 4343.5 tokens/s, Avg generation throughput: 2361.5 tokens/s, Running: 405 reqs, Swapped: 0 reqs, Pending: 6597 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:22:07 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-6764 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
INFO 07-23 06:22:10 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3116.9 tokens/s, Running: 390 reqs, Swapped: 0 reqs, Pending: 6612 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:15 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3637.9 tokens/s, Running: 372 reqs, Swapped: 0 reqs, Pending: 6627 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:20 [metrics.py:486] Avg prompt throughput: 9341.0 tokens/s, Avg generation throughput: 733.1 tokens/s, Running: 73 reqs, Swapped: 0 reqs, Pending: 6557 reqs, GPU KV cache usage: 17.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:25 [metrics.py:486] Avg prompt throughput: 11956.4 tokens/s, Avg generation throughput: 14.2 tokens/s, Running: 145 reqs, Swapped: 0 reqs, Pending: 6485 reqs, GPU KV cache usage: 34.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:31 [metrics.py:486] Avg prompt throughput: 11985.0 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 220 reqs, Swapped: 0 reqs, Pending: 6410 reqs, GPU KV cache usage: 51.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:36 [metrics.py:486] Avg prompt throughput: 12037.4 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 293 reqs, Swapped: 0 reqs, Pending: 6337 reqs, GPU KV cache usage: 67.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:41 [metrics.py:486] Avg prompt throughput: 11896.0 tokens/s, Avg generation throughput: 12.7 tokens/s, Running: 360 reqs, Swapped: 0 reqs, Pending: 6270 reqs, GPU KV cache usage: 84.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:46 [metrics.py:486] Avg prompt throughput: 11970.9 tokens/s, Avg generation throughput: 14.6 tokens/s, Running: 427 reqs, Swapped: 0 reqs, Pending: 6203 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:51 [metrics.py:486] Avg prompt throughput: 1547.3 tokens/s, Avg generation throughput: 3242.2 tokens/s, Running: 413 reqs, Swapped: 0 reqs, Pending: 6206 reqs, GPU KV cache usage: 99.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:22:56 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3151.7 tokens/s, Running: 397 reqs, Swapped: 0 reqs, Pending: 6207 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:23:02 [metrics.py:486] Avg prompt throughput: 113.9 tokens/s, Avg generation throughput: 3519.4 tokens/s, Running: 383 reqs, Swapped: 0 reqs, Pending: 6206 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:23:07 [metrics.py:486] Avg prompt throughput: 11141.0 tokens/s, Avg generation throughput: 215.2 tokens/s, Running: 87 reqs, Swapped: 0 reqs, Pending: 6120 reqs, GPU KV cache usage: 21.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:23:12 [metrics.py:486] Avg prompt throughput: 11900.8 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 160 reqs, Swapped: 0 reqs, Pending: 6047 reqs, GPU KV cache usage: 37.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:23:18 [metrics.py:486] Avg prompt throughput: 11927.3 tokens/s, Avg generation throughput: 14.2 tokens/s, Running: 237 reqs, Swapped: 0 reqs, Pending: 5970 reqs, GPU KV cache usage: 54.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:23:23 [metrics.py:486] Avg prompt throughput: 11890.8 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 312 reqs, Swapped: 0 reqs, Pending: 5895 reqs, GPU KV cache usage: 71.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:23:29 [metrics.py:486] Avg prompt throughput: 11895.4 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 382 reqs, Swapped: 0 reqs, Pending: 5825 reqs, GPU KV cache usage: 89.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:23:34 [metrics.py:486] Avg prompt throughput: 10402.8 tokens/s, Avg generation throughput: 523.9 tokens/s, Running: 428 reqs, Swapped: 0 reqs, Pending: 5779 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:23:39 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3247.9 tokens/s, Running: 410 reqs, Swapped: 0 reqs, Pending: 5796 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:23:39 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-7570 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
INFO 07-23 06:23:44 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3628.2 tokens/s, Running: 387 reqs, Swapped: 0 reqs, Pending: 5816 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:23:49 [metrics.py:486] Avg prompt throughput: 3069.2 tokens/s, Avg generation throughput: 2657.4 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 5791 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:23:54 [metrics.py:486] Avg prompt throughput: 11975.7 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 107 reqs, Swapped: 0 reqs, Pending: 5723 reqs, GPU KV cache usage: 25.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:00 [metrics.py:486] Avg prompt throughput: 12028.6 tokens/s, Avg generation throughput: 14.0 tokens/s, Running: 183 reqs, Swapped: 0 reqs, Pending: 5647 reqs, GPU KV cache usage: 42.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:05 [metrics.py:486] Avg prompt throughput: 11981.7 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 252 reqs, Swapped: 0 reqs, Pending: 5578 reqs, GPU KV cache usage: 59.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:10 [metrics.py:486] Avg prompt throughput: 11949.8 tokens/s, Avg generation throughput: 12.8 tokens/s, Running: 323 reqs, Swapped: 0 reqs, Pending: 5507 reqs, GPU KV cache usage: 76.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:15 [metrics.py:486] Avg prompt throughput: 11901.1 tokens/s, Avg generation throughput: 13.7 tokens/s, Running: 392 reqs, Swapped: 0 reqs, Pending: 5438 reqs, GPU KV cache usage: 93.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:21 [metrics.py:486] Avg prompt throughput: 6914.6 tokens/s, Avg generation throughput: 1061.8 tokens/s, Running: 408 reqs, Swapped: 0 reqs, Pending: 5416 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:26 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3626.4 tokens/s, Running: 389 reqs, Swapped: 0 reqs, Pending: 5417 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:31 [metrics.py:486] Avg prompt throughput: 314.0 tokens/s, Avg generation throughput: 3523.2 tokens/s, Running: 367 reqs, Swapped: 0 reqs, Pending: 5416 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:36 [metrics.py:486] Avg prompt throughput: 5991.6 tokens/s, Avg generation throughput: 1357.8 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 5366 reqs, GPU KV cache usage: 13.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:41 [metrics.py:486] Avg prompt throughput: 12048.3 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 129 reqs, Swapped: 0 reqs, Pending: 5288 reqs, GPU KV cache usage: 30.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:47 [metrics.py:486] Avg prompt throughput: 11900.8 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 198 reqs, Swapped: 0 reqs, Pending: 5219 reqs, GPU KV cache usage: 47.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:52 [metrics.py:486] Avg prompt throughput: 11998.6 tokens/s, Avg generation throughput: 13.7 tokens/s, Running: 276 reqs, Swapped: 0 reqs, Pending: 5141 reqs, GPU KV cache usage: 64.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:24:57 [metrics.py:486] Avg prompt throughput: 12024.6 tokens/s, Avg generation throughput: 14.6 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 5068 reqs, GPU KV cache usage: 81.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:25:03 [metrics.py:486] Avg prompt throughput: 11968.7 tokens/s, Avg generation throughput: 14.0 tokens/s, Running: 424 reqs, Swapped: 0 reqs, Pending: 4993 reqs, GPU KV cache usage: 98.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:25:08 [metrics.py:486] Avg prompt throughput: 3480.4 tokens/s, Avg generation throughput: 2669.0 tokens/s, Running: 415 reqs, Swapped: 0 reqs, Pending: 5002 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:25:09 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-8360 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
INFO 07-23 06:25:13 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3656.9 tokens/s, Running: 394 reqs, Swapped: 0 reqs, Pending: 5022 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:25:18 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3186.2 tokens/s, Running: 377 reqs, Swapped: 0 reqs, Pending: 5038 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:25:24 [metrics.py:486] Avg prompt throughput: 10398.1 tokens/s, Avg generation throughput: 442.5 tokens/s, Running: 83 reqs, Swapped: 0 reqs, Pending: 4957 reqs, GPU KV cache usage: 21.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:25:29 [metrics.py:486] Avg prompt throughput: 12041.0 tokens/s, Avg generation throughput: 14.0 tokens/s, Running: 158 reqs, Swapped: 0 reqs, Pending: 4882 reqs, GPU KV cache usage: 38.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:25:35 [metrics.py:486] Avg prompt throughput: 12005.2 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 230 reqs, Swapped: 0 reqs, Pending: 4810 reqs, GPU KV cache usage: 55.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:25:40 [metrics.py:486] Avg prompt throughput: 12049.2 tokens/s, Avg generation throughput: 14.8 tokens/s, Running: 308 reqs, Swapped: 0 reqs, Pending: 4732 reqs, GPU KV cache usage: 72.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:25:45 [metrics.py:486] Avg prompt throughput: 11962.3 tokens/s, Avg generation throughput: 12.8 tokens/s, Running: 376 reqs, Swapped: 0 reqs, Pending: 4664 reqs, GPU KV cache usage: 89.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:25:50 [metrics.py:486] Avg prompt throughput: 10576.2 tokens/s, Avg generation throughput: 434.5 tokens/s, Running: 421 reqs, Swapped: 0 reqs, Pending: 4617 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:25:55 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3733.6 tokens/s, Running: 404 reqs, Swapped: 0 reqs, Pending: 4617 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:00 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3181.5 tokens/s, Running: 385 reqs, Swapped: 0 reqs, Pending: 4618 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:05 [metrics.py:486] Avg prompt throughput: 3321.7 tokens/s, Avg generation throughput: 2547.7 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 4584 reqs, GPU KV cache usage: 8.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:11 [metrics.py:486] Avg prompt throughput: 11977.9 tokens/s, Avg generation throughput: 13.7 tokens/s, Running: 107 reqs, Swapped: 0 reqs, Pending: 4511 reqs, GPU KV cache usage: 25.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:16 [metrics.py:486] Avg prompt throughput: 12010.0 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 180 reqs, Swapped: 0 reqs, Pending: 4438 reqs, GPU KV cache usage: 42.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:21 [metrics.py:486] Avg prompt throughput: 11954.1 tokens/s, Avg generation throughput: 14.1 tokens/s, Running: 253 reqs, Swapped: 0 reqs, Pending: 4365 reqs, GPU KV cache usage: 59.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:26 [metrics.py:486] Avg prompt throughput: 12008.6 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 334 reqs, Swapped: 0 reqs, Pending: 4284 reqs, GPU KV cache usage: 76.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:32 [metrics.py:486] Avg prompt throughput: 12020.4 tokens/s, Avg generation throughput: 12.8 tokens/s, Running: 399 reqs, Swapped: 0 reqs, Pending: 4219 reqs, GPU KV cache usage: 93.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:37 [metrics.py:486] Avg prompt throughput: 7284.5 tokens/s, Avg generation throughput: 1508.3 tokens/s, Running: 421 reqs, Swapped: 0 reqs, Pending: 4197 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:26:40 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-9158 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
INFO 07-23 06:26:42 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3292.7 tokens/s, Running: 400 reqs, Swapped: 0 reqs, Pending: 4217 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:47 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3600.6 tokens/s, Running: 382 reqs, Swapped: 0 reqs, Pending: 4235 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:53 [metrics.py:486] Avg prompt throughput: 7566.5 tokens/s, Avg generation throughput: 1307.8 tokens/s, Running: 71 reqs, Swapped: 0 reqs, Pending: 4171 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:26:58 [metrics.py:486] Avg prompt throughput: 11986.0 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 143 reqs, Swapped: 0 reqs, Pending: 4099 reqs, GPU KV cache usage: 33.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:04 [metrics.py:486] Avg prompt throughput: 11943.8 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 215 reqs, Swapped: 0 reqs, Pending: 4027 reqs, GPU KV cache usage: 50.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:09 [metrics.py:486] Avg prompt throughput: 12011.3 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 285 reqs, Swapped: 0 reqs, Pending: 3957 reqs, GPU KV cache usage: 67.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:14 [metrics.py:486] Avg prompt throughput: 11906.7 tokens/s, Avg generation throughput: 12.5 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 3890 reqs, GPU KV cache usage: 84.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:20 [metrics.py:486] Avg prompt throughput: 10821.4 tokens/s, Avg generation throughput: 12.4 tokens/s, Running: 414 reqs, Swapped: 0 reqs, Pending: 3828 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:25 [metrics.py:486] Avg prompt throughput: 1027.4 tokens/s, Avg generation throughput: 3365.8 tokens/s, Running: 400 reqs, Swapped: 0 reqs, Pending: 3828 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:30 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3635.0 tokens/s, Running: 379 reqs, Swapped: 0 reqs, Pending: 3828 reqs, GPU KV cache usage: 99.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:36 [metrics.py:486] Avg prompt throughput: 2779.7 tokens/s, Avg generation throughput: 2428.1 tokens/s, Running: 39 reqs, Swapped: 0 reqs, Pending: 3789 reqs, GPU KV cache usage: 8.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:41 [metrics.py:486] Avg prompt throughput: 11954.4 tokens/s, Avg generation throughput: 12.4 tokens/s, Running: 104 reqs, Swapped: 0 reqs, Pending: 3724 reqs, GPU KV cache usage: 25.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:47 [metrics.py:486] Avg prompt throughput: 12025.2 tokens/s, Avg generation throughput: 14.3 tokens/s, Running: 184 reqs, Swapped: 0 reqs, Pending: 3644 reqs, GPU KV cache usage: 42.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:52 [metrics.py:486] Avg prompt throughput: 11951.1 tokens/s, Avg generation throughput: 14.3 tokens/s, Running: 255 reqs, Swapped: 0 reqs, Pending: 3573 reqs, GPU KV cache usage: 59.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:27:57 [metrics.py:486] Avg prompt throughput: 11949.7 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 330 reqs, Swapped: 0 reqs, Pending: 3498 reqs, GPU KV cache usage: 76.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:28:03 [metrics.py:486] Avg prompt throughput: 11871.6 tokens/s, Avg generation throughput: 12.7 tokens/s, Running: 399 reqs, Swapped: 0 reqs, Pending: 3429 reqs, GPU KV cache usage: 93.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:28:08 [metrics.py:486] Avg prompt throughput: 7155.4 tokens/s, Avg generation throughput: 1511.0 tokens/s, Running: 417 reqs, Swapped: 0 reqs, Pending: 3411 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:28:11 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-9944 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
INFO 07-23 06:28:13 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3671.7 tokens/s, Running: 396 reqs, Swapped: 0 reqs, Pending: 3432 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:28:18 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3200.9 tokens/s, Running: 377 reqs, Swapped: 0 reqs, Pending: 3449 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:28:24 [metrics.py:486] Avg prompt throughput: 7578.3 tokens/s, Avg generation throughput: 1273.5 tokens/s, Running: 66 reqs, Swapped: 0 reqs, Pending: 3389 reqs, GPU KV cache usage: 16.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:28:30 [metrics.py:486] Avg prompt throughput: 11889.7 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 146 reqs, Swapped: 0 reqs, Pending: 3309 reqs, GPU KV cache usage: 34.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:28:35 [metrics.py:486] Avg prompt throughput: 11874.5 tokens/s, Avg generation throughput: 13.7 tokens/s, Running: 221 reqs, Swapped: 0 reqs, Pending: 3234 reqs, GPU KV cache usage: 51.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:28:40 [metrics.py:486] Avg prompt throughput: 11938.0 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 291 reqs, Swapped: 0 reqs, Pending: 3164 reqs, GPU KV cache usage: 68.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:28:46 [metrics.py:486] Avg prompt throughput: 11886.9 tokens/s, Avg generation throughput: 13.2 tokens/s, Running: 363 reqs, Swapped: 0 reqs, Pending: 3092 reqs, GPU KV cache usage: 85.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:28:51 [metrics.py:486] Avg prompt throughput: 11945.2 tokens/s, Avg generation throughput: 13.1 tokens/s, Running: 419 reqs, Swapped: 0 reqs, Pending: 3036 reqs, GPU KV cache usage: 98.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:28:56 [metrics.py:486] Avg prompt throughput: 961.6 tokens/s, Avg generation throughput: 3376.2 tokens/s, Running: 404 reqs, Swapped: 0 reqs, Pending: 3037 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:29:01 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3216.5 tokens/s, Running: 386 reqs, Swapped: 0 reqs, Pending: 3037 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:29:07 [metrics.py:486] Avg prompt throughput: 2895.3 tokens/s, Avg generation throughput: 2724.1 tokens/s, Running: 41 reqs, Swapped: 0 reqs, Pending: 2996 reqs, GPU KV cache usage: 9.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:29:12 [metrics.py:486] Avg prompt throughput: 12027.9 tokens/s, Avg generation throughput: 14.2 tokens/s, Running: 120 reqs, Swapped: 0 reqs, Pending: 2917 reqs, GPU KV cache usage: 26.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:29:18 [metrics.py:486] Avg prompt throughput: 12065.3 tokens/s, Avg generation throughput: 15.2 tokens/s, Running: 200 reqs, Swapped: 0 reqs, Pending: 2837 reqs, GPU KV cache usage: 43.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:29:23 [metrics.py:486] Avg prompt throughput: 12016.3 tokens/s, Avg generation throughput: 15.0 tokens/s, Running: 278 reqs, Swapped: 0 reqs, Pending: 2759 reqs, GPU KV cache usage: 60.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:29:28 [metrics.py:486] Avg prompt throughput: 12012.5 tokens/s, Avg generation throughput: 14.0 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 2690 reqs, GPU KV cache usage: 77.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:29:33 [metrics.py:486] Avg prompt throughput: 12013.6 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 423 reqs, Swapped: 0 reqs, Pending: 2614 reqs, GPU KV cache usage: 94.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:29:38 [metrics.py:486] Avg prompt throughput: 6385.9 tokens/s, Avg generation throughput: 1766.3 tokens/s, Running: 437 reqs, Swapped: 0 reqs, Pending: 2600 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:29:42 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-10756 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
INFO 07-23 06:29:44 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3444.1 tokens/s, Running: 419 reqs, Swapped: 0 reqs, Pending: 2618 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:29:49 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3703.7 tokens/s, Running: 400 reqs, Swapped: 0 reqs, Pending: 2636 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:29:55 [metrics.py:486] Avg prompt throughput: 7582.0 tokens/s, Avg generation throughput: 1280.1 tokens/s, Running: 68 reqs, Swapped: 0 reqs, Pending: 2574 reqs, GPU KV cache usage: 16.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:00 [metrics.py:486] Avg prompt throughput: 12068.4 tokens/s, Avg generation throughput: 14.0 tokens/s, Running: 142 reqs, Swapped: 0 reqs, Pending: 2500 reqs, GPU KV cache usage: 33.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:05 [metrics.py:486] Avg prompt throughput: 12030.2 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 218 reqs, Swapped: 0 reqs, Pending: 2424 reqs, GPU KV cache usage: 51.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:11 [metrics.py:486] Avg prompt throughput: 11986.7 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 294 reqs, Swapped: 0 reqs, Pending: 2348 reqs, GPU KV cache usage: 68.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:16 [metrics.py:486] Avg prompt throughput: 11936.8 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 2280 reqs, GPU KV cache usage: 85.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:21 [metrics.py:486] Avg prompt throughput: 12005.7 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 422 reqs, Swapped: 0 reqs, Pending: 2220 reqs, GPU KV cache usage: 98.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:26 [metrics.py:486] Avg prompt throughput: 612.3 tokens/s, Avg generation throughput: 3149.2 tokens/s, Running: 408 reqs, Swapped: 0 reqs, Pending: 2220 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:31 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3642.7 tokens/s, Running: 390 reqs, Swapped: 0 reqs, Pending: 2220 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:37 [metrics.py:486] Avg prompt throughput: 637.1 tokens/s, Avg generation throughput: 3108.0 tokens/s, Running: 377 reqs, Swapped: 0 reqs, Pending: 2218 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:42 [metrics.py:486] Avg prompt throughput: 11334.7 tokens/s, Avg generation throughput: 148.3 tokens/s, Running: 93 reqs, Swapped: 0 reqs, Pending: 2127 reqs, GPU KV cache usage: 21.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:47 [metrics.py:486] Avg prompt throughput: 12072.9 tokens/s, Avg generation throughput: 14.3 tokens/s, Running: 168 reqs, Swapped: 0 reqs, Pending: 2052 reqs, GPU KV cache usage: 38.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:53 [metrics.py:486] Avg prompt throughput: 11955.0 tokens/s, Avg generation throughput: 12.0 tokens/s, Running: 230 reqs, Swapped: 0 reqs, Pending: 1990 reqs, GPU KV cache usage: 55.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:30:58 [metrics.py:486] Avg prompt throughput: 11974.2 tokens/s, Avg generation throughput: 13.7 tokens/s, Running: 304 reqs, Swapped: 0 reqs, Pending: 1916 reqs, GPU KV cache usage: 72.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:31:03 [metrics.py:486] Avg prompt throughput: 11952.4 tokens/s, Avg generation throughput: 12.9 tokens/s, Running: 375 reqs, Swapped: 0 reqs, Pending: 1845 reqs, GPU KV cache usage: 89.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:31:08 [metrics.py:486] Avg prompt throughput: 9681.5 tokens/s, Avg generation throughput: 746.8 tokens/s, Running: 415 reqs, Swapped: 0 reqs, Pending: 1805 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:31:12 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-11546 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=701
INFO 07-23 06:31:14 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3671.8 tokens/s, Running: 396 reqs, Swapped: 0 reqs, Pending: 1824 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:31:19 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3311.4 tokens/s, Running: 374 reqs, Swapped: 0 reqs, Pending: 1845 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:31:24 [metrics.py:486] Avg prompt throughput: 5931.7 tokens/s, Avg generation throughput: 1791.8 tokens/s, Running: 51 reqs, Swapped: 0 reqs, Pending: 1799 reqs, GPU KV cache usage: 12.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:31:29 [metrics.py:486] Avg prompt throughput: 12083.8 tokens/s, Avg generation throughput: 14.1 tokens/s, Running: 126 reqs, Swapped: 0 reqs, Pending: 1724 reqs, GPU KV cache usage: 29.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:31:35 [metrics.py:486] Avg prompt throughput: 12034.9 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 195 reqs, Swapped: 0 reqs, Pending: 1655 reqs, GPU KV cache usage: 46.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:31:40 [metrics.py:486] Avg prompt throughput: 11974.9 tokens/s, Avg generation throughput: 14.1 tokens/s, Running: 275 reqs, Swapped: 0 reqs, Pending: 1575 reqs, GPU KV cache usage: 63.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:31:45 [metrics.py:486] Avg prompt throughput: 12061.5 tokens/s, Avg generation throughput: 14.9 tokens/s, Running: 350 reqs, Swapped: 0 reqs, Pending: 1500 reqs, GPU KV cache usage: 80.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:31:50 [metrics.py:486] Avg prompt throughput: 12022.0 tokens/s, Avg generation throughput: 14.3 tokens/s, Running: 423 reqs, Swapped: 0 reqs, Pending: 1427 reqs, GPU KV cache usage: 97.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:31:56 [metrics.py:486] Avg prompt throughput: 4422.1 tokens/s, Avg generation throughput: 2349.6 tokens/s, Running: 420 reqs, Swapped: 0 reqs, Pending: 1423 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:01 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3709.7 tokens/s, Running: 400 reqs, Swapped: 0 reqs, Pending: 1423 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:06 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3259.6 tokens/s, Running: 382 reqs, Swapped: 0 reqs, Pending: 1423 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:11 [metrics.py:486] Avg prompt throughput: 9245.3 tokens/s, Avg generation throughput: 807.4 tokens/s, Running: 72 reqs, Swapped: 0 reqs, Pending: 1351 reqs, GPU KV cache usage: 17.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:16 [metrics.py:486] Avg prompt throughput: 12061.7 tokens/s, Avg generation throughput: 13.5 tokens/s, Running: 144 reqs, Swapped: 0 reqs, Pending: 1279 reqs, GPU KV cache usage: 34.3%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:21 [metrics.py:486] Avg prompt throughput: 12001.9 tokens/s, Avg generation throughput: 12.5 tokens/s, Running: 211 reqs, Swapped: 0 reqs, Pending: 1212 reqs, GPU KV cache usage: 51.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:27 [metrics.py:486] Avg prompt throughput: 12041.1 tokens/s, Avg generation throughput: 14.6 tokens/s, Running: 289 reqs, Swapped: 0 reqs, Pending: 1134 reqs, GPU KV cache usage: 68.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:32 [metrics.py:486] Avg prompt throughput: 12057.6 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 363 reqs, Swapped: 0 reqs, Pending: 1060 reqs, GPU KV cache usage: 85.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:37 [metrics.py:486] Avg prompt throughput: 12035.7 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 417 reqs, Swapped: 0 reqs, Pending: 1006 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:42 [metrics.py:486] Avg prompt throughput: 1133.6 tokens/s, Avg generation throughput: 3311.4 tokens/s, Running: 403 reqs, Swapped: 0 reqs, Pending: 1020 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:32:43 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-12343 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=751
INFO 07-23 06:32:47 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3292.7 tokens/s, Running: 387 reqs, Swapped: 0 reqs, Pending: 1036 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:53 [metrics.py:486] Avg prompt throughput: 2616.3 tokens/s, Avg generation throughput: 2821.4 tokens/s, Running: 29 reqs, Swapped: 0 reqs, Pending: 1017 reqs, GPU KV cache usage: 8.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:32:58 [metrics.py:486] Avg prompt throughput: 12037.5 tokens/s, Avg generation throughput: 13.9 tokens/s, Running: 104 reqs, Swapped: 0 reqs, Pending: 942 reqs, GPU KV cache usage: 25.6%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:04 [metrics.py:486] Avg prompt throughput: 11992.0 tokens/s, Avg generation throughput: 12.0 tokens/s, Running: 169 reqs, Swapped: 0 reqs, Pending: 877 reqs, GPU KV cache usage: 42.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:09 [metrics.py:486] Avg prompt throughput: 12032.2 tokens/s, Avg generation throughput: 14.3 tokens/s, Running: 247 reqs, Swapped: 0 reqs, Pending: 799 reqs, GPU KV cache usage: 59.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:14 [metrics.py:486] Avg prompt throughput: 12083.8 tokens/s, Avg generation throughput: 14.7 tokens/s, Running: 327 reqs, Swapped: 0 reqs, Pending: 719 reqs, GPU KV cache usage: 77.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:20 [metrics.py:486] Avg prompt throughput: 12093.0 tokens/s, Avg generation throughput: 15.2 tokens/s, Running: 404 reqs, Swapped: 0 reqs, Pending: 642 reqs, GPU KV cache usage: 94.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:25 [metrics.py:486] Avg prompt throughput: 6591.4 tokens/s, Avg generation throughput: 1671.2 tokens/s, Running: 420 reqs, Swapped: 0 reqs, Pending: 621 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:30 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3421.3 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 625 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:35 [metrics.py:486] Avg prompt throughput: 103.0 tokens/s, Avg generation throughput: 3579.1 tokens/s, Running: 385 reqs, Swapped: 0 reqs, Pending: 624 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:41 [metrics.py:486] Avg prompt throughput: 7876.1 tokens/s, Avg generation throughput: 1206.4 tokens/s, Running: 79 reqs, Swapped: 0 reqs, Pending: 546 reqs, GPU KV cache usage: 17.2%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:46 [metrics.py:486] Avg prompt throughput: 12057.3 tokens/s, Avg generation throughput: 14.5 tokens/s, Running: 150 reqs, Swapped: 0 reqs, Pending: 475 reqs, GPU KV cache usage: 33.8%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:51 [metrics.py:486] Avg prompt throughput: 12032.5 tokens/s, Avg generation throughput: 13.3 tokens/s, Running: 218 reqs, Swapped: 0 reqs, Pending: 407 reqs, GPU KV cache usage: 50.5%, CPU KV cache usage: 0.0%.
INFO 07-23 06:33:57 [metrics.py:486] Avg prompt throughput: 11971.6 tokens/s, Avg generation throughput: 13.8 tokens/s, Running: 294 reqs, Swapped: 0 reqs, Pending: 331 reqs, GPU KV cache usage: 67.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:34:02 [metrics.py:486] Avg prompt throughput: 11967.4 tokens/s, Avg generation throughput: 12.5 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 268 reqs, GPU KV cache usage: 84.4%, CPU KV cache usage: 0.0%.
INFO 07-23 06:34:07 [metrics.py:486] Avg prompt throughput: 11862.6 tokens/s, Avg generation throughput: 11.5 tokens/s, Running: 411 reqs, Swapped: 0 reqs, Pending: 214 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:34:12 [metrics.py:486] Avg prompt throughput: 1274.0 tokens/s, Avg generation throughput: 2915.4 tokens/s, Running: 400 reqs, Swapped: 0 reqs, Pending: 225 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
WARNING 07-23 06:34:17 [scheduler.py:1800] Sequence group cmpl-b89dfedcb16c45f7a71cf4e8cadea651-13129 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=801
INFO 07-23 06:34:17 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3578.1 tokens/s, Running: 383 reqs, Swapped: 0 reqs, Pending: 240 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 06:34:23 [metrics.py:486] Avg prompt throughput: 2498.6 tokens/s, Avg generation throughput: 2828.7 tokens/s, Running: 27 reqs, Swapped: 0 reqs, Pending: 225 reqs, GPU KV cache usage: 8.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:34:29 [metrics.py:486] Avg prompt throughput: 11877.3 tokens/s, Avg generation throughput: 12.5 tokens/s, Running: 101 reqs, Swapped: 0 reqs, Pending: 151 reqs, GPU KV cache usage: 25.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:34:34 [metrics.py:486] Avg prompt throughput: 11957.5 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 174 reqs, Swapped: 0 reqs, Pending: 78 reqs, GPU KV cache usage: 42.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:34:39 [metrics.py:486] Avg prompt throughput: 11924.6 tokens/s, Avg generation throughput: 14.4 tokens/s, Running: 249 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 59.1%, CPU KV cache usage: 0.0%.
INFO 07-23 06:34:44 [metrics.py:486] Avg prompt throughput: 3680.3 tokens/s, Avg generation throughput: 2099.5 tokens/s, Running: 240 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 58.9%, CPU KV cache usage: 0.0%.
INFO 07-23 06:34:49 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3416.9 tokens/s, Running: 214 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 55.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60638 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 07-23 06:35:00 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 180.8 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:35:10 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 07-23 06:37:01 [launcher.py:79] Shutting down FastAPI HTTP server.
Exception ignored in: <function Socket.__del__ at 0x7f5d68e50c20>
Traceback (most recent call last):
  File "/root/rehan/.venv/lib/python3.12/site-packages/zmq/sugar/socket.py", line 184, in __del__
    def __del__(self):

  File "/root/rehan/.venv/lib/python3.12/site-packages/vllm/engine/multiprocessing/engine.py", line 435, in signal_handler
    raise KeyboardInterrupt("MQLLMEngine terminated")
KeyboardInterrupt: MQLLMEngine terminated
[rank0]:[W723 06:37:01.315058480 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
