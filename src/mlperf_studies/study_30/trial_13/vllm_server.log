INFO 07-23 10:40:04 [__init__.py:243] Automatically detected platform cuda.
INFO 07-23 10:40:11 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 07-23 10:40:11 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 07-23 10:40:11 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 07-23 10:40:12 [api_server.py:1289] vLLM API server version 0.9.0.1
INFO 07-23 10:40:12 [cli_args.py:300] non-default args: {'max_model_len': 8192, 'block_size': 16, 'gpu_memory_utilization': 0.91, 'kv_cache_dtype': 'fp8', 'max_num_batched_tokens': 16384, 'max_num_seqs': 512, 'max_num_partial_prefills': 4, 'cuda_graph_sizes': [5000], 'long_prefill_token_threshold': 2048, 'enable_chunked_prefill': True, 'compilation_config': {"level": 3, "inductor_compile_config": {"enable_auto_functionalized_v2": false}}, 'disable_log_requests': True}
INFO 07-23 10:40:22 [config.py:793] This model supports multiple tasks: {'classify', 'score', 'embed', 'reward', 'generate'}. Defaulting to 'generate'.
WARNING 07-23 10:40:22 [arg_utils.py:1583] --kv-cache-dtype is not supported by the V1 Engine. Falling back to V0. 
INFO 07-23 10:40:22 [config.py:1503] Using fp8 data type to store kv cache. It reduces the GPU memory footprint and boosts the performance. Meanwhile, it may cause accuracy drop without a proper scaling factor
INFO 07-23 10:40:22 [config.py:2118] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 07-23 10:40:22 [config.py:2128] Concurrent partial prefills enabled with max_num_partial_prefills=4, max_long_partial_prefills=1, long_prefill_token_threshold=2048
INFO 07-23 10:40:22 [api_server.py:257] Started engine process with PID 284544
INFO 07-23 10:40:26 [__init__.py:243] Automatically detected platform cuda.
INFO 07-23 10:40:29 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 07-23 10:40:29 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 07-23 10:40:29 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 07-23 10:40:29 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.0.1) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=fp8,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level": 3, "compile_sizes": [], "inductor_compile_config": {"enable_auto_functionalized_v2": false}, "cudagraph_capture_sizes": [512, 504, 496, 488, 480, 472, 464, 456, 448, 440, 432, 424, 416, 408, 400, 392, 384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], "max_capture_size": 512}, use_cached_outputs=True, 
INFO 07-23 10:40:32 [cuda.py:273] Cannot use FlashAttention backend for FP8 KV cache.
WARNING 07-23 10:40:32 [cuda.py:275] Please use FlashInfer backend with FP8 KV Cache for better performance by setting environment variable VLLM_ATTENTION_BACKEND=FLASHINFER
INFO 07-23 10:40:32 [cuda.py:289] Using XFormers backend.
INFO 07-23 10:40:37 [parallel_state.py:1064] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
INFO 07-23 10:40:37 [model_runner.py:1170] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 07-23 10:40:37 [backends.py:35] Using InductorAdaptor
INFO 07-23 10:40:38 [weight_utils.py:291] Using model weights format ['*.safetensors']
INFO 07-23 10:40:39 [weight_utils.py:307] Time spent downloading weights for meta-llama/Llama-3.1-8B-Instruct: 0.608123 seconds
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.54it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.47it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.44it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  2.00it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.77it/s]

INFO 07-23 10:40:42 [default_loader.py:280] Loading weights took 2.28 seconds
INFO 07-23 10:40:42 [model_runner.py:1202] Model loading took 14.9889 GiB and 4.708293 seconds
INFO 07-23 10:40:48 [backends.py:459] Using cache directory: /root/.cache/vllm/torch_compile_cache/5ea595cc58/rank_0_0 for vLLM's torch.compile
INFO 07-23 10:40:48 [backends.py:469] Dynamo bytecode transform time: 5.77 s
INFO 07-23 10:40:51 [backends.py:132] Directly load the compiled graph(s) for shape None from the cache, took 0.116 s
INFO 07-23 10:40:51 [monitor.py:33] torch.compile takes 5.77 s in total
INFO 07-23 10:40:53 [worker.py:291] Memory profiling takes 10.57 seconds
INFO 07-23 10:40:53 [worker.py:291] the current vLLM instance can use total_gpu_memory (44.52GiB) x gpu_memory_utilization (0.91) = 40.51GiB
INFO 07-23 10:40:53 [worker.py:291] model weights take 14.99GiB; non_torch_memory takes 0.08GiB; PyTorch activation peak memory takes 2.54GiB; the rest of the memory reserved for KV Cache is 22.90GiB.
INFO 07-23 10:40:53 [executor_base.py:112] # cuda blocks: 23450, # CPU blocks: 4096
INFO 07-23 10:40:53 [executor_base.py:117] Maximum concurrency for 8192 tokens per request: 45.80x
INFO 07-23 10:40:54 [model_runner.py:1512] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|▏         | 1/67 [00:00<00:37,  1.76it/s]Capturing CUDA graph shapes:   3%|▎         | 2/67 [00:01<00:34,  1.89it/s]Capturing CUDA graph shapes:   4%|▍         | 3/67 [00:01<00:33,  1.91it/s]Capturing CUDA graph shapes:   6%|▌         | 4/67 [00:02<00:33,  1.90it/s]Capturing CUDA graph shapes:   7%|▋         | 5/67 [00:02<00:32,  1.92it/s]Capturing CUDA graph shapes:   9%|▉         | 6/67 [00:03<00:31,  1.95it/s]Capturing CUDA graph shapes:  10%|█         | 7/67 [00:03<00:30,  1.96it/s]Capturing CUDA graph shapes:  12%|█▏        | 8/67 [00:04<00:29,  1.98it/s]Capturing CUDA graph shapes:  13%|█▎        | 9/67 [00:04<00:29,  1.96it/s]Capturing CUDA graph shapes:  15%|█▍        | 10/67 [00:05<00:28,  1.97it/s]Capturing CUDA graph shapes:  16%|█▋        | 11/67 [00:05<00:28,  1.99it/s]Capturing CUDA graph shapes:  18%|█▊        | 12/67 [00:06<00:27,  1.99it/s]Capturing CUDA graph shapes:  19%|█▉        | 13/67 [00:06<00:27,  1.98it/s]Capturing CUDA graph shapes:  21%|██        | 14/67 [00:07<00:27,  1.95it/s]Capturing CUDA graph shapes:  22%|██▏       | 15/67 [00:07<00:27,  1.89it/s]Capturing CUDA graph shapes:  24%|██▍       | 16/67 [00:08<00:27,  1.88it/s]Capturing CUDA graph shapes:  25%|██▌       | 17/67 [00:08<00:26,  1.91it/s]Capturing CUDA graph shapes:  27%|██▋       | 18/67 [00:09<00:25,  1.92it/s]Capturing CUDA graph shapes:  28%|██▊       | 19/67 [00:09<00:24,  1.96it/s]Capturing CUDA graph shapes:  30%|██▉       | 20/67 [00:10<00:23,  1.96it/s]Capturing CUDA graph shapes:  31%|███▏      | 21/67 [00:10<00:23,  1.97it/s]Capturing CUDA graph shapes:  33%|███▎      | 22/67 [00:11<00:22,  1.98it/s]Capturing CUDA graph shapes:  34%|███▍      | 23/67 [00:11<00:22,  1.99it/s]Capturing CUDA graph shapes:  36%|███▌      | 24/67 [00:12<00:21,  1.99it/s]Capturing CUDA graph shapes:  37%|███▋      | 25/67 [00:12<00:20,  2.01it/s]Capturing CUDA graph shapes:  39%|███▉      | 26/67 [00:13<00:20,  2.02it/s]Capturing CUDA graph shapes:  40%|████      | 27/67 [00:13<00:19,  2.03it/s]Capturing CUDA graph shapes:  42%|████▏     | 28/67 [00:14<00:19,  2.04it/s]Capturing CUDA graph shapes:  43%|████▎     | 29/67 [00:14<00:18,  2.04it/s]Capturing CUDA graph shapes:  45%|████▍     | 30/67 [00:15<00:18,  2.05it/s]Capturing CUDA graph shapes:  46%|████▋     | 31/67 [00:15<00:18,  1.99it/s]Capturing CUDA graph shapes:  48%|████▊     | 32/67 [00:16<00:17,  2.01it/s]Capturing CUDA graph shapes:  49%|████▉     | 33/67 [00:16<00:17,  1.99it/s]Capturing CUDA graph shapes:  51%|█████     | 34/67 [00:17<00:16,  1.99it/s]Capturing CUDA graph shapes:  52%|█████▏    | 35/67 [00:17<00:16,  1.99it/s]Capturing CUDA graph shapes:  54%|█████▎    | 36/67 [00:18<00:15,  2.01it/s]Capturing CUDA graph shapes:  55%|█████▌    | 37/67 [00:18<00:14,  2.04it/s]Capturing CUDA graph shapes:  57%|█████▋    | 38/67 [00:19<00:14,  1.98it/s]Capturing CUDA graph shapes:  58%|█████▊    | 39/67 [00:19<00:13,  2.00it/s]Capturing CUDA graph shapes:  60%|█████▉    | 40/67 [00:20<00:13,  2.03it/s]Capturing CUDA graph shapes:  61%|██████    | 41/67 [00:20<00:12,  2.03it/s]Capturing CUDA graph shapes:  63%|██████▎   | 42/67 [00:21<00:12,  2.05it/s]Capturing CUDA graph shapes:  64%|██████▍   | 43/67 [00:21<00:11,  2.06it/s]Capturing CUDA graph shapes:  66%|██████▌   | 44/67 [00:22<00:11,  2.08it/s]Capturing CUDA graph shapes:  67%|██████▋   | 45/67 [00:22<00:10,  2.06it/s]Capturing CUDA graph shapes:  69%|██████▊   | 46/67 [00:23<00:10,  2.07it/s]Capturing CUDA graph shapes:  70%|███████   | 47/67 [00:23<00:09,  2.08it/s]Capturing CUDA graph shapes:  72%|███████▏  | 48/67 [00:24<00:09,  2.10it/s]Capturing CUDA graph shapes:  73%|███████▎  | 49/67 [00:24<00:08,  2.08it/s]Capturing CUDA graph shapes:  75%|███████▍  | 50/67 [00:25<00:08,  2.10it/s]Capturing CUDA graph shapes:  76%|███████▌  | 51/67 [00:25<00:07,  2.11it/s]Capturing CUDA graph shapes:  78%|███████▊  | 52/67 [00:25<00:07,  2.09it/s]Capturing CUDA graph shapes:  79%|███████▉  | 53/67 [00:26<00:06,  2.10it/s]Capturing CUDA graph shapes:  81%|████████  | 54/67 [00:26<00:06,  2.09it/s]Capturing CUDA graph shapes:  82%|████████▏ | 55/67 [00:27<00:05,  2.06it/s]Capturing CUDA graph shapes:  84%|████████▎ | 56/67 [00:27<00:05,  2.07it/s]Capturing CUDA graph shapes:  85%|████████▌ | 57/67 [00:28<00:04,  2.08it/s]Capturing CUDA graph shapes:  87%|████████▋ | 58/67 [00:28<00:04,  2.07it/s]Capturing CUDA graph shapes:  88%|████████▊ | 59/67 [00:29<00:03,  2.10it/s]Capturing CUDA graph shapes:  90%|████████▉ | 60/67 [00:29<00:03,  2.11it/s]Capturing CUDA graph shapes:  91%|█████████ | 61/67 [00:30<00:02,  2.13it/s]Capturing CUDA graph shapes:  93%|█████████▎| 62/67 [00:30<00:02,  2.14it/s]Capturing CUDA graph shapes:  94%|█████████▍| 63/67 [00:31<00:01,  2.08it/s]Capturing CUDA graph shapes:  96%|█████████▌| 64/67 [00:31<00:01,  2.11it/s]Capturing CUDA graph shapes:  97%|█████████▋| 65/67 [00:32<00:00,  2.13it/s]Capturing CUDA graph shapes:  99%|█████████▊| 66/67 [00:32<00:00,  2.11it/s]Capturing CUDA graph shapes: 100%|██████████| 67/67 [00:33<00:00,  2.12it/s]Capturing CUDA graph shapes: 100%|██████████| 67/67 [00:33<00:00,  2.02it/s]
INFO 07-23 10:41:27 [model_runner.py:1670] Graph capturing finished in 33 secs, took 0.45 GiB
INFO 07-23 10:41:27 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 45.29 seconds
WARNING 07-23 10:41:28 [config.py:1339] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 07-23 10:41:28 [serving_chat.py:117] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 07-23 10:41:29 [serving_completion.py:65] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 07-23 10:41:29 [api_server.py:1336] Starting vLLM API server on http://0.0.0.0:8000
INFO 07-23 10:41:29 [launcher.py:28] Available routes are:
INFO 07-23 10:41:29 [launcher.py:36] Route: /openapi.json, Methods: HEAD, GET
INFO 07-23 10:41:29 [launcher.py:36] Route: /docs, Methods: HEAD, GET
INFO 07-23 10:41:29 [launcher.py:36] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 07-23 10:41:29 [launcher.py:36] Route: /redoc, Methods: HEAD, GET
INFO 07-23 10:41:29 [launcher.py:36] Route: /health, Methods: GET
INFO 07-23 10:41:29 [launcher.py:36] Route: /load, Methods: GET
INFO 07-23 10:41:29 [launcher.py:36] Route: /ping, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /ping, Methods: GET
INFO 07-23 10:41:29 [launcher.py:36] Route: /tokenize, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /detokenize, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /v1/models, Methods: GET
INFO 07-23 10:41:29 [launcher.py:36] Route: /version, Methods: GET
INFO 07-23 10:41:29 [launcher.py:36] Route: /v1/chat/completions, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /v1/completions, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /v1/embeddings, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /pooling, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /classify, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /score, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /v1/score, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /v1/audio/transcriptions, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /rerank, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /v1/rerank, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /v2/rerank, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /invocations, Methods: POST
INFO 07-23 10:41:29 [launcher.py:36] Route: /metrics, Methods: GET
INFO:     Started server process [284235]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:33934 - "GET /health HTTP/1.1" 200 OK
INFO 07-23 10:44:26 [metrics.py:486] Avg prompt throughput: 1972.8 tokens/s, Avg generation throughput: 1.9 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 13334 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:44:32 [metrics.py:486] Avg prompt throughput: 12403.9 tokens/s, Avg generation throughput: 44.2 tokens/s, Running: 110 reqs, Swapped: 0 reqs, Pending: 13258 reqs, GPU KV cache usage: 26.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:44:37 [metrics.py:486] Avg prompt throughput: 12146.2 tokens/s, Avg generation throughput: 104.0 tokens/s, Running: 188 reqs, Swapped: 0 reqs, Pending: 13180 reqs, GPU KV cache usage: 44.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:44:42 [metrics.py:486] Avg prompt throughput: 11914.7 tokens/s, Avg generation throughput: 159.9 tokens/s, Running: 269 reqs, Swapped: 0 reqs, Pending: 13099 reqs, GPU KV cache usage: 61.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:44:48 [metrics.py:486] Avg prompt throughput: 11686.4 tokens/s, Avg generation throughput: 214.2 tokens/s, Running: 343 reqs, Swapped: 0 reqs, Pending: 13025 reqs, GPU KV cache usage: 79.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:44:53 [metrics.py:486] Avg prompt throughput: 11499.4 tokens/s, Avg generation throughput: 264.3 tokens/s, Running: 413 reqs, Swapped: 0 reqs, Pending: 12955 reqs, GPU KV cache usage: 97.2%, CPU KV cache usage: 0.0%.
WARNING 07-23 10:44:56 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-420 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
INFO 07-23 10:44:58 [metrics.py:486] Avg prompt throughput: 4597.8 tokens/s, Avg generation throughput: 2419.4 tokens/s, Running: 411 reqs, Swapped: 0 reqs, Pending: 12957 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:04 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3702.8 tokens/s, Running: 393 reqs, Swapped: 0 reqs, Pending: 12975 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:09 [metrics.py:486] Avg prompt throughput: 2474.8 tokens/s, Avg generation throughput: 2322.2 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 12958 reqs, GPU KV cache usage: 93.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:15 [metrics.py:486] Avg prompt throughput: 11300.9 tokens/s, Avg generation throughput: 253.0 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 12884 reqs, GPU KV cache usage: 90.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:20 [metrics.py:486] Avg prompt throughput: 11308.0 tokens/s, Avg generation throughput: 250.4 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 12805 reqs, GPU KV cache usage: 88.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:26 [metrics.py:486] Avg prompt throughput: 11344.4 tokens/s, Avg generation throughput: 250.2 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 12729 reqs, GPU KV cache usage: 85.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:32 [metrics.py:486] Avg prompt throughput: 11274.0 tokens/s, Avg generation throughput: 245.8 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 12656 reqs, GPU KV cache usage: 83.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:37 [metrics.py:486] Avg prompt throughput: 11320.1 tokens/s, Avg generation throughput: 257.9 tokens/s, Running: 410 reqs, Swapped: 0 reqs, Pending: 12576 reqs, GPU KV cache usage: 95.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:42 [metrics.py:486] Avg prompt throughput: 6008.9 tokens/s, Avg generation throughput: 1930.8 tokens/s, Running: 418 reqs, Swapped: 0 reqs, Pending: 12558 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:47 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3126.5 tokens/s, Running: 406 reqs, Swapped: 0 reqs, Pending: 12558 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:52 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3622.1 tokens/s, Running: 389 reqs, Swapped: 0 reqs, Pending: 12558 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:45:57 [metrics.py:486] Avg prompt throughput: 10316.8 tokens/s, Avg generation throughput: 529.0 tokens/s, Running: 372 reqs, Swapped: 0 reqs, Pending: 12472 reqs, GPU KV cache usage: 92.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:46:03 [metrics.py:486] Avg prompt throughput: 11142.6 tokens/s, Avg generation throughput: 254.8 tokens/s, Running: 365 reqs, Swapped: 0 reqs, Pending: 12403 reqs, GPU KV cache usage: 89.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:46:09 [metrics.py:486] Avg prompt throughput: 11160.9 tokens/s, Avg generation throughput: 253.8 tokens/s, Running: 368 reqs, Swapped: 0 reqs, Pending: 12329 reqs, GPU KV cache usage: 87.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:46:15 [metrics.py:486] Avg prompt throughput: 11124.1 tokens/s, Avg generation throughput: 254.2 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 12259 reqs, GPU KV cache usage: 85.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:46:21 [metrics.py:486] Avg prompt throughput: 11104.1 tokens/s, Avg generation throughput: 246.3 tokens/s, Running: 378 reqs, Swapped: 0 reqs, Pending: 12180 reqs, GPU KV cache usage: 88.4%, CPU KV cache usage: 0.0%.
INFO 07-23 10:46:26 [metrics.py:486] Avg prompt throughput: 10794.7 tokens/s, Avg generation throughput: 399.2 tokens/s, Running: 424 reqs, Swapped: 0 reqs, Pending: 12134 reqs, GPU KV cache usage: 99.1%, CPU KV cache usage: 0.0%.
WARNING 07-23 10:46:29 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-1223 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
INFO 07-23 10:46:31 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3146.5 tokens/s, Running: 407 reqs, Swapped: 0 reqs, Pending: 12151 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:46:36 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3590.5 tokens/s, Running: 388 reqs, Swapped: 0 reqs, Pending: 12170 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:46:41 [metrics.py:486] Avg prompt throughput: 6215.9 tokens/s, Avg generation throughput: 1690.7 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 12121 reqs, GPU KV cache usage: 92.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:46:47 [metrics.py:486] Avg prompt throughput: 11001.9 tokens/s, Avg generation throughput: 243.1 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 12049 reqs, GPU KV cache usage: 90.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:46:53 [metrics.py:486] Avg prompt throughput: 10987.4 tokens/s, Avg generation throughput: 242.6 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 11973 reqs, GPU KV cache usage: 88.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:46:58 [metrics.py:486] Avg prompt throughput: 10964.5 tokens/s, Avg generation throughput: 244.2 tokens/s, Running: 360 reqs, Swapped: 0 reqs, Pending: 11900 reqs, GPU KV cache usage: 86.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:47:04 [metrics.py:486] Avg prompt throughput: 10968.4 tokens/s, Avg generation throughput: 246.4 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 11825 reqs, GPU KV cache usage: 84.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:47:10 [metrics.py:486] Avg prompt throughput: 10981.0 tokens/s, Avg generation throughput: 261.0 tokens/s, Running: 419 reqs, Swapped: 0 reqs, Pending: 11759 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:47:15 [metrics.py:486] Avg prompt throughput: 2164.2 tokens/s, Avg generation throughput: 2439.5 tokens/s, Running: 407 reqs, Swapped: 0 reqs, Pending: 11758 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:47:20 [metrics.py:486] Avg prompt throughput: 237.0 tokens/s, Avg generation throughput: 3516.2 tokens/s, Running: 388 reqs, Swapped: 0 reqs, Pending: 11757 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:47:26 [metrics.py:486] Avg prompt throughput: 4128.3 tokens/s, Avg generation throughput: 2344.1 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 11713 reqs, GPU KV cache usage: 93.4%, CPU KV cache usage: 0.0%.
INFO 07-23 10:47:32 [metrics.py:486] Avg prompt throughput: 10991.7 tokens/s, Avg generation throughput: 241.0 tokens/s, Running: 346 reqs, Swapped: 0 reqs, Pending: 11645 reqs, GPU KV cache usage: 90.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:47:38 [metrics.py:486] Avg prompt throughput: 11038.4 tokens/s, Avg generation throughput: 237.3 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 11574 reqs, GPU KV cache usage: 88.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:47:44 [metrics.py:486] Avg prompt throughput: 11057.0 tokens/s, Avg generation throughput: 236.4 tokens/s, Running: 343 reqs, Swapped: 0 reqs, Pending: 11502 reqs, GPU KV cache usage: 86.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:47:49 [metrics.py:486] Avg prompt throughput: 11040.4 tokens/s, Avg generation throughput: 236.4 tokens/s, Running: 342 reqs, Swapped: 0 reqs, Pending: 11427 reqs, GPU KV cache usage: 84.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:47:56 [metrics.py:486] Avg prompt throughput: 9731.5 tokens/s, Avg generation throughput: 219.1 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 11356 reqs, GPU KV cache usage: 98.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:48:01 [metrics.py:486] Avg prompt throughput: 3453.9 tokens/s, Avg generation throughput: 2599.0 tokens/s, Running: 396 reqs, Swapped: 0 reqs, Pending: 11362 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 10:48:04 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-1996 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
INFO 07-23 10:48:06 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3616.7 tokens/s, Running: 377 reqs, Swapped: 0 reqs, Pending: 11380 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:48:11 [metrics.py:486] Avg prompt throughput: 3880.1 tokens/s, Avg generation throughput: 1976.6 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 11353 reqs, GPU KV cache usage: 93.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:48:17 [metrics.py:486] Avg prompt throughput: 10989.5 tokens/s, Avg generation throughput: 237.4 tokens/s, Running: 342 reqs, Swapped: 0 reqs, Pending: 11285 reqs, GPU KV cache usage: 91.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:48:23 [metrics.py:486] Avg prompt throughput: 10999.3 tokens/s, Avg generation throughput: 235.9 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 11208 reqs, GPU KV cache usage: 89.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:48:29 [metrics.py:486] Avg prompt throughput: 10979.4 tokens/s, Avg generation throughput: 237.4 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 11135 reqs, GPU KV cache usage: 87.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:48:35 [metrics.py:486] Avg prompt throughput: 10945.4 tokens/s, Avg generation throughput: 234.9 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 11064 reqs, GPU KV cache usage: 85.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:48:41 [metrics.py:486] Avg prompt throughput: 10948.0 tokens/s, Avg generation throughput: 245.1 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 10987 reqs, GPU KV cache usage: 97.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:48:46 [metrics.py:486] Avg prompt throughput: 4630.4 tokens/s, Avg generation throughput: 2238.0 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 10977 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:48:51 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3559.3 tokens/s, Running: 383 reqs, Swapped: 0 reqs, Pending: 10979 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:48:57 [metrics.py:486] Avg prompt throughput: 2664.9 tokens/s, Avg generation throughput: 2337.2 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 10937 reqs, GPU KV cache usage: 93.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:49:03 [metrics.py:486] Avg prompt throughput: 10998.5 tokens/s, Avg generation throughput: 253.8 tokens/s, Running: 368 reqs, Swapped: 0 reqs, Pending: 10860 reqs, GPU KV cache usage: 91.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:49:08 [metrics.py:486] Avg prompt throughput: 10981.6 tokens/s, Avg generation throughput: 252.8 tokens/s, Running: 368 reqs, Swapped: 0 reqs, Pending: 10787 reqs, GPU KV cache usage: 89.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:49:14 [metrics.py:486] Avg prompt throughput: 10929.7 tokens/s, Avg generation throughput: 248.5 tokens/s, Running: 367 reqs, Swapped: 0 reqs, Pending: 10718 reqs, GPU KV cache usage: 87.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:49:20 [metrics.py:486] Avg prompt throughput: 10953.5 tokens/s, Avg generation throughput: 248.7 tokens/s, Running: 363 reqs, Swapped: 0 reqs, Pending: 10647 reqs, GPU KV cache usage: 85.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:49:26 [metrics.py:486] Avg prompt throughput: 11012.2 tokens/s, Avg generation throughput: 256.8 tokens/s, Running: 412 reqs, Swapped: 0 reqs, Pending: 10567 reqs, GPU KV cache usage: 96.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:49:31 [metrics.py:486] Avg prompt throughput: 5290.3 tokens/s, Avg generation throughput: 2089.6 tokens/s, Running: 415 reqs, Swapped: 0 reqs, Pending: 10564 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:49:36 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3650.3 tokens/s, Running: 399 reqs, Swapped: 0 reqs, Pending: 10578 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 10:49:38 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-2784 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
INFO 07-23 10:49:42 [metrics.py:486] Avg prompt throughput: 2122.1 tokens/s, Avg generation throughput: 2462.1 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 10565 reqs, GPU KV cache usage: 93.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:49:48 [metrics.py:486] Avg prompt throughput: 10973.2 tokens/s, Avg generation throughput: 241.5 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 10488 reqs, GPU KV cache usage: 91.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:49:54 [metrics.py:486] Avg prompt throughput: 10969.6 tokens/s, Avg generation throughput: 240.7 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 10417 reqs, GPU KV cache usage: 89.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:00 [metrics.py:486] Avg prompt throughput: 10989.6 tokens/s, Avg generation throughput: 245.3 tokens/s, Running: 363 reqs, Swapped: 0 reqs, Pending: 10337 reqs, GPU KV cache usage: 87.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:06 [metrics.py:486] Avg prompt throughput: 10976.8 tokens/s, Avg generation throughput: 251.6 tokens/s, Running: 366 reqs, Swapped: 0 reqs, Pending: 10256 reqs, GPU KV cache usage: 85.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:11 [metrics.py:486] Avg prompt throughput: 10995.9 tokens/s, Avg generation throughput: 258.0 tokens/s, Running: 407 reqs, Swapped: 0 reqs, Pending: 10186 reqs, GPU KV cache usage: 95.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:16 [metrics.py:486] Avg prompt throughput: 6079.7 tokens/s, Avg generation throughput: 1813.9 tokens/s, Running: 414 reqs, Swapped: 0 reqs, Pending: 10170 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:22 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3113.4 tokens/s, Running: 399 reqs, Swapped: 0 reqs, Pending: 10171 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:27 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3581.9 tokens/s, Running: 384 reqs, Swapped: 0 reqs, Pending: 10171 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:32 [metrics.py:486] Avg prompt throughput: 10189.6 tokens/s, Avg generation throughput: 489.7 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 10092 reqs, GPU KV cache usage: 92.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:38 [metrics.py:486] Avg prompt throughput: 10946.0 tokens/s, Avg generation throughput: 248.2 tokens/s, Running: 366 reqs, Swapped: 0 reqs, Pending: 10015 reqs, GPU KV cache usage: 89.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:44 [metrics.py:486] Avg prompt throughput: 10984.6 tokens/s, Avg generation throughput: 248.2 tokens/s, Running: 359 reqs, Swapped: 0 reqs, Pending: 9937 reqs, GPU KV cache usage: 87.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:49 [metrics.py:486] Avg prompt throughput: 10954.6 tokens/s, Avg generation throughput: 242.5 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 9866 reqs, GPU KV cache usage: 85.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:50:55 [metrics.py:486] Avg prompt throughput: 10993.7 tokens/s, Avg generation throughput: 243.6 tokens/s, Running: 386 reqs, Swapped: 0 reqs, Pending: 9785 reqs, GPU KV cache usage: 88.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:51:00 [metrics.py:486] Avg prompt throughput: 10344.6 tokens/s, Avg generation throughput: 495.2 tokens/s, Running: 432 reqs, Swapped: 0 reqs, Pending: 9739 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:51:05 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3221.7 tokens/s, Running: 417 reqs, Swapped: 0 reqs, Pending: 9754 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:51:10 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3643.5 tokens/s, Running: 397 reqs, Swapped: 0 reqs, Pending: 9773 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
WARNING 07-23 10:51:11 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-3591 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
INFO 07-23 10:51:16 [metrics.py:486] Avg prompt throughput: 6109.8 tokens/s, Avg generation throughput: 1707.0 tokens/s, Running: 366 reqs, Swapped: 0 reqs, Pending: 9727 reqs, GPU KV cache usage: 92.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:51:21 [metrics.py:486] Avg prompt throughput: 10944.8 tokens/s, Avg generation throughput: 245.6 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 9660 reqs, GPU KV cache usage: 90.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:51:27 [metrics.py:486] Avg prompt throughput: 10960.1 tokens/s, Avg generation throughput: 239.8 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 9591 reqs, GPU KV cache usage: 88.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:51:32 [metrics.py:486] Avg prompt throughput: 9458.3 tokens/s, Avg generation throughput: 207.0 tokens/s, Running: 359 reqs, Swapped: 0 reqs, Pending: 9526 reqs, GPU KV cache usage: 86.4%, CPU KV cache usage: 0.0%.
INFO 07-23 10:51:38 [metrics.py:486] Avg prompt throughput: 11020.5 tokens/s, Avg generation throughput: 244.4 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 9460 reqs, GPU KV cache usage: 84.4%, CPU KV cache usage: 0.0%.
INFO 07-23 10:51:44 [metrics.py:486] Avg prompt throughput: 10987.8 tokens/s, Avg generation throughput: 243.6 tokens/s, Running: 390 reqs, Swapped: 0 reqs, Pending: 9392 reqs, GPU KV cache usage: 96.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:51:49 [metrics.py:486] Avg prompt throughput: 5574.0 tokens/s, Avg generation throughput: 1899.3 tokens/s, Running: 391 reqs, Swapped: 0 reqs, Pending: 9379 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:51:54 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3629.2 tokens/s, Running: 372 reqs, Swapped: 0 reqs, Pending: 9379 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:00 [metrics.py:486] Avg prompt throughput: 1952.8 tokens/s, Avg generation throughput: 2497.2 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 9349 reqs, GPU KV cache usage: 94.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:06 [metrics.py:486] Avg prompt throughput: 10938.4 tokens/s, Avg generation throughput: 238.7 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 9272 reqs, GPU KV cache usage: 91.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:12 [metrics.py:486] Avg prompt throughput: 10883.0 tokens/s, Avg generation throughput: 238.6 tokens/s, Running: 343 reqs, Swapped: 0 reqs, Pending: 9204 reqs, GPU KV cache usage: 89.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:17 [metrics.py:486] Avg prompt throughput: 10948.3 tokens/s, Avg generation throughput: 234.6 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 9128 reqs, GPU KV cache usage: 87.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:23 [metrics.py:486] Avg prompt throughput: 10969.7 tokens/s, Avg generation throughput: 239.6 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 9051 reqs, GPU KV cache usage: 85.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:29 [metrics.py:486] Avg prompt throughput: 10981.0 tokens/s, Avg generation throughput: 250.2 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 8977 reqs, GPU KV cache usage: 94.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:34 [metrics.py:486] Avg prompt throughput: 6318.1 tokens/s, Avg generation throughput: 1751.2 tokens/s, Running: 416 reqs, Swapped: 0 reqs, Pending: 8963 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:39 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3634.8 tokens/s, Running: 395 reqs, Swapped: 0 reqs, Pending: 8984 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:44 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3060.4 tokens/s, Running: 380 reqs, Swapped: 0 reqs, Pending: 8997 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:49 [metrics.py:486] Avg prompt throughput: 10388.9 tokens/s, Avg generation throughput: 424.9 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 8924 reqs, GPU KV cache usage: 92.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:52:55 [metrics.py:486] Avg prompt throughput: 11023.6 tokens/s, Avg generation throughput: 242.0 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 8849 reqs, GPU KV cache usage: 90.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:01 [metrics.py:486] Avg prompt throughput: 10970.4 tokens/s, Avg generation throughput: 239.3 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 8784 reqs, GPU KV cache usage: 87.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:07 [metrics.py:486] Avg prompt throughput: 11013.6 tokens/s, Avg generation throughput: 235.3 tokens/s, Running: 340 reqs, Swapped: 0 reqs, Pending: 8712 reqs, GPU KV cache usage: 85.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:13 [metrics.py:486] Avg prompt throughput: 11045.0 tokens/s, Avg generation throughput: 234.4 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 8639 reqs, GPU KV cache usage: 88.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:18 [metrics.py:486] Avg prompt throughput: 10926.4 tokens/s, Avg generation throughput: 297.0 tokens/s, Running: 401 reqs, Swapped: 0 reqs, Pending: 8595 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:23 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3577.8 tokens/s, Running: 385 reqs, Swapped: 0 reqs, Pending: 8596 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:28 [metrics.py:486] Avg prompt throughput: 291.9 tokens/s, Avg generation throughput: 3064.1 tokens/s, Running: 365 reqs, Swapped: 0 reqs, Pending: 8596 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:34 [metrics.py:486] Avg prompt throughput: 7518.5 tokens/s, Avg generation throughput: 1272.7 tokens/s, Running: 341 reqs, Swapped: 0 reqs, Pending: 8526 reqs, GPU KV cache usage: 92.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:40 [metrics.py:486] Avg prompt throughput: 10997.5 tokens/s, Avg generation throughput: 235.6 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 8449 reqs, GPU KV cache usage: 90.4%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:46 [metrics.py:486] Avg prompt throughput: 10971.1 tokens/s, Avg generation throughput: 241.4 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 8381 reqs, GPU KV cache usage: 88.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:52 [metrics.py:486] Avg prompt throughput: 10958.1 tokens/s, Avg generation throughput: 239.2 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 8308 reqs, GPU KV cache usage: 86.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:53:58 [metrics.py:486] Avg prompt throughput: 10958.6 tokens/s, Avg generation throughput: 238.8 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 8235 reqs, GPU KV cache usage: 87.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:54:03 [metrics.py:486] Avg prompt throughput: 10886.4 tokens/s, Avg generation throughput: 289.1 tokens/s, Running: 411 reqs, Swapped: 0 reqs, Pending: 8186 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 10:54:04 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-5181 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
INFO 07-23 10:54:08 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3630.8 tokens/s, Running: 395 reqs, Swapped: 0 reqs, Pending: 8201 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:54:13 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3081.3 tokens/s, Running: 379 reqs, Swapped: 0 reqs, Pending: 8216 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:54:19 [metrics.py:486] Avg prompt throughput: 7109.1 tokens/s, Avg generation throughput: 1421.0 tokens/s, Running: 350 reqs, Swapped: 0 reqs, Pending: 8159 reqs, GPU KV cache usage: 92.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:54:25 [metrics.py:486] Avg prompt throughput: 10997.7 tokens/s, Avg generation throughput: 238.0 tokens/s, Running: 343 reqs, Swapped: 0 reqs, Pending: 8088 reqs, GPU KV cache usage: 90.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:54:31 [metrics.py:486] Avg prompt throughput: 10967.8 tokens/s, Avg generation throughput: 235.6 tokens/s, Running: 346 reqs, Swapped: 0 reqs, Pending: 8018 reqs, GPU KV cache usage: 88.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:54:37 [metrics.py:486] Avg prompt throughput: 10978.2 tokens/s, Avg generation throughput: 235.8 tokens/s, Running: 350 reqs, Swapped: 0 reqs, Pending: 7942 reqs, GPU KV cache usage: 86.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:54:43 [metrics.py:486] Avg prompt throughput: 10990.9 tokens/s, Avg generation throughput: 237.3 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 7866 reqs, GPU KV cache usage: 86.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:54:48 [metrics.py:486] Avg prompt throughput: 10934.7 tokens/s, Avg generation throughput: 273.0 tokens/s, Running: 413 reqs, Swapped: 0 reqs, Pending: 7810 reqs, GPU KV cache usage: 98.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:54:54 [metrics.py:486] Avg prompt throughput: 237.3 tokens/s, Avg generation throughput: 3120.4 tokens/s, Running: 399 reqs, Swapped: 0 reqs, Pending: 7809 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:54:59 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3572.9 tokens/s, Running: 380 reqs, Swapped: 0 reqs, Pending: 7809 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:55:04 [metrics.py:486] Avg prompt throughput: 6786.3 tokens/s, Avg generation throughput: 1520.9 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 7754 reqs, GPU KV cache usage: 92.4%, CPU KV cache usage: 0.0%.
INFO 07-23 10:55:10 [metrics.py:486] Avg prompt throughput: 10900.9 tokens/s, Avg generation throughput: 238.6 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 7680 reqs, GPU KV cache usage: 90.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:55:16 [metrics.py:486] Avg prompt throughput: 10895.2 tokens/s, Avg generation throughput: 241.8 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 7608 reqs, GPU KV cache usage: 88.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:55:22 [metrics.py:486] Avg prompt throughput: 10912.4 tokens/s, Avg generation throughput: 240.0 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 7537 reqs, GPU KV cache usage: 86.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:55:28 [metrics.py:486] Avg prompt throughput: 10919.2 tokens/s, Avg generation throughput: 237.0 tokens/s, Running: 343 reqs, Swapped: 0 reqs, Pending: 7467 reqs, GPU KV cache usage: 84.4%, CPU KV cache usage: 0.0%.
INFO 07-23 10:55:34 [metrics.py:486] Avg prompt throughput: 10915.6 tokens/s, Avg generation throughput: 249.8 tokens/s, Running: 395 reqs, Swapped: 0 reqs, Pending: 7415 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:55:39 [metrics.py:486] Avg prompt throughput: 910.6 tokens/s, Avg generation throughput: 2831.5 tokens/s, Running: 385 reqs, Swapped: 0 reqs, Pending: 7424 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
WARNING 07-23 10:55:40 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-5941 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
INFO 07-23 10:55:44 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3615.3 tokens/s, Running: 368 reqs, Swapped: 0 reqs, Pending: 7441 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:55:49 [metrics.py:486] Avg prompt throughput: 6345.4 tokens/s, Avg generation throughput: 1615.9 tokens/s, Running: 340 reqs, Swapped: 0 reqs, Pending: 7397 reqs, GPU KV cache usage: 93.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:55:55 [metrics.py:486] Avg prompt throughput: 10980.8 tokens/s, Avg generation throughput: 233.0 tokens/s, Running: 339 reqs, Swapped: 0 reqs, Pending: 7323 reqs, GPU KV cache usage: 90.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:01 [metrics.py:486] Avg prompt throughput: 10935.1 tokens/s, Avg generation throughput: 228.4 tokens/s, Running: 339 reqs, Swapped: 0 reqs, Pending: 7252 reqs, GPU KV cache usage: 89.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:07 [metrics.py:486] Avg prompt throughput: 10983.8 tokens/s, Avg generation throughput: 232.9 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 7174 reqs, GPU KV cache usage: 86.4%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:13 [metrics.py:486] Avg prompt throughput: 11030.5 tokens/s, Avg generation throughput: 240.7 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 7094 reqs, GPU KV cache usage: 84.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:18 [metrics.py:486] Avg prompt throughput: 9579.8 tokens/s, Avg generation throughput: 221.8 tokens/s, Running: 406 reqs, Swapped: 0 reqs, Pending: 7039 reqs, GPU KV cache usage: 96.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:23 [metrics.py:486] Avg prompt throughput: 5146.7 tokens/s, Avg generation throughput: 2129.0 tokens/s, Running: 411 reqs, Swapped: 0 reqs, Pending: 7028 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:28 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3636.0 tokens/s, Running: 395 reqs, Swapped: 0 reqs, Pending: 7028 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:34 [metrics.py:486] Avg prompt throughput: 2167.9 tokens/s, Avg generation throughput: 2564.7 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 6998 reqs, GPU KV cache usage: 93.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:40 [metrics.py:486] Avg prompt throughput: 10966.7 tokens/s, Avg generation throughput: 248.1 tokens/s, Running: 372 reqs, Swapped: 0 reqs, Pending: 6920 reqs, GPU KV cache usage: 91.4%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:46 [metrics.py:486] Avg prompt throughput: 10936.4 tokens/s, Avg generation throughput: 251.1 tokens/s, Running: 369 reqs, Swapped: 0 reqs, Pending: 6847 reqs, GPU KV cache usage: 89.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:51 [metrics.py:486] Avg prompt throughput: 10940.7 tokens/s, Avg generation throughput: 247.9 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 6776 reqs, GPU KV cache usage: 87.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:56:57 [metrics.py:486] Avg prompt throughput: 10897.0 tokens/s, Avg generation throughput: 238.6 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 6704 reqs, GPU KV cache usage: 84.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:57:03 [metrics.py:486] Avg prompt throughput: 10902.1 tokens/s, Avg generation throughput: 245.2 tokens/s, Running: 396 reqs, Swapped: 0 reqs, Pending: 6636 reqs, GPU KV cache usage: 94.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:57:08 [metrics.py:486] Avg prompt throughput: 6123.6 tokens/s, Avg generation throughput: 1777.8 tokens/s, Running: 406 reqs, Swapped: 0 reqs, Pending: 6622 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:57:13 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3579.2 tokens/s, Running: 386 reqs, Swapped: 0 reqs, Pending: 6642 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 10:57:14 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-6721 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
INFO 07-23 10:57:19 [metrics.py:486] Avg prompt throughput: 1085.6 tokens/s, Avg generation throughput: 2852.8 tokens/s, Running: 344 reqs, Swapped: 0 reqs, Pending: 6634 reqs, GPU KV cache usage: 93.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:57:25 [metrics.py:486] Avg prompt throughput: 10989.1 tokens/s, Avg generation throughput: 234.8 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 6557 reqs, GPU KV cache usage: 91.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:57:30 [metrics.py:486] Avg prompt throughput: 11015.4 tokens/s, Avg generation throughput: 236.8 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 6484 reqs, GPU KV cache usage: 88.9%, CPU KV cache usage: 0.0%.
INFO 07-23 10:57:36 [metrics.py:486] Avg prompt throughput: 11031.0 tokens/s, Avg generation throughput: 239.0 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 6409 reqs, GPU KV cache usage: 87.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:57:42 [metrics.py:486] Avg prompt throughput: 11006.7 tokens/s, Avg generation throughput: 243.2 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 6335 reqs, GPU KV cache usage: 85.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:57:48 [metrics.py:486] Avg prompt throughput: 10965.8 tokens/s, Avg generation throughput: 245.2 tokens/s, Running: 395 reqs, Swapped: 0 reqs, Pending: 6263 reqs, GPU KV cache usage: 93.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:57:53 [metrics.py:486] Avg prompt throughput: 7485.6 tokens/s, Avg generation throughput: 1415.9 tokens/s, Running: 417 reqs, Swapped: 0 reqs, Pending: 6236 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:57:58 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3211.7 tokens/s, Running: 399 reqs, Swapped: 0 reqs, Pending: 6236 reqs, GPU KV cache usage: 99.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:58:03 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3589.1 tokens/s, Running: 383 reqs, Swapped: 0 reqs, Pending: 6237 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:58:08 [metrics.py:486] Avg prompt throughput: 9405.9 tokens/s, Avg generation throughput: 731.2 tokens/s, Running: 367 reqs, Swapped: 0 reqs, Pending: 6158 reqs, GPU KV cache usage: 92.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:58:14 [metrics.py:486] Avg prompt throughput: 10923.4 tokens/s, Avg generation throughput: 245.3 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 6089 reqs, GPU KV cache usage: 90.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:58:20 [metrics.py:486] Avg prompt throughput: 10987.1 tokens/s, Avg generation throughput: 242.8 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 6017 reqs, GPU KV cache usage: 87.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:58:26 [metrics.py:486] Avg prompt throughput: 10996.5 tokens/s, Avg generation throughput: 242.8 tokens/s, Running: 361 reqs, Swapped: 0 reqs, Pending: 5941 reqs, GPU KV cache usage: 85.8%, CPU KV cache usage: 0.0%.
INFO 07-23 10:58:32 [metrics.py:486] Avg prompt throughput: 10941.9 tokens/s, Avg generation throughput: 245.1 tokens/s, Running: 372 reqs, Swapped: 0 reqs, Pending: 5867 reqs, GPU KV cache usage: 87.2%, CPU KV cache usage: 0.0%.
INFO 07-23 10:58:37 [metrics.py:486] Avg prompt throughput: 10854.4 tokens/s, Avg generation throughput: 295.7 tokens/s, Running: 417 reqs, Swapped: 0 reqs, Pending: 5820 reqs, GPU KV cache usage: 98.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:58:42 [metrics.py:486] Avg prompt throughput: 274.2 tokens/s, Avg generation throughput: 3164.0 tokens/s, Running: 403 reqs, Swapped: 0 reqs, Pending: 5833 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:58:47 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3546.2 tokens/s, Running: 385 reqs, Swapped: 0 reqs, Pending: 5851 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
WARNING 07-23 10:58:48 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-7514 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
INFO 07-23 10:58:54 [metrics.py:486] Avg prompt throughput: 6270.4 tokens/s, Avg generation throughput: 1384.4 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 5788 reqs, GPU KV cache usage: 92.5%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:00 [metrics.py:486] Avg prompt throughput: 11000.5 tokens/s, Avg generation throughput: 243.1 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 5719 reqs, GPU KV cache usage: 90.6%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:05 [metrics.py:486] Avg prompt throughput: 11014.5 tokens/s, Avg generation throughput: 243.9 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 5643 reqs, GPU KV cache usage: 88.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:11 [metrics.py:486] Avg prompt throughput: 10940.1 tokens/s, Avg generation throughput: 240.6 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 5574 reqs, GPU KV cache usage: 86.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:17 [metrics.py:486] Avg prompt throughput: 10939.0 tokens/s, Avg generation throughput: 238.1 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 5501 reqs, GPU KV cache usage: 85.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:23 [metrics.py:486] Avg prompt throughput: 10959.3 tokens/s, Avg generation throughput: 261.0 tokens/s, Running: 406 reqs, Swapped: 0 reqs, Pending: 5448 reqs, GPU KV cache usage: 98.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:28 [metrics.py:486] Avg prompt throughput: 221.7 tokens/s, Avg generation throughput: 3575.1 tokens/s, Running: 393 reqs, Swapped: 0 reqs, Pending: 5447 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:33 [metrics.py:486] Avg prompt throughput: 225.6 tokens/s, Avg generation throughput: 3541.7 tokens/s, Running: 374 reqs, Swapped: 0 reqs, Pending: 5446 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:39 [metrics.py:486] Avg prompt throughput: 6280.0 tokens/s, Avg generation throughput: 1273.2 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 5392 reqs, GPU KV cache usage: 92.7%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:44 [metrics.py:486] Avg prompt throughput: 10979.9 tokens/s, Avg generation throughput: 234.1 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 5317 reqs, GPU KV cache usage: 90.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:50 [metrics.py:486] Avg prompt throughput: 11008.2 tokens/s, Avg generation throughput: 236.6 tokens/s, Running: 346 reqs, Swapped: 0 reqs, Pending: 5244 reqs, GPU KV cache usage: 88.1%, CPU KV cache usage: 0.0%.
INFO 07-23 10:59:56 [metrics.py:486] Avg prompt throughput: 11005.7 tokens/s, Avg generation throughput: 236.6 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 5172 reqs, GPU KV cache usage: 86.6%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:02 [metrics.py:486] Avg prompt throughput: 11020.5 tokens/s, Avg generation throughput: 239.2 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 5095 reqs, GPU KV cache usage: 84.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:08 [metrics.py:486] Avg prompt throughput: 11009.1 tokens/s, Avg generation throughput: 259.9 tokens/s, Running: 415 reqs, Swapped: 0 reqs, Pending: 5032 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:13 [metrics.py:486] Avg prompt throughput: 1542.9 tokens/s, Avg generation throughput: 3208.8 tokens/s, Running: 401 reqs, Swapped: 0 reqs, Pending: 5046 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:18 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3151.5 tokens/s, Running: 381 reqs, Swapped: 0 reqs, Pending: 5066 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:24 [metrics.py:486] Avg prompt throughput: 5652.0 tokens/s, Avg generation throughput: 1866.4 tokens/s, Running: 360 reqs, Swapped: 0 reqs, Pending: 5020 reqs, GPU KV cache usage: 93.1%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:29 [metrics.py:486] Avg prompt throughput: 10983.7 tokens/s, Avg generation throughput: 244.9 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4948 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:35 [metrics.py:486] Avg prompt throughput: 10933.4 tokens/s, Avg generation throughput: 240.4 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 4874 reqs, GPU KV cache usage: 88.7%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:41 [metrics.py:486] Avg prompt throughput: 10964.6 tokens/s, Avg generation throughput: 241.1 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 4797 reqs, GPU KV cache usage: 86.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:47 [metrics.py:486] Avg prompt throughput: 11011.1 tokens/s, Avg generation throughput: 243.7 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4725 reqs, GPU KV cache usage: 84.5%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:53 [metrics.py:486] Avg prompt throughput: 10954.5 tokens/s, Avg generation throughput: 256.6 tokens/s, Running: 413 reqs, Swapped: 0 reqs, Pending: 4658 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:00:58 [metrics.py:486] Avg prompt throughput: 2528.6 tokens/s, Avg generation throughput: 2452.1 tokens/s, Running: 404 reqs, Swapped: 0 reqs, Pending: 4658 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:01:03 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3574.0 tokens/s, Running: 382 reqs, Swapped: 0 reqs, Pending: 4658 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:01:08 [metrics.py:486] Avg prompt throughput: 4173.3 tokens/s, Avg generation throughput: 2366.1 tokens/s, Running: 359 reqs, Swapped: 0 reqs, Pending: 4609 reqs, GPU KV cache usage: 93.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:01:14 [metrics.py:486] Avg prompt throughput: 10988.6 tokens/s, Avg generation throughput: 243.4 tokens/s, Running: 360 reqs, Swapped: 0 reqs, Pending: 4534 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:01:20 [metrics.py:486] Avg prompt throughput: 11037.4 tokens/s, Avg generation throughput: 246.4 tokens/s, Running: 361 reqs, Swapped: 0 reqs, Pending: 4460 reqs, GPU KV cache usage: 88.7%, CPU KV cache usage: 0.0%.
INFO 07-23 11:01:27 [metrics.py:486] Avg prompt throughput: 10009.0 tokens/s, Avg generation throughput: 221.4 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4388 reqs, GPU KV cache usage: 86.4%, CPU KV cache usage: 0.0%.
INFO 07-23 11:01:32 [metrics.py:486] Avg prompt throughput: 11089.1 tokens/s, Avg generation throughput: 246.3 tokens/s, Running: 365 reqs, Swapped: 0 reqs, Pending: 4306 reqs, GPU KV cache usage: 84.6%, CPU KV cache usage: 0.0%.
INFO 07-23 11:01:38 [metrics.py:486] Avg prompt throughput: 11012.0 tokens/s, Avg generation throughput: 260.6 tokens/s, Running: 419 reqs, Swapped: 0 reqs, Pending: 4239 reqs, GPU KV cache usage: 98.0%, CPU KV cache usage: 0.0%.
WARNING 07-23 11:01:42 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-9125 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
INFO 07-23 11:01:43 [metrics.py:486] Avg prompt throughput: 3664.7 tokens/s, Avg generation throughput: 2621.6 tokens/s, Running: 412 reqs, Swapped: 0 reqs, Pending: 4246 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:01:48 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3635.3 tokens/s, Running: 394 reqs, Swapped: 0 reqs, Pending: 4264 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:01:54 [metrics.py:486] Avg prompt throughput: 3565.4 tokens/s, Avg generation throughput: 2103.1 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4238 reqs, GPU KV cache usage: 93.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:00 [metrics.py:486] Avg prompt throughput: 11035.5 tokens/s, Avg generation throughput: 243.5 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 4161 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:06 [metrics.py:486] Avg prompt throughput: 11072.9 tokens/s, Avg generation throughput: 245.6 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4090 reqs, GPU KV cache usage: 88.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:11 [metrics.py:486] Avg prompt throughput: 11055.4 tokens/s, Avg generation throughput: 243.8 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4017 reqs, GPU KV cache usage: 86.7%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:17 [metrics.py:486] Avg prompt throughput: 11021.2 tokens/s, Avg generation throughput: 239.2 tokens/s, Running: 344 reqs, Swapped: 0 reqs, Pending: 3947 reqs, GPU KV cache usage: 84.3%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:23 [metrics.py:486] Avg prompt throughput: 10982.1 tokens/s, Avg generation throughput: 244.0 tokens/s, Running: 397 reqs, Swapped: 0 reqs, Pending: 3876 reqs, GPU KV cache usage: 97.3%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:28 [metrics.py:486] Avg prompt throughput: 4500.2 tokens/s, Avg generation throughput: 2263.6 tokens/s, Running: 393 reqs, Swapped: 0 reqs, Pending: 3871 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:33 [metrics.py:486] Avg prompt throughput: 367.4 tokens/s, Avg generation throughput: 3486.7 tokens/s, Running: 376 reqs, Swapped: 0 reqs, Pending: 3870 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:39 [metrics.py:486] Avg prompt throughput: 2332.1 tokens/s, Avg generation throughput: 2511.0 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 3833 reqs, GPU KV cache usage: 93.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:44 [metrics.py:486] Avg prompt throughput: 10959.7 tokens/s, Avg generation throughput: 238.0 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 3761 reqs, GPU KV cache usage: 91.4%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:50 [metrics.py:486] Avg prompt throughput: 10958.1 tokens/s, Avg generation throughput: 235.7 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 3689 reqs, GPU KV cache usage: 89.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:02:56 [metrics.py:486] Avg prompt throughput: 11048.0 tokens/s, Avg generation throughput: 241.1 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 3611 reqs, GPU KV cache usage: 87.6%, CPU KV cache usage: 0.0%.
INFO 07-23 11:03:02 [metrics.py:486] Avg prompt throughput: 10928.1 tokens/s, Avg generation throughput: 240.5 tokens/s, Running: 363 reqs, Swapped: 0 reqs, Pending: 3535 reqs, GPU KV cache usage: 85.4%, CPU KV cache usage: 0.0%.
INFO 07-23 11:03:08 [metrics.py:486] Avg prompt throughput: 10895.8 tokens/s, Avg generation throughput: 250.8 tokens/s, Running: 405 reqs, Swapped: 0 reqs, Pending: 3466 reqs, GPU KV cache usage: 95.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:03:13 [metrics.py:486] Avg prompt throughput: 5546.2 tokens/s, Avg generation throughput: 1961.4 tokens/s, Running: 410 reqs, Swapped: 0 reqs, Pending: 3461 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 11:03:18 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-9893 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
INFO 07-23 11:03:18 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3227.9 tokens/s, Running: 395 reqs, Swapped: 0 reqs, Pending: 3476 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:03:24 [metrics.py:486] Avg prompt throughput: 1765.7 tokens/s, Avg generation throughput: 3036.7 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 3465 reqs, GPU KV cache usage: 93.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:03:29 [metrics.py:486] Avg prompt throughput: 10944.3 tokens/s, Avg generation throughput: 238.0 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 3393 reqs, GPU KV cache usage: 91.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:03:35 [metrics.py:486] Avg prompt throughput: 10926.4 tokens/s, Avg generation throughput: 239.7 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 3317 reqs, GPU KV cache usage: 89.1%, CPU KV cache usage: 0.0%.
INFO 07-23 11:03:41 [metrics.py:486] Avg prompt throughput: 10928.8 tokens/s, Avg generation throughput: 237.4 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 3244 reqs, GPU KV cache usage: 87.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:03:47 [metrics.py:486] Avg prompt throughput: 10959.6 tokens/s, Avg generation throughput: 239.2 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 3168 reqs, GPU KV cache usage: 85.1%, CPU KV cache usage: 0.0%.
INFO 07-23 11:03:53 [metrics.py:486] Avg prompt throughput: 10986.0 tokens/s, Avg generation throughput: 245.3 tokens/s, Running: 393 reqs, Swapped: 0 reqs, Pending: 3097 reqs, GPU KV cache usage: 93.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:03:58 [metrics.py:486] Avg prompt throughput: 6885.9 tokens/s, Avg generation throughput: 1207.7 tokens/s, Running: 410 reqs, Swapped: 0 reqs, Pending: 3075 reqs, GPU KV cache usage: 99.1%, CPU KV cache usage: 0.0%.
INFO 07-23 11:04:03 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3607.8 tokens/s, Running: 392 reqs, Swapped: 0 reqs, Pending: 3078 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 11:04:08 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3265.2 tokens/s, Running: 377 reqs, Swapped: 0 reqs, Pending: 3078 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 11:04:13 [metrics.py:486] Avg prompt throughput: 9338.5 tokens/s, Avg generation throughput: 750.2 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 3005 reqs, GPU KV cache usage: 91.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:04:19 [metrics.py:486] Avg prompt throughput: 10986.1 tokens/s, Avg generation throughput: 242.4 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 2925 reqs, GPU KV cache usage: 89.6%, CPU KV cache usage: 0.0%.
INFO 07-23 11:04:25 [metrics.py:486] Avg prompt throughput: 10993.9 tokens/s, Avg generation throughput: 245.4 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 2845 reqs, GPU KV cache usage: 87.4%, CPU KV cache usage: 0.0%.
INFO 07-23 11:04:31 [metrics.py:486] Avg prompt throughput: 10972.1 tokens/s, Avg generation throughput: 249.3 tokens/s, Running: 369 reqs, Swapped: 0 reqs, Pending: 2765 reqs, GPU KV cache usage: 85.5%, CPU KV cache usage: 0.0%.
INFO 07-23 11:04:37 [metrics.py:486] Avg prompt throughput: 10958.1 tokens/s, Avg generation throughput: 251.6 tokens/s, Running: 385 reqs, Swapped: 0 reqs, Pending: 2693 reqs, GPU KV cache usage: 88.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:04:42 [metrics.py:486] Avg prompt throughput: 10883.1 tokens/s, Avg generation throughput: 319.7 tokens/s, Running: 434 reqs, Swapped: 0 reqs, Pending: 2644 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:04:47 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3747.2 tokens/s, Running: 416 reqs, Swapped: 0 reqs, Pending: 2662 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 11:04:50 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-10693 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
INFO 07-23 11:04:52 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3262.7 tokens/s, Running: 396 reqs, Swapped: 0 reqs, Pending: 2679 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 11:04:57 [metrics.py:486] Avg prompt throughput: 5835.7 tokens/s, Avg generation throughput: 1774.6 tokens/s, Running: 373 reqs, Swapped: 0 reqs, Pending: 2633 reqs, GPU KV cache usage: 93.3%, CPU KV cache usage: 0.0%.
INFO 07-23 11:05:03 [metrics.py:486] Avg prompt throughput: 11007.9 tokens/s, Avg generation throughput: 252.4 tokens/s, Running: 366 reqs, Swapped: 0 reqs, Pending: 2560 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:05:09 [metrics.py:486] Avg prompt throughput: 10966.3 tokens/s, Avg generation throughput: 247.4 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 2489 reqs, GPU KV cache usage: 88.4%, CPU KV cache usage: 0.0%.
INFO 07-23 11:05:15 [metrics.py:486] Avg prompt throughput: 11021.8 tokens/s, Avg generation throughput: 244.8 tokens/s, Running: 359 reqs, Swapped: 0 reqs, Pending: 2407 reqs, GPU KV cache usage: 86.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:05:20 [metrics.py:486] Avg prompt throughput: 11041.9 tokens/s, Avg generation throughput: 246.6 tokens/s, Running: 361 reqs, Swapped: 0 reqs, Pending: 2333 reqs, GPU KV cache usage: 83.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:05:26 [metrics.py:486] Avg prompt throughput: 10947.7 tokens/s, Avg generation throughput: 258.7 tokens/s, Running: 417 reqs, Swapped: 0 reqs, Pending: 2268 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:05:31 [metrics.py:486] Avg prompt throughput: 2915.0 tokens/s, Avg generation throughput: 2431.5 tokens/s, Running: 408 reqs, Swapped: 0 reqs, Pending: 2267 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:05:36 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3587.3 tokens/s, Running: 387 reqs, Swapped: 0 reqs, Pending: 2268 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 11:05:42 [metrics.py:486] Avg prompt throughput: 3937.6 tokens/s, Avg generation throughput: 2424.4 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 2222 reqs, GPU KV cache usage: 92.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:05:48 [metrics.py:486] Avg prompt throughput: 10991.8 tokens/s, Avg generation throughput: 244.5 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 2148 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:05:54 [metrics.py:486] Avg prompt throughput: 11002.5 tokens/s, Avg generation throughput: 245.9 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 2073 reqs, GPU KV cache usage: 88.6%, CPU KV cache usage: 0.0%.
INFO 07-23 11:06:00 [metrics.py:486] Avg prompt throughput: 10180.4 tokens/s, Avg generation throughput: 223.7 tokens/s, Running: 344 reqs, Swapped: 0 reqs, Pending: 2007 reqs, GPU KV cache usage: 86.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:06:06 [metrics.py:486] Avg prompt throughput: 11040.0 tokens/s, Avg generation throughput: 236.6 tokens/s, Running: 350 reqs, Swapped: 0 reqs, Pending: 1934 reqs, GPU KV cache usage: 84.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:06:11 [metrics.py:486] Avg prompt throughput: 11032.0 tokens/s, Avg generation throughput: 249.6 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 1866 reqs, GPU KV cache usage: 97.4%, CPU KV cache usage: 0.0%.
INFO 07-23 11:06:16 [metrics.py:486] Avg prompt throughput: 4158.7 tokens/s, Avg generation throughput: 2408.9 tokens/s, Running: 398 reqs, Swapped: 0 reqs, Pending: 1870 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:06:21 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3581.9 tokens/s, Running: 380 reqs, Swapped: 0 reqs, Pending: 1887 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
WARNING 07-23 11:06:25 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-11470 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
INFO 07-23 11:06:27 [metrics.py:486] Avg prompt throughput: 3243.8 tokens/s, Avg generation throughput: 2304.8 tokens/s, Running: 343 reqs, Swapped: 0 reqs, Pending: 1862 reqs, GPU KV cache usage: 93.3%, CPU KV cache usage: 0.0%.
INFO 07-23 11:06:33 [metrics.py:486] Avg prompt throughput: 11022.2 tokens/s, Avg generation throughput: 236.9 tokens/s, Running: 344 reqs, Swapped: 0 reqs, Pending: 1785 reqs, GPU KV cache usage: 90.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:06:38 [metrics.py:486] Avg prompt throughput: 11024.2 tokens/s, Avg generation throughput: 235.5 tokens/s, Running: 343 reqs, Swapped: 0 reqs, Pending: 1713 reqs, GPU KV cache usage: 89.1%, CPU KV cache usage: 0.0%.
INFO 07-23 11:06:44 [metrics.py:486] Avg prompt throughput: 11019.6 tokens/s, Avg generation throughput: 237.7 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 1636 reqs, GPU KV cache usage: 87.1%, CPU KV cache usage: 0.0%.
INFO 07-23 11:06:50 [metrics.py:486] Avg prompt throughput: 10995.6 tokens/s, Avg generation throughput: 243.3 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 1561 reqs, GPU KV cache usage: 84.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:06:56 [metrics.py:486] Avg prompt throughput: 10994.8 tokens/s, Avg generation throughput: 255.5 tokens/s, Running: 416 reqs, Swapped: 0 reqs, Pending: 1482 reqs, GPU KV cache usage: 96.4%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:01 [metrics.py:486] Avg prompt throughput: 5264.7 tokens/s, Avg generation throughput: 2107.5 tokens/s, Running: 419 reqs, Swapped: 0 reqs, Pending: 1469 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:06 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3324.8 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 1472 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:12 [metrics.py:486] Avg prompt throughput: 2029.7 tokens/s, Avg generation throughput: 2925.2 tokens/s, Running: 366 reqs, Swapped: 0 reqs, Pending: 1439 reqs, GPU KV cache usage: 93.7%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:18 [metrics.py:486] Avg prompt throughput: 10928.2 tokens/s, Avg generation throughput: 248.0 tokens/s, Running: 360 reqs, Swapped: 0 reqs, Pending: 1369 reqs, GPU KV cache usage: 91.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:24 [metrics.py:486] Avg prompt throughput: 10915.7 tokens/s, Avg generation throughput: 245.8 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 1296 reqs, GPU KV cache usage: 89.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:30 [metrics.py:486] Avg prompt throughput: 10910.5 tokens/s, Avg generation throughput: 243.4 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 1230 reqs, GPU KV cache usage: 86.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:36 [metrics.py:486] Avg prompt throughput: 10956.1 tokens/s, Avg generation throughput: 240.0 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 1151 reqs, GPU KV cache usage: 84.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:41 [metrics.py:486] Avg prompt throughput: 10958.2 tokens/s, Avg generation throughput: 246.8 tokens/s, Running: 398 reqs, Swapped: 0 reqs, Pending: 1075 reqs, GPU KV cache usage: 94.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:46 [metrics.py:486] Avg prompt throughput: 6425.3 tokens/s, Avg generation throughput: 1386.2 tokens/s, Running: 413 reqs, Swapped: 0 reqs, Pending: 1059 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:51 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3609.2 tokens/s, Running: 392 reqs, Swapped: 0 reqs, Pending: 1078 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:07:57 [metrics.py:486] Avg prompt throughput: 950.8 tokens/s, Avg generation throughput: 3307.6 tokens/s, Running: 350 reqs, Swapped: 0 reqs, Pending: 1073 reqs, GPU KV cache usage: 93.3%, CPU KV cache usage: 0.0%.
INFO 07-23 11:08:03 [metrics.py:486] Avg prompt throughput: 10285.3 tokens/s, Avg generation throughput: 224.2 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 1004 reqs, GPU KV cache usage: 91.4%, CPU KV cache usage: 0.0%.
INFO 07-23 11:08:09 [metrics.py:486] Avg prompt throughput: 11000.6 tokens/s, Avg generation throughput: 239.4 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 930 reqs, GPU KV cache usage: 89.6%, CPU KV cache usage: 0.0%.
INFO 07-23 11:08:15 [metrics.py:486] Avg prompt throughput: 10946.3 tokens/s, Avg generation throughput: 236.9 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 863 reqs, GPU KV cache usage: 87.3%, CPU KV cache usage: 0.0%.
INFO 07-23 11:08:21 [metrics.py:486] Avg prompt throughput: 11048.5 tokens/s, Avg generation throughput: 237.7 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 784 reqs, GPU KV cache usage: 85.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:08:26 [metrics.py:486] Avg prompt throughput: 11038.9 tokens/s, Avg generation throughput: 242.8 tokens/s, Running: 386 reqs, Swapped: 0 reqs, Pending: 707 reqs, GPU KV cache usage: 92.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:08:32 [metrics.py:486] Avg prompt throughput: 7760.0 tokens/s, Avg generation throughput: 1308.7 tokens/s, Running: 413 reqs, Swapped: 0 reqs, Pending: 676 reqs, GPU KV cache usage: 99.4%, CPU KV cache usage: 0.0%.
INFO 07-23 11:08:37 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3661.9 tokens/s, Running: 397 reqs, Swapped: 0 reqs, Pending: 676 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 11:08:42 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3283.5 tokens/s, Running: 379 reqs, Swapped: 0 reqs, Pending: 677 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 11:08:48 [metrics.py:486] Avg prompt throughput: 9850.4 tokens/s, Avg generation throughput: 589.8 tokens/s, Running: 361 reqs, Swapped: 0 reqs, Pending: 584 reqs, GPU KV cache usage: 91.7%, CPU KV cache usage: 0.0%.
INFO 07-23 11:08:54 [metrics.py:486] Avg prompt throughput: 10984.4 tokens/s, Avg generation throughput: 252.3 tokens/s, Running: 376 reqs, Swapped: 0 reqs, Pending: 506 reqs, GPU KV cache usage: 89.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:09:00 [metrics.py:486] Avg prompt throughput: 10948.7 tokens/s, Avg generation throughput: 255.9 tokens/s, Running: 374 reqs, Swapped: 0 reqs, Pending: 432 reqs, GPU KV cache usage: 87.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:09:05 [metrics.py:486] Avg prompt throughput: 10900.7 tokens/s, Avg generation throughput: 249.3 tokens/s, Running: 364 reqs, Swapped: 0 reqs, Pending: 362 reqs, GPU KV cache usage: 85.5%, CPU KV cache usage: 0.0%.
INFO 07-23 11:09:11 [metrics.py:486] Avg prompt throughput: 10922.6 tokens/s, Avg generation throughput: 248.5 tokens/s, Running: 384 reqs, Swapped: 0 reqs, Pending: 293 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 11:09:16 [metrics.py:486] Avg prompt throughput: 8882.2 tokens/s, Avg generation throughput: 891.2 tokens/s, Running: 413 reqs, Swapped: 0 reqs, Pending: 264 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
WARNING 07-23 11:09:18 [scheduler.py:1800] Sequence group cmpl-3f8a81f6541b4679ab5f8248d684f9ff-13098 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
INFO 07-23 11:09:21 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3317.5 tokens/s, Running: 396 reqs, Swapped: 0 reqs, Pending: 280 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 11:09:26 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3563.3 tokens/s, Running: 381 reqs, Swapped: 0 reqs, Pending: 295 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:09:32 [metrics.py:486] Avg prompt throughput: 8422.8 tokens/s, Avg generation throughput: 1011.1 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 240 reqs, GPU KV cache usage: 92.7%, CPU KV cache usage: 0.0%.
INFO 07-23 11:09:38 [metrics.py:486] Avg prompt throughput: 10157.1 tokens/s, Avg generation throughput: 213.7 tokens/s, Running: 337 reqs, Swapped: 0 reqs, Pending: 170 reqs, GPU KV cache usage: 90.2%, CPU KV cache usage: 0.0%.
INFO 07-23 11:09:44 [metrics.py:486] Avg prompt throughput: 11041.2 tokens/s, Avg generation throughput: 232.0 tokens/s, Running: 340 reqs, Swapped: 0 reqs, Pending: 93 reqs, GPU KV cache usage: 88.6%, CPU KV cache usage: 0.0%.
INFO 07-23 11:09:50 [metrics.py:486] Avg prompt throughput: 11018.6 tokens/s, Avg generation throughput: 235.8 tokens/s, Running: 346 reqs, Swapped: 0 reqs, Pending: 17 reqs, GPU KV cache usage: 86.1%, CPU KV cache usage: 0.0%.
INFO 07-23 11:09:55 [metrics.py:486] Avg prompt throughput: 6449.3 tokens/s, Avg generation throughput: 1618.9 tokens/s, Running: 292 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 72.5%, CPU KV cache usage: 0.0%.
INFO 07-23 11:10:00 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3431.9 tokens/s, Running: 272 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 70.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:46706 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 07-23 11:10:13 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 704.4 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:10:23 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 07-23 11:12:06 [launcher.py:79] Shutting down FastAPI HTTP server.
Exception ignored in: <function ExactWeakKeyDictionary.__setitem__.<locals>.<lambda> at 0x7f4bcc1c1940>
Traceback (most recent call last):
  File "/root/rehan/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py", line 908, in <lambda>
    self.refs[idx] = weakref.ref(key, lambda ref: self._remove_id(idx))

  File "/root/rehan/.venv/lib/python3.12/site-packages/vllm/engine/multiprocessing/engine.py", line 435, in signal_handler
    raise KeyboardInterrupt("MQLLMEngine terminated")
KeyboardInterrupt: MQLLMEngine terminated
[rank0]:[W723 11:12:07.575348599 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
