INFO 07-23 03:53:53 [__init__.py:243] Automatically detected platform cuda.
INFO 07-23 03:54:00 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 07-23 03:54:00 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 07-23 03:54:00 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 07-23 03:54:01 [api_server.py:1289] vLLM API server version 0.9.0.1
INFO 07-23 03:54:01 [cli_args.py:300] non-default args: {'max_model_len': 8192, 'block_size': 16, 'gpu_memory_utilization': 0.91, 'kv_cache_dtype': 'fp8', 'max_num_batched_tokens': 16384, 'max_num_seqs': 512, 'max_num_partial_prefills': 2, 'cuda_graph_sizes': [4296], 'long_prefill_token_threshold': 2048, 'enable_chunked_prefill': True, 'compilation_config': {"level": 3, "inductor_compile_config": {"enable_auto_functionalized_v2": false}}, 'disable_log_requests': True}
INFO 07-23 03:54:13 [config.py:793] This model supports multiple tasks: {'embed', 'reward', 'score', 'generate', 'classify'}. Defaulting to 'generate'.
WARNING 07-23 03:54:13 [arg_utils.py:1583] --kv-cache-dtype is not supported by the V1 Engine. Falling back to V0. 
INFO 07-23 03:54:13 [config.py:1503] Using fp8 data type to store kv cache. It reduces the GPU memory footprint and boosts the performance. Meanwhile, it may cause accuracy drop without a proper scaling factor
INFO 07-23 03:54:13 [config.py:2118] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 07-23 03:54:13 [config.py:2128] Concurrent partial prefills enabled with max_num_partial_prefills=2, max_long_partial_prefills=1, long_prefill_token_threshold=2048
INFO 07-23 03:54:13 [api_server.py:257] Started engine process with PID 266766
INFO 07-23 03:54:16 [__init__.py:243] Automatically detected platform cuda.
INFO 07-23 03:54:19 [__init__.py:31] Available plugins for group vllm.general_plugins:
INFO 07-23 03:54:19 [__init__.py:33] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
INFO 07-23 03:54:19 [__init__.py:36] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 07-23 03:54:19 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.0.1) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=fp8,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level": 3, "compile_sizes": [], "inductor_compile_config": {"enable_auto_functionalized_v2": false}, "cudagraph_capture_sizes": [512, 504, 496, 488, 480, 472, 464, 456, 448, 440, 432, 424, 416, 408, 400, 392, 384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], "max_capture_size": 512}, use_cached_outputs=True, 
INFO 07-23 03:54:27 [cuda.py:273] Cannot use FlashAttention backend for FP8 KV cache.
WARNING 07-23 03:54:27 [cuda.py:275] Please use FlashInfer backend with FP8 KV Cache for better performance by setting environment variable VLLM_ATTENTION_BACKEND=FLASHINFER
INFO 07-23 03:54:27 [cuda.py:289] Using XFormers backend.
INFO 07-23 03:54:27 [parallel_state.py:1064] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
INFO 07-23 03:54:27 [model_runner.py:1170] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
INFO 07-23 03:54:27 [backends.py:35] Using InductorAdaptor
INFO 07-23 03:54:28 [weight_utils.py:291] Using model weights format ['*.safetensors']
INFO 07-23 03:54:29 [weight_utils.py:307] Time spent downloading weights for meta-llama/Llama-3.1-8B-Instruct: 0.599740 seconds
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.57it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.51it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.48it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  2.04it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.81it/s]

INFO 07-23 03:54:32 [default_loader.py:280] Loading weights took 2.23 seconds
INFO 07-23 03:54:32 [model_runner.py:1202] Model loading took 14.9889 GiB and 4.552711 seconds
INFO 07-23 03:54:38 [backends.py:459] Using cache directory: /root/.cache/vllm/torch_compile_cache/5ea595cc58/rank_0_0 for vLLM's torch.compile
INFO 07-23 03:54:38 [backends.py:469] Dynamo bytecode transform time: 5.76 s
INFO 07-23 03:54:40 [backends.py:132] Directly load the compiled graph(s) for shape None from the cache, took 0.116 s
INFO 07-23 03:54:41 [monitor.py:33] torch.compile takes 5.76 s in total
INFO 07-23 03:54:43 [worker.py:291] Memory profiling takes 10.55 seconds
INFO 07-23 03:54:43 [worker.py:291] the current vLLM instance can use total_gpu_memory (44.52GiB) x gpu_memory_utilization (0.91) = 40.51GiB
INFO 07-23 03:54:43 [worker.py:291] model weights take 14.99GiB; non_torch_memory takes 0.08GiB; PyTorch activation peak memory takes 2.54GiB; the rest of the memory reserved for KV Cache is 22.90GiB.
INFO 07-23 03:54:43 [executor_base.py:112] # cuda blocks: 23450, # CPU blocks: 4096
INFO 07-23 03:54:43 [executor_base.py:117] Maximum concurrency for 8192 tokens per request: 45.80x
INFO 07-23 03:54:44 [model_runner.py:1512] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graph shapes:   1%|▏         | 1/67 [00:00<00:37,  1.75it/s]Capturing CUDA graph shapes:   3%|▎         | 2/67 [00:01<00:35,  1.83it/s]Capturing CUDA graph shapes:   4%|▍         | 3/67 [00:01<00:34,  1.83it/s]Capturing CUDA graph shapes:   6%|▌         | 4/67 [00:02<00:32,  1.91it/s]Capturing CUDA graph shapes:   7%|▋         | 5/67 [00:02<00:32,  1.90it/s]Capturing CUDA graph shapes:   9%|▉         | 6/67 [00:03<00:31,  1.93it/s]Capturing CUDA graph shapes:  10%|█         | 7/67 [00:03<00:30,  1.96it/s]Capturing CUDA graph shapes:  12%|█▏        | 8/67 [00:04<00:30,  1.95it/s]Capturing CUDA graph shapes:  13%|█▎        | 9/67 [00:04<00:29,  1.94it/s]Capturing CUDA graph shapes:  15%|█▍        | 10/67 [00:05<00:29,  1.93it/s]Capturing CUDA graph shapes:  16%|█▋        | 11/67 [00:05<00:28,  1.96it/s]Capturing CUDA graph shapes:  18%|█▊        | 12/67 [00:06<00:28,  1.96it/s]Capturing CUDA graph shapes:  19%|█▉        | 13/67 [00:06<00:28,  1.92it/s]Capturing CUDA graph shapes:  21%|██        | 14/67 [00:07<00:27,  1.96it/s]Capturing CUDA graph shapes:  22%|██▏       | 15/67 [00:07<00:26,  1.93it/s]Capturing CUDA graph shapes:  24%|██▍       | 16/67 [00:08<00:25,  1.96it/s]Capturing CUDA graph shapes:  25%|██▌       | 17/67 [00:08<00:25,  1.97it/s]Capturing CUDA graph shapes:  27%|██▋       | 18/67 [00:09<00:25,  1.94it/s]Capturing CUDA graph shapes:  28%|██▊       | 19/67 [00:09<00:24,  1.98it/s]Capturing CUDA graph shapes:  30%|██▉       | 20/67 [00:10<00:24,  1.95it/s]Capturing CUDA graph shapes:  31%|███▏      | 21/67 [00:10<00:23,  1.99it/s]Capturing CUDA graph shapes:  33%|███▎      | 22/67 [00:11<00:22,  1.97it/s]Capturing CUDA graph shapes:  34%|███▍      | 23/67 [00:11<00:22,  1.97it/s]Capturing CUDA graph shapes:  36%|███▌      | 24/67 [00:12<00:21,  2.00it/s]Capturing CUDA graph shapes:  37%|███▋      | 25/67 [00:12<00:21,  1.98it/s]Capturing CUDA graph shapes:  39%|███▉      | 26/67 [00:13<00:20,  2.00it/s]Capturing CUDA graph shapes:  40%|████      | 27/67 [00:13<00:20,  1.99it/s]Capturing CUDA graph shapes:  42%|████▏     | 28/67 [00:14<00:19,  2.00it/s]Capturing CUDA graph shapes:  43%|████▎     | 29/67 [00:14<00:19,  1.99it/s]Capturing CUDA graph shapes:  45%|████▍     | 30/67 [00:15<00:18,  2.01it/s]Capturing CUDA graph shapes:  46%|████▋     | 31/67 [00:15<00:17,  2.01it/s]Capturing CUDA graph shapes:  48%|████▊     | 32/67 [00:16<00:17,  2.00it/s]Capturing CUDA graph shapes:  49%|████▉     | 33/67 [00:16<00:17,  1.99it/s]Capturing CUDA graph shapes:  51%|█████     | 34/67 [00:17<00:16,  2.01it/s]Capturing CUDA graph shapes:  52%|█████▏    | 35/67 [00:17<00:16,  1.99it/s]Capturing CUDA graph shapes:  54%|█████▎    | 36/67 [00:18<00:15,  2.00it/s]Capturing CUDA graph shapes:  55%|█████▌    | 37/67 [00:18<00:15,  1.99it/s]Capturing CUDA graph shapes:  57%|█████▋    | 38/67 [00:19<00:14,  1.97it/s]Capturing CUDA graph shapes:  58%|█████▊    | 39/67 [00:19<00:14,  1.99it/s]Capturing CUDA graph shapes:  60%|█████▉    | 40/67 [00:20<00:13,  2.04it/s]Capturing CUDA graph shapes:  61%|██████    | 41/67 [00:20<00:12,  2.06it/s]Capturing CUDA graph shapes:  63%|██████▎   | 42/67 [00:21<00:12,  2.04it/s]Capturing CUDA graph shapes:  64%|██████▍   | 43/67 [00:21<00:11,  2.04it/s]Capturing CUDA graph shapes:  66%|██████▌   | 44/67 [00:22<00:11,  2.04it/s]Capturing CUDA graph shapes:  67%|██████▋   | 45/67 [00:22<00:10,  2.06it/s]Capturing CUDA graph shapes:  69%|██████▊   | 46/67 [00:23<00:10,  2.08it/s]Capturing CUDA graph shapes:  70%|███████   | 47/67 [00:23<00:09,  2.04it/s]Capturing CUDA graph shapes:  72%|███████▏  | 48/67 [00:24<00:09,  2.09it/s]Capturing CUDA graph shapes:  73%|███████▎  | 49/67 [00:24<00:08,  2.08it/s]Capturing CUDA graph shapes:  75%|███████▍  | 50/67 [00:25<00:08,  2.10it/s]Capturing CUDA graph shapes:  76%|███████▌  | 51/67 [00:25<00:07,  2.12it/s]Capturing CUDA graph shapes:  78%|███████▊  | 52/67 [00:26<00:07,  2.05it/s]Capturing CUDA graph shapes:  79%|███████▉  | 53/67 [00:26<00:06,  2.07it/s]Capturing CUDA graph shapes:  81%|████████  | 54/67 [00:27<00:06,  2.07it/s]Capturing CUDA graph shapes:  82%|████████▏ | 55/67 [00:27<00:05,  2.08it/s]Capturing CUDA graph shapes:  84%|████████▎ | 56/67 [00:28<00:05,  2.11it/s]Capturing CUDA graph shapes:  85%|████████▌ | 57/67 [00:28<00:04,  2.10it/s]Capturing CUDA graph shapes:  87%|████████▋ | 58/67 [00:28<00:04,  2.10it/s]Capturing CUDA graph shapes:  88%|████████▊ | 59/67 [00:29<00:03,  2.06it/s]Capturing CUDA graph shapes:  90%|████████▉ | 60/67 [00:29<00:03,  2.09it/s]Capturing CUDA graph shapes:  91%|█████████ | 61/67 [00:30<00:02,  2.13it/s]Capturing CUDA graph shapes:  93%|█████████▎| 62/67 [00:30<00:02,  2.11it/s]Capturing CUDA graph shapes:  94%|█████████▍| 63/67 [00:31<00:01,  2.09it/s]Capturing CUDA graph shapes:  96%|█████████▌| 64/67 [00:31<00:01,  2.06it/s]Capturing CUDA graph shapes:  97%|█████████▋| 65/67 [00:32<00:00,  2.07it/s]Capturing CUDA graph shapes:  99%|█████████▊| 66/67 [00:32<00:00,  2.11it/s]Capturing CUDA graph shapes: 100%|██████████| 67/67 [00:33<00:00,  2.07it/s]Capturing CUDA graph shapes: 100%|██████████| 67/67 [00:33<00:00,  2.01it/s]
INFO 07-23 03:55:17 [model_runner.py:1670] Graph capturing finished in 33 secs, took 0.45 GiB
INFO 07-23 03:55:17 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 45.49 seconds
WARNING 07-23 03:55:18 [config.py:1339] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 07-23 03:55:18 [serving_chat.py:117] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 07-23 03:55:19 [serving_completion.py:65] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
INFO 07-23 03:55:19 [api_server.py:1336] Starting vLLM API server on http://0.0.0.0:8000
INFO 07-23 03:55:19 [launcher.py:28] Available routes are:
INFO 07-23 03:55:19 [launcher.py:36] Route: /openapi.json, Methods: HEAD, GET
INFO 07-23 03:55:19 [launcher.py:36] Route: /docs, Methods: HEAD, GET
INFO 07-23 03:55:19 [launcher.py:36] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 07-23 03:55:19 [launcher.py:36] Route: /redoc, Methods: HEAD, GET
INFO 07-23 03:55:19 [launcher.py:36] Route: /health, Methods: GET
INFO 07-23 03:55:19 [launcher.py:36] Route: /load, Methods: GET
INFO 07-23 03:55:19 [launcher.py:36] Route: /ping, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /ping, Methods: GET
INFO 07-23 03:55:19 [launcher.py:36] Route: /tokenize, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /detokenize, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /v1/models, Methods: GET
INFO 07-23 03:55:19 [launcher.py:36] Route: /version, Methods: GET
INFO 07-23 03:55:19 [launcher.py:36] Route: /v1/chat/completions, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /v1/completions, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /v1/embeddings, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /pooling, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /classify, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /score, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /v1/score, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /v1/audio/transcriptions, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /rerank, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /v1/rerank, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /v2/rerank, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /invocations, Methods: POST
INFO 07-23 03:55:19 [launcher.py:36] Route: /metrics, Methods: GET
INFO:     Started server process [266447]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:37216 - "GET /health HTTP/1.1" 200 OK
INFO 07-23 03:58:26 [metrics.py:486] Avg prompt throughput: 2082.5 tokens/s, Avg generation throughput: 2.0 tokens/s, Running: 34 reqs, Swapped: 0 reqs, Pending: 13334 reqs, GPU KV cache usage: 9.1%, CPU KV cache usage: 0.0%.
INFO 07-23 03:58:31 [metrics.py:486] Avg prompt throughput: 12411.1 tokens/s, Avg generation throughput: 44.2 tokens/s, Running: 110 reqs, Swapped: 0 reqs, Pending: 13258 reqs, GPU KV cache usage: 26.5%, CPU KV cache usage: 0.0%.
INFO 07-23 03:58:36 [metrics.py:486] Avg prompt throughput: 12163.4 tokens/s, Avg generation throughput: 104.1 tokens/s, Running: 188 reqs, Swapped: 0 reqs, Pending: 13180 reqs, GPU KV cache usage: 44.2%, CPU KV cache usage: 0.0%.
INFO 07-23 03:58:42 [metrics.py:486] Avg prompt throughput: 12064.3 tokens/s, Avg generation throughput: 161.9 tokens/s, Running: 269 reqs, Swapped: 0 reqs, Pending: 13099 reqs, GPU KV cache usage: 61.9%, CPU KV cache usage: 0.0%.
INFO 07-23 03:58:48 [metrics.py:486] Avg prompt throughput: 7579.2 tokens/s, Avg generation throughput: 135.0 tokens/s, Running: 321 reqs, Swapped: 0 reqs, Pending: 13047 reqs, GPU KV cache usage: 75.0%, CPU KV cache usage: 0.0%.
INFO 07-23 03:58:54 [metrics.py:486] Avg prompt throughput: 11549.9 tokens/s, Avg generation throughput: 251.7 tokens/s, Running: 396 reqs, Swapped: 0 reqs, Pending: 12972 reqs, GPU KV cache usage: 92.6%, CPU KV cache usage: 0.0%.
WARNING 07-23 03:58:58 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-420 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1
INFO 07-23 03:58:59 [metrics.py:486] Avg prompt throughput: 7793.4 tokens/s, Avg generation throughput: 1420.9 tokens/s, Running: 418 reqs, Swapped: 0 reqs, Pending: 12950 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:04 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3733.4 tokens/s, Running: 398 reqs, Swapped: 0 reqs, Pending: 12970 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:09 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3026.3 tokens/s, Running: 383 reqs, Swapped: 0 reqs, Pending: 12985 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:15 [metrics.py:486] Avg prompt throughput: 9915.9 tokens/s, Avg generation throughput: 659.3 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 12903 reqs, GPU KV cache usage: 91.3%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:21 [metrics.py:486] Avg prompt throughput: 11319.8 tokens/s, Avg generation throughput: 250.2 tokens/s, Running: 359 reqs, Swapped: 0 reqs, Pending: 12822 reqs, GPU KV cache usage: 88.7%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:26 [metrics.py:486] Avg prompt throughput: 11262.1 tokens/s, Avg generation throughput: 248.9 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 12744 reqs, GPU KV cache usage: 86.5%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:32 [metrics.py:486] Avg prompt throughput: 11216.6 tokens/s, Avg generation throughput: 245.9 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 12678 reqs, GPU KV cache usage: 84.0%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:38 [metrics.py:486] Avg prompt throughput: 11246.4 tokens/s, Avg generation throughput: 248.8 tokens/s, Running: 390 reqs, Swapped: 0 reqs, Pending: 12597 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:43 [metrics.py:486] Avg prompt throughput: 9213.2 tokens/s, Avg generation throughput: 922.2 tokens/s, Running: 424 reqs, Swapped: 0 reqs, Pending: 12558 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:49 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3232.9 tokens/s, Running: 407 reqs, Swapped: 0 reqs, Pending: 12558 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:54 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3636.0 tokens/s, Running: 389 reqs, Swapped: 0 reqs, Pending: 12558 reqs, GPU KV cache usage: 99.1%, CPU KV cache usage: 0.0%.
INFO 07-23 03:59:59 [metrics.py:486] Avg prompt throughput: 9253.1 tokens/s, Avg generation throughput: 822.4 tokens/s, Running: 372 reqs, Swapped: 0 reqs, Pending: 12472 reqs, GPU KV cache usage: 92.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:00:05 [metrics.py:486] Avg prompt throughput: 11097.2 tokens/s, Avg generation throughput: 253.8 tokens/s, Running: 365 reqs, Swapped: 0 reqs, Pending: 12403 reqs, GPU KV cache usage: 89.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:00:11 [metrics.py:486] Avg prompt throughput: 11174.7 tokens/s, Avg generation throughput: 254.1 tokens/s, Running: 368 reqs, Swapped: 0 reqs, Pending: 12329 reqs, GPU KV cache usage: 87.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:00:17 [metrics.py:486] Avg prompt throughput: 11152.7 tokens/s, Avg generation throughput: 254.8 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 12259 reqs, GPU KV cache usage: 85.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:00:22 [metrics.py:486] Avg prompt throughput: 11160.0 tokens/s, Avg generation throughput: 247.5 tokens/s, Running: 378 reqs, Swapped: 0 reqs, Pending: 12180 reqs, GPU KV cache usage: 88.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:00:27 [metrics.py:486] Avg prompt throughput: 10826.0 tokens/s, Avg generation throughput: 400.4 tokens/s, Running: 424 reqs, Swapped: 0 reqs, Pending: 12134 reqs, GPU KV cache usage: 99.1%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:00:31 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-1223 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=51
INFO 07-23 04:00:32 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3157.9 tokens/s, Running: 407 reqs, Swapped: 0 reqs, Pending: 12151 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:00:38 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3584.5 tokens/s, Running: 388 reqs, Swapped: 0 reqs, Pending: 12170 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:00:43 [metrics.py:486] Avg prompt throughput: 6241.9 tokens/s, Avg generation throughput: 1697.7 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 12121 reqs, GPU KV cache usage: 92.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:00:48 [metrics.py:486] Avg prompt throughput: 11119.8 tokens/s, Avg generation throughput: 245.7 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 12049 reqs, GPU KV cache usage: 90.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:00:54 [metrics.py:486] Avg prompt throughput: 11154.3 tokens/s, Avg generation throughput: 246.3 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 11973 reqs, GPU KV cache usage: 88.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:00 [metrics.py:486] Avg prompt throughput: 11125.7 tokens/s, Avg generation throughput: 247.8 tokens/s, Running: 360 reqs, Swapped: 0 reqs, Pending: 11900 reqs, GPU KV cache usage: 86.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:06 [metrics.py:486] Avg prompt throughput: 11101.2 tokens/s, Avg generation throughput: 249.4 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 11825 reqs, GPU KV cache usage: 84.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:11 [metrics.py:486] Avg prompt throughput: 9405.2 tokens/s, Avg generation throughput: 218.0 tokens/s, Running: 410 reqs, Swapped: 0 reqs, Pending: 11768 reqs, GPU KV cache usage: 96.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:16 [metrics.py:486] Avg prompt throughput: 5373.0 tokens/s, Avg generation throughput: 2061.3 tokens/s, Running: 409 reqs, Swapped: 0 reqs, Pending: 11758 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:21 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3632.8 tokens/s, Running: 390 reqs, Swapped: 0 reqs, Pending: 11758 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:27 [metrics.py:486] Avg prompt throughput: 3922.4 tokens/s, Avg generation throughput: 2422.3 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 11713 reqs, GPU KV cache usage: 93.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:33 [metrics.py:486] Avg prompt throughput: 10983.7 tokens/s, Avg generation throughput: 240.8 tokens/s, Running: 346 reqs, Swapped: 0 reqs, Pending: 11645 reqs, GPU KV cache usage: 90.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:38 [metrics.py:486] Avg prompt throughput: 9322.4 tokens/s, Avg generation throughput: 200.5 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 11590 reqs, GPU KV cache usage: 89.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:44 [metrics.py:486] Avg prompt throughput: 11061.9 tokens/s, Avg generation throughput: 236.9 tokens/s, Running: 343 reqs, Swapped: 0 reqs, Pending: 11519 reqs, GPU KV cache usage: 86.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:50 [metrics.py:486] Avg prompt throughput: 10992.4 tokens/s, Avg generation throughput: 235.0 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 11444 reqs, GPU KV cache usage: 84.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:01:56 [metrics.py:486] Avg prompt throughput: 10969.3 tokens/s, Avg generation throughput: 239.4 tokens/s, Running: 389 reqs, Swapped: 0 reqs, Pending: 11370 reqs, GPU KV cache usage: 94.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:02:01 [metrics.py:486] Avg prompt throughput: 6651.3 tokens/s, Avg generation throughput: 1590.1 tokens/s, Running: 400 reqs, Swapped: 0 reqs, Pending: 11358 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:02:05 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-1996 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=101
INFO 07-23 04:02:06 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3567.4 tokens/s, Running: 383 reqs, Swapped: 0 reqs, Pending: 11375 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:02:12 [metrics.py:486] Avg prompt throughput: 3326.3 tokens/s, Avg generation throughput: 2596.6 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 11353 reqs, GPU KV cache usage: 93.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:02:18 [metrics.py:486] Avg prompt throughput: 10875.2 tokens/s, Avg generation throughput: 235.0 tokens/s, Running: 342 reqs, Swapped: 0 reqs, Pending: 11285 reqs, GPU KV cache usage: 91.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:02:23 [metrics.py:486] Avg prompt throughput: 9257.3 tokens/s, Avg generation throughput: 198.0 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 11227 reqs, GPU KV cache usage: 89.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:02:29 [metrics.py:486] Avg prompt throughput: 11032.8 tokens/s, Avg generation throughput: 238.4 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 11154 reqs, GPU KV cache usage: 87.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:02:35 [metrics.py:486] Avg prompt throughput: 10942.0 tokens/s, Avg generation throughput: 235.7 tokens/s, Running: 344 reqs, Swapped: 0 reqs, Pending: 11084 reqs, GPU KV cache usage: 85.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:02:41 [metrics.py:486] Avg prompt throughput: 11013.8 tokens/s, Avg generation throughput: 240.2 tokens/s, Running: 381 reqs, Swapped: 0 reqs, Pending: 11009 reqs, GPU KV cache usage: 92.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:02:46 [metrics.py:486] Avg prompt throughput: 7792.7 tokens/s, Avg generation throughput: 1281.7 tokens/s, Running: 407 reqs, Swapped: 0 reqs, Pending: 10977 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:02:51 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3599.5 tokens/s, Running: 388 reqs, Swapped: 0 reqs, Pending: 10979 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:02:56 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3083.4 tokens/s, Running: 376 reqs, Swapped: 0 reqs, Pending: 10979 reqs, GPU KV cache usage: 99.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:03:01 [metrics.py:486] Avg prompt throughput: 9274.1 tokens/s, Avg generation throughput: 799.0 tokens/s, Running: 368 reqs, Swapped: 0 reqs, Pending: 10898 reqs, GPU KV cache usage: 92.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:03:07 [metrics.py:486] Avg prompt throughput: 11025.7 tokens/s, Avg generation throughput: 252.5 tokens/s, Running: 371 reqs, Swapped: 0 reqs, Pending: 10822 reqs, GPU KV cache usage: 90.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:03:13 [metrics.py:486] Avg prompt throughput: 10959.4 tokens/s, Avg generation throughput: 251.7 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 10756 reqs, GPU KV cache usage: 88.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:03:19 [metrics.py:486] Avg prompt throughput: 11031.3 tokens/s, Avg generation throughput: 251.2 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 10683 reqs, GPU KV cache usage: 86.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:03:25 [metrics.py:486] Avg prompt throughput: 10976.7 tokens/s, Avg generation throughput: 248.7 tokens/s, Running: 374 reqs, Swapped: 0 reqs, Pending: 10605 reqs, GPU KV cache usage: 86.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:03:30 [metrics.py:486] Avg prompt throughput: 10923.0 tokens/s, Avg generation throughput: 298.0 tokens/s, Running: 424 reqs, Swapped: 0 reqs, Pending: 10555 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:03:35 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3727.2 tokens/s, Running: 409 reqs, Swapped: 0 reqs, Pending: 10570 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:03:40 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-2784 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=151
INFO 07-23 04:03:40 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3065.1 tokens/s, Running: 392 reqs, Swapped: 0 reqs, Pending: 10585 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:03:45 [metrics.py:486] Avg prompt throughput: 5708.6 tokens/s, Avg generation throughput: 1805.5 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 10544 reqs, GPU KV cache usage: 93.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:03:51 [metrics.py:486] Avg prompt throughput: 10960.5 tokens/s, Avg generation throughput: 241.3 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 10469 reqs, GPU KV cache usage: 91.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:03:57 [metrics.py:486] Avg prompt throughput: 10939.2 tokens/s, Avg generation throughput: 240.3 tokens/s, Running: 361 reqs, Swapped: 0 reqs, Pending: 10396 reqs, GPU KV cache usage: 89.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:04:03 [metrics.py:486] Avg prompt throughput: 10980.6 tokens/s, Avg generation throughput: 246.1 tokens/s, Running: 369 reqs, Swapped: 0 reqs, Pending: 10315 reqs, GPU KV cache usage: 87.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:04:09 [metrics.py:486] Avg prompt throughput: 10946.0 tokens/s, Avg generation throughput: 251.5 tokens/s, Running: 371 reqs, Swapped: 0 reqs, Pending: 10235 reqs, GPU KV cache usage: 85.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:04:14 [metrics.py:486] Avg prompt throughput: 10921.2 tokens/s, Avg generation throughput: 263.3 tokens/s, Running: 423 reqs, Swapped: 0 reqs, Pending: 10170 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:04:20 [metrics.py:486] Avg prompt throughput: 2775.4 tokens/s, Avg generation throughput: 2337.6 tokens/s, Running: 411 reqs, Swapped: 0 reqs, Pending: 10170 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:04:25 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3629.2 tokens/s, Running: 395 reqs, Swapped: 0 reqs, Pending: 10171 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:04:30 [metrics.py:486] Avg prompt throughput: 3873.7 tokens/s, Avg generation throughput: 2418.5 tokens/s, Running: 359 reqs, Swapped: 0 reqs, Pending: 10130 reqs, GPU KV cache usage: 92.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:04:36 [metrics.py:486] Avg prompt throughput: 10974.3 tokens/s, Avg generation throughput: 246.9 tokens/s, Running: 366 reqs, Swapped: 0 reqs, Pending: 10052 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:04:42 [metrics.py:486] Avg prompt throughput: 10972.5 tokens/s, Avg generation throughput: 249.0 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 9976 reqs, GPU KV cache usage: 88.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:04:48 [metrics.py:486] Avg prompt throughput: 11009.8 tokens/s, Avg generation throughput: 246.7 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 9903 reqs, GPU KV cache usage: 86.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:04:55 [metrics.py:486] Avg prompt throughput: 9813.6 tokens/s, Avg generation throughput: 214.9 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 9829 reqs, GPU KV cache usage: 84.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:00 [metrics.py:486] Avg prompt throughput: 11092.9 tokens/s, Avg generation throughput: 262.3 tokens/s, Running: 427 reqs, Swapped: 0 reqs, Pending: 9744 reqs, GPU KV cache usage: 97.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:05 [metrics.py:486] Avg prompt throughput: 4048.4 tokens/s, Avg generation throughput: 2537.3 tokens/s, Running: 422 reqs, Swapped: 0 reqs, Pending: 9749 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:10 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3696.0 tokens/s, Running: 405 reqs, Swapped: 0 reqs, Pending: 9765 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:05:13 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-3591 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=201
INFO 07-23 04:05:16 [metrics.py:486] Avg prompt throughput: 3130.4 tokens/s, Avg generation throughput: 2616.9 tokens/s, Running: 368 reqs, Swapped: 0 reqs, Pending: 9744 reqs, GPU KV cache usage: 93.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:21 [metrics.py:486] Avg prompt throughput: 10950.8 tokens/s, Avg generation throughput: 247.5 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 9677 reqs, GPU KV cache usage: 91.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:27 [metrics.py:486] Avg prompt throughput: 10931.2 tokens/s, Avg generation throughput: 241.2 tokens/s, Running: 346 reqs, Swapped: 0 reqs, Pending: 9610 reqs, GPU KV cache usage: 88.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:32 [metrics.py:486] Avg prompt throughput: 9426.2 tokens/s, Avg generation throughput: 204.0 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 9546 reqs, GPU KV cache usage: 87.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:38 [metrics.py:486] Avg prompt throughput: 10975.6 tokens/s, Avg generation throughput: 244.4 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 9478 reqs, GPU KV cache usage: 84.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:44 [metrics.py:486] Avg prompt throughput: 10917.0 tokens/s, Avg generation throughput: 238.0 tokens/s, Running: 376 reqs, Swapped: 0 reqs, Pending: 9406 reqs, GPU KV cache usage: 91.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:49 [metrics.py:486] Avg prompt throughput: 8714.4 tokens/s, Avg generation throughput: 944.0 tokens/s, Running: 397 reqs, Swapped: 0 reqs, Pending: 9379 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:54 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3613.1 tokens/s, Running: 379 reqs, Swapped: 0 reqs, Pending: 9379 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:05:59 [metrics.py:486] Avg prompt throughput: 492.0 tokens/s, Avg generation throughput: 2945.9 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 9377 reqs, GPU KV cache usage: 99.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:06:06 [metrics.py:486] Avg prompt throughput: 8961.4 tokens/s, Avg generation throughput: 847.4 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 9291 reqs, GPU KV cache usage: 92.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:06:11 [metrics.py:486] Avg prompt throughput: 10965.3 tokens/s, Avg generation throughput: 241.5 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 9223 reqs, GPU KV cache usage: 90.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:06:17 [metrics.py:486] Avg prompt throughput: 11017.0 tokens/s, Avg generation throughput: 235.8 tokens/s, Running: 350 reqs, Swapped: 0 reqs, Pending: 9144 reqs, GPU KV cache usage: 88.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:06:23 [metrics.py:486] Avg prompt throughput: 11025.7 tokens/s, Avg generation throughput: 240.8 tokens/s, Running: 350 reqs, Swapped: 0 reqs, Pending: 9075 reqs, GPU KV cache usage: 86.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:06:29 [metrics.py:486] Avg prompt throughput: 11040.7 tokens/s, Avg generation throughput: 245.7 tokens/s, Running: 384 reqs, Swapped: 0 reqs, Pending: 8995 reqs, GPU KV cache usage: 90.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:06:34 [metrics.py:486] Avg prompt throughput: 9528.8 tokens/s, Avg generation throughput: 744.3 tokens/s, Running: 421 reqs, Swapped: 0 reqs, Pending: 8958 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:06:39 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3691.1 tokens/s, Running: 401 reqs, Swapped: 0 reqs, Pending: 8978 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:06:44 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3048.7 tokens/s, Running: 384 reqs, Swapped: 0 reqs, Pending: 8994 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:06:49 [metrics.py:486] Avg prompt throughput: 7267.8 tokens/s, Avg generation throughput: 1415.5 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 8941 reqs, GPU KV cache usage: 92.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:06:55 [metrics.py:486] Avg prompt throughput: 10998.3 tokens/s, Avg generation throughput: 240.2 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 8866 reqs, GPU KV cache usage: 90.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:01 [metrics.py:486] Avg prompt throughput: 11003.6 tokens/s, Avg generation throughput: 242.5 tokens/s, Running: 344 reqs, Swapped: 0 reqs, Pending: 8801 reqs, GPU KV cache usage: 87.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:06 [metrics.py:486] Avg prompt throughput: 10973.5 tokens/s, Avg generation throughput: 234.3 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 8731 reqs, GPU KV cache usage: 85.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:12 [metrics.py:486] Avg prompt throughput: 11041.7 tokens/s, Avg generation throughput: 234.9 tokens/s, Running: 342 reqs, Swapped: 0 reqs, Pending: 8656 reqs, GPU KV cache usage: 84.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:18 [metrics.py:486] Avg prompt throughput: 10977.8 tokens/s, Avg generation throughput: 250.5 tokens/s, Running: 401 reqs, Swapped: 0 reqs, Pending: 8595 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:23 [metrics.py:486] Avg prompt throughput: 1564.5 tokens/s, Avg generation throughput: 3120.1 tokens/s, Running: 388 reqs, Swapped: 0 reqs, Pending: 8596 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:28 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3105.9 tokens/s, Running: 369 reqs, Swapped: 0 reqs, Pending: 8597 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:34 [metrics.py:486] Avg prompt throughput: 5567.7 tokens/s, Avg generation throughput: 1875.7 tokens/s, Running: 341 reqs, Swapped: 0 reqs, Pending: 8545 reqs, GPU KV cache usage: 92.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:40 [metrics.py:486] Avg prompt throughput: 10926.2 tokens/s, Avg generation throughput: 232.6 tokens/s, Running: 350 reqs, Swapped: 0 reqs, Pending: 8469 reqs, GPU KV cache usage: 91.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:46 [metrics.py:486] Avg prompt throughput: 10924.0 tokens/s, Avg generation throughput: 239.8 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 8398 reqs, GPU KV cache usage: 89.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:52 [metrics.py:486] Avg prompt throughput: 10914.9 tokens/s, Avg generation throughput: 239.1 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 8325 reqs, GPU KV cache usage: 86.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:07:58 [metrics.py:486] Avg prompt throughput: 10946.9 tokens/s, Avg generation throughput: 237.9 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 8253 reqs, GPU KV cache usage: 84.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:08:03 [metrics.py:486] Avg prompt throughput: 10948.3 tokens/s, Avg generation throughput: 254.7 tokens/s, Running: 411 reqs, Swapped: 0 reqs, Pending: 8186 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:08:06 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-5181 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=251
INFO 07-23 04:08:08 [metrics.py:486] Avg prompt throughput: 2028.1 tokens/s, Avg generation throughput: 2559.0 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 8194 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:08:14 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3566.6 tokens/s, Running: 381 reqs, Swapped: 0 reqs, Pending: 8214 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:08:19 [metrics.py:486] Avg prompt throughput: 5054.5 tokens/s, Avg generation throughput: 2055.7 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 8175 reqs, GPU KV cache usage: 93.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:08:25 [metrics.py:486] Avg prompt throughput: 11038.8 tokens/s, Avg generation throughput: 239.9 tokens/s, Running: 346 reqs, Swapped: 0 reqs, Pending: 8104 reqs, GPU KV cache usage: 91.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:08:31 [metrics.py:486] Avg prompt throughput: 11002.9 tokens/s, Avg generation throughput: 236.0 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 8034 reqs, GPU KV cache usage: 89.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:08:37 [metrics.py:486] Avg prompt throughput: 11033.8 tokens/s, Avg generation throughput: 237.2 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 7962 reqs, GPU KV cache usage: 87.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:08:42 [metrics.py:486] Avg prompt throughput: 11033.5 tokens/s, Avg generation throughput: 238.0 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 7888 reqs, GPU KV cache usage: 84.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:08:48 [metrics.py:486] Avg prompt throughput: 11036.5 tokens/s, Avg generation throughput: 253.9 tokens/s, Running: 414 reqs, Swapped: 0 reqs, Pending: 7810 reqs, GPU KV cache usage: 98.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:08:53 [metrics.py:486] Avg prompt throughput: 2989.9 tokens/s, Avg generation throughput: 2284.6 tokens/s, Running: 404 reqs, Swapped: 0 reqs, Pending: 7809 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:08:58 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3575.7 tokens/s, Running: 385 reqs, Swapped: 0 reqs, Pending: 7809 reqs, GPU KV cache usage: 99.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:09:05 [metrics.py:486] Avg prompt throughput: 3530.3 tokens/s, Avg generation throughput: 2211.4 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 7771 reqs, GPU KV cache usage: 93.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:09:10 [metrics.py:486] Avg prompt throughput: 11028.9 tokens/s, Avg generation throughput: 241.5 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 7702 reqs, GPU KV cache usage: 91.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:09:16 [metrics.py:486] Avg prompt throughput: 11028.1 tokens/s, Avg generation throughput: 244.4 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 7625 reqs, GPU KV cache usage: 88.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:09:22 [metrics.py:486] Avg prompt throughput: 11004.6 tokens/s, Avg generation throughput: 242.5 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 7558 reqs, GPU KV cache usage: 87.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:09:28 [metrics.py:486] Avg prompt throughput: 11024.4 tokens/s, Avg generation throughput: 240.7 tokens/s, Running: 344 reqs, Swapped: 0 reqs, Pending: 7484 reqs, GPU KV cache usage: 84.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:09:34 [metrics.py:486] Avg prompt throughput: 10975.8 tokens/s, Avg generation throughput: 243.0 tokens/s, Running: 391 reqs, Swapped: 0 reqs, Pending: 7419 reqs, GPU KV cache usage: 97.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:09:39 [metrics.py:486] Avg prompt throughput: 4129.7 tokens/s, Avg generation throughput: 2351.4 tokens/s, Running: 388 reqs, Swapped: 0 reqs, Pending: 7421 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:09:41 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-5941 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=301
INFO 07-23 04:09:44 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3618.7 tokens/s, Running: 371 reqs, Swapped: 0 reqs, Pending: 7438 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:09:49 [metrics.py:486] Avg prompt throughput: 3358.6 tokens/s, Avg generation throughput: 2095.6 tokens/s, Running: 339 reqs, Swapped: 0 reqs, Pending: 7416 reqs, GPU KV cache usage: 93.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:09:55 [metrics.py:486] Avg prompt throughput: 11001.5 tokens/s, Avg generation throughput: 233.1 tokens/s, Running: 341 reqs, Swapped: 0 reqs, Pending: 7340 reqs, GPU KV cache usage: 91.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:01 [metrics.py:486] Avg prompt throughput: 10931.0 tokens/s, Avg generation throughput: 229.2 tokens/s, Running: 336 reqs, Swapped: 0 reqs, Pending: 7273 reqs, GPU KV cache usage: 89.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:07 [metrics.py:486] Avg prompt throughput: 10974.5 tokens/s, Avg generation throughput: 231.5 tokens/s, Running: 343 reqs, Swapped: 0 reqs, Pending: 7195 reqs, GPU KV cache usage: 87.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:13 [metrics.py:486] Avg prompt throughput: 11004.4 tokens/s, Avg generation throughput: 237.4 tokens/s, Running: 359 reqs, Swapped: 0 reqs, Pending: 7109 reqs, GPU KV cache usage: 85.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:18 [metrics.py:486] Avg prompt throughput: 10991.4 tokens/s, Avg generation throughput: 252.2 tokens/s, Running: 406 reqs, Swapped: 0 reqs, Pending: 7039 reqs, GPU KV cache usage: 96.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:24 [metrics.py:486] Avg prompt throughput: 5122.0 tokens/s, Avg generation throughput: 2118.8 tokens/s, Running: 411 reqs, Swapped: 0 reqs, Pending: 7028 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:29 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3622.1 tokens/s, Running: 395 reqs, Swapped: 0 reqs, Pending: 7028 reqs, GPU KV cache usage: 99.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:35 [metrics.py:486] Avg prompt throughput: 2087.0 tokens/s, Avg generation throughput: 2533.5 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 6998 reqs, GPU KV cache usage: 93.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:40 [metrics.py:486] Avg prompt throughput: 10976.3 tokens/s, Avg generation throughput: 248.3 tokens/s, Running: 372 reqs, Swapped: 0 reqs, Pending: 6920 reqs, GPU KV cache usage: 91.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:46 [metrics.py:486] Avg prompt throughput: 10983.7 tokens/s, Avg generation throughput: 252.2 tokens/s, Running: 369 reqs, Swapped: 0 reqs, Pending: 6847 reqs, GPU KV cache usage: 89.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:52 [metrics.py:486] Avg prompt throughput: 10994.9 tokens/s, Avg generation throughput: 249.2 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 6776 reqs, GPU KV cache usage: 87.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:10:58 [metrics.py:486] Avg prompt throughput: 10984.3 tokens/s, Avg generation throughput: 240.5 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 6704 reqs, GPU KV cache usage: 84.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:11:04 [metrics.py:486] Avg prompt throughput: 10973.7 tokens/s, Avg generation throughput: 246.8 tokens/s, Running: 396 reqs, Swapped: 0 reqs, Pending: 6636 reqs, GPU KV cache usage: 94.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:11:09 [metrics.py:486] Avg prompt throughput: 6156.2 tokens/s, Avg generation throughput: 1787.2 tokens/s, Running: 406 reqs, Swapped: 0 reqs, Pending: 6622 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:11:14 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3136.5 tokens/s, Running: 389 reqs, Swapped: 0 reqs, Pending: 6639 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:11:16 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-6721 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=351
INFO 07-23 04:11:19 [metrics.py:486] Avg prompt throughput: 1084.5 tokens/s, Avg generation throughput: 3280.0 tokens/s, Running: 344 reqs, Swapped: 0 reqs, Pending: 6634 reqs, GPU KV cache usage: 93.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:11:25 [metrics.py:486] Avg prompt throughput: 11003.3 tokens/s, Avg generation throughput: 235.1 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 6557 reqs, GPU KV cache usage: 91.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:11:31 [metrics.py:486] Avg prompt throughput: 11028.5 tokens/s, Avg generation throughput: 237.0 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 6484 reqs, GPU KV cache usage: 88.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:11:37 [metrics.py:486] Avg prompt throughput: 11008.3 tokens/s, Avg generation throughput: 238.5 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 6409 reqs, GPU KV cache usage: 87.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:11:43 [metrics.py:486] Avg prompt throughput: 10970.7 tokens/s, Avg generation throughput: 242.4 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 6335 reqs, GPU KV cache usage: 85.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:11:49 [metrics.py:486] Avg prompt throughput: 10926.8 tokens/s, Avg generation throughput: 244.4 tokens/s, Running: 395 reqs, Swapped: 0 reqs, Pending: 6263 reqs, GPU KV cache usage: 93.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:11:54 [metrics.py:486] Avg prompt throughput: 7450.5 tokens/s, Avg generation throughput: 1409.3 tokens/s, Running: 417 reqs, Swapped: 0 reqs, Pending: 6236 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:11:59 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3213.0 tokens/s, Running: 399 reqs, Swapped: 0 reqs, Pending: 6236 reqs, GPU KV cache usage: 99.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:12:04 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3576.0 tokens/s, Running: 384 reqs, Swapped: 0 reqs, Pending: 6236 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:12:09 [metrics.py:486] Avg prompt throughput: 9192.5 tokens/s, Avg generation throughput: 788.1 tokens/s, Running: 367 reqs, Swapped: 0 reqs, Pending: 6158 reqs, GPU KV cache usage: 92.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:12:15 [metrics.py:486] Avg prompt throughput: 10933.5 tokens/s, Avg generation throughput: 245.5 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 6089 reqs, GPU KV cache usage: 90.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:12:21 [metrics.py:486] Avg prompt throughput: 9958.0 tokens/s, Avg generation throughput: 220.1 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 6017 reqs, GPU KV cache usage: 87.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:12:27 [metrics.py:486] Avg prompt throughput: 11040.4 tokens/s, Avg generation throughput: 243.8 tokens/s, Running: 361 reqs, Swapped: 0 reqs, Pending: 5941 reqs, GPU KV cache usage: 85.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:12:33 [metrics.py:486] Avg prompt throughput: 11014.9 tokens/s, Avg generation throughput: 246.8 tokens/s, Running: 372 reqs, Swapped: 0 reqs, Pending: 5867 reqs, GPU KV cache usage: 87.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:12:38 [metrics.py:486] Avg prompt throughput: 10921.4 tokens/s, Avg generation throughput: 297.5 tokens/s, Running: 417 reqs, Swapped: 0 reqs, Pending: 5820 reqs, GPU KV cache usage: 98.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:12:43 [metrics.py:486] Avg prompt throughput: 277.3 tokens/s, Avg generation throughput: 3600.1 tokens/s, Running: 401 reqs, Swapped: 0 reqs, Pending: 5835 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:12:48 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3126.3 tokens/s, Running: 385 reqs, Swapped: 0 reqs, Pending: 5851 reqs, GPU KV cache usage: 99.7%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:12:50 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-7514 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=401
INFO 07-23 04:12:54 [metrics.py:486] Avg prompt throughput: 6849.2 tokens/s, Avg generation throughput: 1512.2 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 5788 reqs, GPU KV cache usage: 92.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:00 [metrics.py:486] Avg prompt throughput: 10956.0 tokens/s, Avg generation throughput: 242.1 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 5719 reqs, GPU KV cache usage: 90.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:06 [metrics.py:486] Avg prompt throughput: 10993.2 tokens/s, Avg generation throughput: 243.5 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 5643 reqs, GPU KV cache usage: 88.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:12 [metrics.py:486] Avg prompt throughput: 10957.8 tokens/s, Avg generation throughput: 241.0 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 5574 reqs, GPU KV cache usage: 86.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:18 [metrics.py:486] Avg prompt throughput: 10921.4 tokens/s, Avg generation throughput: 237.7 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 5501 reqs, GPU KV cache usage: 85.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:24 [metrics.py:486] Avg prompt throughput: 10905.2 tokens/s, Avg generation throughput: 259.7 tokens/s, Running: 406 reqs, Swapped: 0 reqs, Pending: 5448 reqs, GPU KV cache usage: 98.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:29 [metrics.py:486] Avg prompt throughput: 221.5 tokens/s, Avg generation throughput: 3571.8 tokens/s, Running: 393 reqs, Swapped: 0 reqs, Pending: 5447 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:34 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3160.7 tokens/s, Running: 376 reqs, Swapped: 0 reqs, Pending: 5446 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:39 [metrics.py:486] Avg prompt throughput: 6519.3 tokens/s, Avg generation throughput: 1621.6 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 5392 reqs, GPU KV cache usage: 92.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:45 [metrics.py:486] Avg prompt throughput: 10948.5 tokens/s, Avg generation throughput: 233.4 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 5317 reqs, GPU KV cache usage: 90.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:51 [metrics.py:486] Avg prompt throughput: 10956.2 tokens/s, Avg generation throughput: 235.5 tokens/s, Running: 346 reqs, Swapped: 0 reqs, Pending: 5244 reqs, GPU KV cache usage: 88.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:13:57 [metrics.py:486] Avg prompt throughput: 10915.9 tokens/s, Avg generation throughput: 234.6 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 5172 reqs, GPU KV cache usage: 86.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:03 [metrics.py:486] Avg prompt throughput: 10987.9 tokens/s, Avg generation throughput: 238.4 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 5095 reqs, GPU KV cache usage: 84.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:09 [metrics.py:486] Avg prompt throughput: 10987.8 tokens/s, Avg generation throughput: 259.4 tokens/s, Running: 415 reqs, Swapped: 0 reqs, Pending: 5032 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:14 [metrics.py:486] Avg prompt throughput: 1565.1 tokens/s, Avg generation throughput: 2775.1 tokens/s, Running: 404 reqs, Swapped: 0 reqs, Pending: 5043 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:19 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3586.1 tokens/s, Running: 381 reqs, Swapped: 0 reqs, Pending: 5066 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:24 [metrics.py:486] Avg prompt throughput: 5565.6 tokens/s, Avg generation throughput: 1904.5 tokens/s, Running: 360 reqs, Swapped: 0 reqs, Pending: 5020 reqs, GPU KV cache usage: 93.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:30 [metrics.py:486] Avg prompt throughput: 10986.0 tokens/s, Avg generation throughput: 244.9 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4948 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:36 [metrics.py:486] Avg prompt throughput: 10985.8 tokens/s, Avg generation throughput: 241.6 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 4874 reqs, GPU KV cache usage: 88.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:42 [metrics.py:486] Avg prompt throughput: 10996.3 tokens/s, Avg generation throughput: 241.8 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 4797 reqs, GPU KV cache usage: 86.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:48 [metrics.py:486] Avg prompt throughput: 10091.4 tokens/s, Avg generation throughput: 223.3 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4725 reqs, GPU KV cache usage: 84.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:54 [metrics.py:486] Avg prompt throughput: 11036.4 tokens/s, Avg generation throughput: 258.5 tokens/s, Running: 413 reqs, Swapped: 0 reqs, Pending: 4658 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:14:59 [metrics.py:486] Avg prompt throughput: 2502.2 tokens/s, Avg generation throughput: 2904.7 tokens/s, Running: 402 reqs, Swapped: 0 reqs, Pending: 4658 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:15:04 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3600.9 tokens/s, Running: 381 reqs, Swapped: 0 reqs, Pending: 4658 reqs, GPU KV cache usage: 99.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:15:10 [metrics.py:486] Avg prompt throughput: 4354.6 tokens/s, Avg generation throughput: 1966.8 tokens/s, Running: 359 reqs, Swapped: 0 reqs, Pending: 4609 reqs, GPU KV cache usage: 93.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:15:15 [metrics.py:486] Avg prompt throughput: 11006.2 tokens/s, Avg generation throughput: 243.8 tokens/s, Running: 360 reqs, Swapped: 0 reqs, Pending: 4534 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:15:21 [metrics.py:486] Avg prompt throughput: 11022.6 tokens/s, Avg generation throughput: 246.0 tokens/s, Running: 361 reqs, Swapped: 0 reqs, Pending: 4460 reqs, GPU KV cache usage: 88.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:15:27 [metrics.py:486] Avg prompt throughput: 11008.6 tokens/s, Avg generation throughput: 243.5 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4388 reqs, GPU KV cache usage: 86.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:15:33 [metrics.py:486] Avg prompt throughput: 11055.3 tokens/s, Avg generation throughput: 245.5 tokens/s, Running: 365 reqs, Swapped: 0 reqs, Pending: 4306 reqs, GPU KV cache usage: 84.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:15:39 [metrics.py:486] Avg prompt throughput: 10993.5 tokens/s, Avg generation throughput: 260.2 tokens/s, Running: 419 reqs, Swapped: 0 reqs, Pending: 4239 reqs, GPU KV cache usage: 98.0%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:15:43 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-9125 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=451
INFO 07-23 04:15:44 [metrics.py:486] Avg prompt throughput: 3732.8 tokens/s, Avg generation throughput: 2588.0 tokens/s, Running: 413 reqs, Swapped: 0 reqs, Pending: 4245 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:15:49 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3212.3 tokens/s, Running: 397 reqs, Swapped: 0 reqs, Pending: 4261 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:15:55 [metrics.py:486] Avg prompt throughput: 3433.6 tokens/s, Avg generation throughput: 2492.6 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4238 reqs, GPU KV cache usage: 93.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:00 [metrics.py:486] Avg prompt throughput: 10993.3 tokens/s, Avg generation throughput: 242.6 tokens/s, Running: 358 reqs, Swapped: 0 reqs, Pending: 4161 reqs, GPU KV cache usage: 90.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:06 [metrics.py:486] Avg prompt throughput: 11003.6 tokens/s, Avg generation throughput: 244.1 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4090 reqs, GPU KV cache usage: 88.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:12 [metrics.py:486] Avg prompt throughput: 10993.5 tokens/s, Avg generation throughput: 242.4 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 4017 reqs, GPU KV cache usage: 86.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:18 [metrics.py:486] Avg prompt throughput: 10961.6 tokens/s, Avg generation throughput: 237.9 tokens/s, Running: 344 reqs, Swapped: 0 reqs, Pending: 3947 reqs, GPU KV cache usage: 84.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:24 [metrics.py:486] Avg prompt throughput: 10934.6 tokens/s, Avg generation throughput: 242.9 tokens/s, Running: 397 reqs, Swapped: 0 reqs, Pending: 3876 reqs, GPU KV cache usage: 97.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:29 [metrics.py:486] Avg prompt throughput: 4483.9 tokens/s, Avg generation throughput: 1870.3 tokens/s, Running: 394 reqs, Swapped: 0 reqs, Pending: 3871 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:34 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3576.3 tokens/s, Running: 377 reqs, Swapped: 0 reqs, Pending: 3871 reqs, GPU KV cache usage: 98.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:39 [metrics.py:486] Avg prompt throughput: 2675.5 tokens/s, Avg generation throughput: 2786.4 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 3833 reqs, GPU KV cache usage: 93.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:45 [metrics.py:486] Avg prompt throughput: 10963.5 tokens/s, Avg generation throughput: 238.1 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 3761 reqs, GPU KV cache usage: 91.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:52 [metrics.py:486] Avg prompt throughput: 10076.5 tokens/s, Avg generation throughput: 216.8 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 3689 reqs, GPU KV cache usage: 89.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:16:57 [metrics.py:486] Avg prompt throughput: 11039.3 tokens/s, Avg generation throughput: 240.9 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 3611 reqs, GPU KV cache usage: 87.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:17:03 [metrics.py:486] Avg prompt throughput: 10933.0 tokens/s, Avg generation throughput: 240.6 tokens/s, Running: 363 reqs, Swapped: 0 reqs, Pending: 3535 reqs, GPU KV cache usage: 85.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:17:09 [metrics.py:486] Avg prompt throughput: 10912.9 tokens/s, Avg generation throughput: 251.1 tokens/s, Running: 405 reqs, Swapped: 0 reqs, Pending: 3466 reqs, GPU KV cache usage: 95.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:17:14 [metrics.py:486] Avg prompt throughput: 5540.8 tokens/s, Avg generation throughput: 1959.4 tokens/s, Running: 410 reqs, Swapped: 0 reqs, Pending: 3461 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:17:18 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-9893 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=501
INFO 07-23 04:17:19 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3592.3 tokens/s, Running: 393 reqs, Swapped: 0 reqs, Pending: 3478 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:17:25 [metrics.py:486] Avg prompt throughput: 1736.8 tokens/s, Avg generation throughput: 2709.5 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 3465 reqs, GPU KV cache usage: 93.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:17:31 [metrics.py:486] Avg prompt throughput: 10984.6 tokens/s, Avg generation throughput: 238.9 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 3393 reqs, GPU KV cache usage: 91.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:17:37 [metrics.py:486] Avg prompt throughput: 11041.1 tokens/s, Avg generation throughput: 242.2 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 3317 reqs, GPU KV cache usage: 89.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:17:42 [metrics.py:486] Avg prompt throughput: 11010.9 tokens/s, Avg generation throughput: 239.1 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 3244 reqs, GPU KV cache usage: 87.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:17:48 [metrics.py:486] Avg prompt throughput: 11054.5 tokens/s, Avg generation throughput: 241.3 tokens/s, Running: 351 reqs, Swapped: 0 reqs, Pending: 3168 reqs, GPU KV cache usage: 85.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:17:54 [metrics.py:486] Avg prompt throughput: 11042.2 tokens/s, Avg generation throughput: 246.6 tokens/s, Running: 393 reqs, Swapped: 0 reqs, Pending: 3097 reqs, GPU KV cache usage: 93.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:17:59 [metrics.py:486] Avg prompt throughput: 7013.3 tokens/s, Avg generation throughput: 1556.4 tokens/s, Running: 407 reqs, Swapped: 0 reqs, Pending: 3075 reqs, GPU KV cache usage: 99.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:18:04 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3236.6 tokens/s, Running: 392 reqs, Swapped: 0 reqs, Pending: 3078 reqs, GPU KV cache usage: 99.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:18:09 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3618.7 tokens/s, Running: 377 reqs, Swapped: 0 reqs, Pending: 3078 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:18:15 [metrics.py:486] Avg prompt throughput: 10480.0 tokens/s, Avg generation throughput: 396.9 tokens/s, Running: 356 reqs, Swapped: 0 reqs, Pending: 2983 reqs, GPU KV cache usage: 91.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:18:21 [metrics.py:486] Avg prompt throughput: 11037.8 tokens/s, Avg generation throughput: 244.4 tokens/s, Running: 361 reqs, Swapped: 0 reqs, Pending: 2904 reqs, GPU KV cache usage: 89.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:18:27 [metrics.py:486] Avg prompt throughput: 11104.0 tokens/s, Avg generation throughput: 248.7 tokens/s, Running: 369 reqs, Swapped: 0 reqs, Pending: 2821 reqs, GPU KV cache usage: 87.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:18:33 [metrics.py:486] Avg prompt throughput: 11051.0 tokens/s, Avg generation throughput: 252.3 tokens/s, Running: 370 reqs, Swapped: 0 reqs, Pending: 2745 reqs, GPU KV cache usage: 84.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:18:39 [metrics.py:486] Avg prompt throughput: 11016.4 tokens/s, Avg generation throughput: 255.7 tokens/s, Running: 403 reqs, Swapped: 0 reqs, Pending: 2675 reqs, GPU KV cache usage: 92.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:18:44 [metrics.py:486] Avg prompt throughput: 7932.7 tokens/s, Avg generation throughput: 1284.1 tokens/s, Running: 433 reqs, Swapped: 0 reqs, Pending: 2645 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:18:49 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3370.0 tokens/s, Running: 412 reqs, Swapped: 0 reqs, Pending: 2666 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:18:50 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-10693 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=551
INFO 07-23 04:18:54 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3609.8 tokens/s, Running: 392 reqs, Swapped: 0 reqs, Pending: 2683 reqs, GPU KV cache usage: 100.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:18:59 [metrics.py:486] Avg prompt throughput: 8995.9 tokens/s, Avg generation throughput: 833.1 tokens/s, Running: 368 reqs, Swapped: 0 reqs, Pending: 2616 reqs, GPU KV cache usage: 92.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:19:05 [metrics.py:486] Avg prompt throughput: 10948.6 tokens/s, Avg generation throughput: 249.8 tokens/s, Running: 360 reqs, Swapped: 0 reqs, Pending: 2545 reqs, GPU KV cache usage: 90.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:19:11 [metrics.py:486] Avg prompt throughput: 10882.4 tokens/s, Avg generation throughput: 244.0 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 2467 reqs, GPU KV cache usage: 87.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:19:16 [metrics.py:486] Avg prompt throughput: 10959.4 tokens/s, Avg generation throughput: 243.8 tokens/s, Running: 355 reqs, Swapped: 0 reqs, Pending: 2391 reqs, GPU KV cache usage: 85.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:19:23 [metrics.py:486] Avg prompt throughput: 10147.7 tokens/s, Avg generation throughput: 227.0 tokens/s, Running: 368 reqs, Swapped: 0 reqs, Pending: 2318 reqs, GPU KV cache usage: 86.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:19:28 [metrics.py:486] Avg prompt throughput: 10869.6 tokens/s, Avg generation throughput: 274.8 tokens/s, Running: 416 reqs, Swapped: 0 reqs, Pending: 2268 reqs, GPU KV cache usage: 98.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:19:34 [metrics.py:486] Avg prompt throughput: 144.9 tokens/s, Avg generation throughput: 3628.4 tokens/s, Running: 400 reqs, Swapped: 0 reqs, Pending: 2268 reqs, GPU KV cache usage: 99.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:19:39 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3567.0 tokens/s, Running: 378 reqs, Swapped: 0 reqs, Pending: 2268 reqs, GPU KV cache usage: 98.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:19:44 [metrics.py:486] Avg prompt throughput: 6592.3 tokens/s, Avg generation throughput: 1310.6 tokens/s, Running: 357 reqs, Swapped: 0 reqs, Pending: 2204 reqs, GPU KV cache usage: 92.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:19:50 [metrics.py:486] Avg prompt throughput: 10991.7 tokens/s, Avg generation throughput: 244.5 tokens/s, Running: 362 reqs, Swapped: 0 reqs, Pending: 2128 reqs, GPU KV cache usage: 90.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:19:56 [metrics.py:486] Avg prompt throughput: 11000.2 tokens/s, Avg generation throughput: 245.6 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 2055 reqs, GPU KV cache usage: 87.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:20:02 [metrics.py:486] Avg prompt throughput: 10943.3 tokens/s, Avg generation throughput: 238.4 tokens/s, Running: 343 reqs, Swapped: 0 reqs, Pending: 1991 reqs, GPU KV cache usage: 85.9%, CPU KV cache usage: 0.0%.
INFO 07-23 04:20:08 [metrics.py:486] Avg prompt throughput: 10969.8 tokens/s, Avg generation throughput: 236.1 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 1916 reqs, GPU KV cache usage: 84.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:20:14 [metrics.py:486] Avg prompt throughput: 10944.6 tokens/s, Avg generation throughput: 256.7 tokens/s, Running: 408 reqs, Swapped: 0 reqs, Pending: 1860 reqs, GPU KV cache usage: 98.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:20:19 [metrics.py:486] Avg prompt throughput: 984.0 tokens/s, Avg generation throughput: 3351.2 tokens/s, Running: 393 reqs, Swapped: 0 reqs, Pending: 1875 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:20:24 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3251.2 tokens/s, Running: 376 reqs, Swapped: 0 reqs, Pending: 1891 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:20:26 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-11470 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=601
INFO 07-23 04:20:29 [metrics.py:486] Avg prompt throughput: 6250.6 tokens/s, Avg generation throughput: 1658.8 tokens/s, Running: 346 reqs, Swapped: 0 reqs, Pending: 1842 reqs, GPU KV cache usage: 92.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:20:35 [metrics.py:486] Avg prompt throughput: 10977.8 tokens/s, Avg generation throughput: 236.1 tokens/s, Running: 344 reqs, Swapped: 0 reqs, Pending: 1768 reqs, GPU KV cache usage: 90.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:20:41 [metrics.py:486] Avg prompt throughput: 10925.5 tokens/s, Avg generation throughput: 233.3 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 1694 reqs, GPU KV cache usage: 88.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:20:47 [metrics.py:486] Avg prompt throughput: 10960.1 tokens/s, Avg generation throughput: 238.7 tokens/s, Running: 354 reqs, Swapped: 0 reqs, Pending: 1620 reqs, GPU KV cache usage: 86.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:20:52 [metrics.py:486] Avg prompt throughput: 10938.1 tokens/s, Avg generation throughput: 242.1 tokens/s, Running: 363 reqs, Swapped: 0 reqs, Pending: 1539 reqs, GPU KV cache usage: 84.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:20:58 [metrics.py:486] Avg prompt throughput: 10958.5 tokens/s, Avg generation throughput: 265.0 tokens/s, Running: 425 reqs, Swapped: 0 reqs, Pending: 1472 reqs, GPU KV cache usage: 98.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:03 [metrics.py:486] Avg prompt throughput: 2052.4 tokens/s, Avg generation throughput: 2814.3 tokens/s, Running: 415 reqs, Swapped: 0 reqs, Pending: 1469 reqs, GPU KV cache usage: 99.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:08 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3642.6 tokens/s, Running: 397 reqs, Swapped: 0 reqs, Pending: 1472 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:15 [metrics.py:486] Avg prompt throughput: 4470.7 tokens/s, Avg generation throughput: 1965.5 tokens/s, Running: 364 reqs, Swapped: 0 reqs, Pending: 1422 reqs, GPU KV cache usage: 93.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:21 [metrics.py:486] Avg prompt throughput: 11037.6 tokens/s, Avg generation throughput: 249.4 tokens/s, Running: 363 reqs, Swapped: 0 reqs, Pending: 1351 reqs, GPU KV cache usage: 91.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:26 [metrics.py:486] Avg prompt throughput: 11002.9 tokens/s, Avg generation throughput: 248.1 tokens/s, Running: 359 reqs, Swapped: 0 reqs, Pending: 1278 reqs, GPU KV cache usage: 88.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:32 [metrics.py:486] Avg prompt throughput: 10978.3 tokens/s, Avg generation throughput: 242.7 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 1209 reqs, GPU KV cache usage: 86.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:38 [metrics.py:486] Avg prompt throughput: 11028.3 tokens/s, Avg generation throughput: 242.1 tokens/s, Running: 352 reqs, Swapped: 0 reqs, Pending: 1131 reqs, GPU KV cache usage: 84.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:44 [metrics.py:486] Avg prompt throughput: 11018.2 tokens/s, Avg generation throughput: 256.1 tokens/s, Running: 415 reqs, Swapped: 0 reqs, Pending: 1057 reqs, GPU KV cache usage: 98.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:49 [metrics.py:486] Avg prompt throughput: 3289.0 tokens/s, Avg generation throughput: 2685.8 tokens/s, Running: 404 reqs, Swapped: 0 reqs, Pending: 1068 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:54 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3272.9 tokens/s, Running: 387 reqs, Swapped: 0 reqs, Pending: 1082 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:21:59 [metrics.py:486] Avg prompt throughput: 3975.3 tokens/s, Avg generation throughput: 2414.0 tokens/s, Running: 353 reqs, Swapped: 0 reqs, Pending: 1054 reqs, GPU KV cache usage: 93.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:22:05 [metrics.py:486] Avg prompt throughput: 10956.7 tokens/s, Avg generation throughput: 238.5 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 985 reqs, GPU KV cache usage: 90.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:22:11 [metrics.py:486] Avg prompt throughput: 10936.7 tokens/s, Avg generation throughput: 238.2 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 917 reqs, GPU KV cache usage: 89.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:22:17 [metrics.py:486] Avg prompt throughput: 10884.0 tokens/s, Avg generation throughput: 235.2 tokens/s, Running: 345 reqs, Swapped: 0 reqs, Pending: 843 reqs, GPU KV cache usage: 86.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:22:23 [metrics.py:486] Avg prompt throughput: 10958.2 tokens/s, Avg generation throughput: 235.9 tokens/s, Running: 348 reqs, Swapped: 0 reqs, Pending: 765 reqs, GPU KV cache usage: 84.3%, CPU KV cache usage: 0.0%.
INFO 07-23 04:22:29 [metrics.py:486] Avg prompt throughput: 10980.4 tokens/s, Avg generation throughput: 248.1 tokens/s, Running: 407 reqs, Swapped: 0 reqs, Pending: 686 reqs, GPU KV cache usage: 97.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:22:34 [metrics.py:486] Avg prompt throughput: 4415.2 tokens/s, Avg generation throughput: 2051.7 tokens/s, Running: 408 reqs, Swapped: 0 reqs, Pending: 676 reqs, GPU KV cache usage: 99.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:22:39 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3621.3 tokens/s, Running: 392 reqs, Swapped: 0 reqs, Pending: 677 reqs, GPU KV cache usage: 99.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:22:44 [metrics.py:486] Avg prompt throughput: 2589.1 tokens/s, Avg generation throughput: 2800.2 tokens/s, Running: 363 reqs, Swapped: 0 reqs, Pending: 642 reqs, GPU KV cache usage: 93.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:22:50 [metrics.py:486] Avg prompt throughput: 10289.9 tokens/s, Avg generation throughput: 232.3 tokens/s, Running: 367 reqs, Swapped: 0 reqs, Pending: 564 reqs, GPU KV cache usage: 91.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:22:56 [metrics.py:486] Avg prompt throughput: 10968.0 tokens/s, Avg generation throughput: 254.6 tokens/s, Running: 377 reqs, Swapped: 0 reqs, Pending: 487 reqs, GPU KV cache usage: 89.5%, CPU KV cache usage: 0.0%.
INFO 07-23 04:23:02 [metrics.py:486] Avg prompt throughput: 10910.2 tokens/s, Avg generation throughput: 254.7 tokens/s, Running: 367 reqs, Swapped: 0 reqs, Pending: 418 reqs, GPU KV cache usage: 87.1%, CPU KV cache usage: 0.0%.
INFO 07-23 04:23:08 [metrics.py:486] Avg prompt throughput: 10888.9 tokens/s, Avg generation throughput: 247.3 tokens/s, Running: 367 reqs, Swapped: 0 reqs, Pending: 341 reqs, GPU KV cache usage: 85.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:23:14 [metrics.py:486] Avg prompt throughput: 10926.7 tokens/s, Avg generation throughput: 252.0 tokens/s, Running: 400 reqs, Swapped: 0 reqs, Pending: 277 reqs, GPU KV cache usage: 95.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:23:19 [metrics.py:486] Avg prompt throughput: 5758.2 tokens/s, Avg generation throughput: 1889.2 tokens/s, Running: 408 reqs, Swapped: 0 reqs, Pending: 269 reqs, GPU KV cache usage: 99.9%, CPU KV cache usage: 0.0%.
WARNING 07-23 04:23:19 [scheduler.py:1800] Sequence group cmpl-6549b95d197c49689333433c3dd493db-13098 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=651
INFO 07-23 04:23:24 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3323.0 tokens/s, Running: 391 reqs, Swapped: 0 reqs, Pending: 285 reqs, GPU KV cache usage: 99.8%, CPU KV cache usage: 0.0%.
INFO 07-23 04:23:30 [metrics.py:486] Avg prompt throughput: 2098.9 tokens/s, Avg generation throughput: 2951.3 tokens/s, Running: 349 reqs, Swapped: 0 reqs, Pending: 274 reqs, GPU KV cache usage: 93.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:23:35 [metrics.py:486] Avg prompt throughput: 10939.3 tokens/s, Avg generation throughput: 234.7 tokens/s, Running: 335 reqs, Swapped: 0 reqs, Pending: 210 reqs, GPU KV cache usage: 91.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:23:41 [metrics.py:486] Avg prompt throughput: 11017.3 tokens/s, Avg generation throughput: 230.1 tokens/s, Running: 337 reqs, Swapped: 0 reqs, Pending: 133 reqs, GPU KV cache usage: 89.2%, CPU KV cache usage: 0.0%.
INFO 07-23 04:23:47 [metrics.py:486] Avg prompt throughput: 10997.6 tokens/s, Avg generation throughput: 232.7 tokens/s, Running: 347 reqs, Swapped: 0 reqs, Pending: 55 reqs, GPU KV cache usage: 87.6%, CPU KV cache usage: 0.0%.
INFO 07-23 04:23:53 [metrics.py:486] Avg prompt throughput: 11016.5 tokens/s, Avg generation throughput: 236.3 tokens/s, Running: 325 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 80.7%, CPU KV cache usage: 0.0%.
INFO 07-23 04:23:58 [metrics.py:486] Avg prompt throughput: 53.9 tokens/s, Avg generation throughput: 3226.9 tokens/s, Running: 281 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 71.4%, CPU KV cache usage: 0.0%.
INFO 07-23 04:24:03 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 3320.2 tokens/s, Running: 134 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 34.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37916 - "POST /v1/completions HTTP/1.1" 200 OK
INFO 07-23 04:24:14 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 51.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:24:24 [metrics.py:486] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 07-23 04:26:15 [launcher.py:79] Shutting down FastAPI HTTP server.
Exception ignored in: <function ExactWeakKeyDictionary.__setitem__.<locals>.<lambda> at 0x7f32e8280540>
Traceback (most recent call last):
  File "/root/rehan/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py", line 908, in <lambda>
    self.refs[idx] = weakref.ref(key, lambda ref: self._remove_id(idx))

  File "/root/rehan/.venv/lib/python3.12/site-packages/vllm/engine/multiprocessing/engine.py", line 435, in signal_handler
    raise KeyboardInterrupt("MQLLMEngine terminated")
KeyboardInterrupt: MQLLMEngine terminated
[rank0]:[W723 04:26:16.579273619 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
